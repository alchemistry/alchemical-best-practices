%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% LIVECOMS ARTICLE TEMPLATE FOR BEST PRACTICES GUIDE
%%% ADAPTED FROM ELIFE ARTICLE TEMPLATE (8/10/2017)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PREAMBLE
\documentclass[9pt,bestpractices]{livecoms}
% Use the 'onehalfspacing' option for 1.5 line spacing
% Use the 'doublespacing' option for 2.0 line spacing
% Use the 'lineno' option for adding line numbers.
% The 'bestpractices' option for indicates that this is a best practices guide.
% Omit the bestpractices option to remove the marking as a LiveCoMS paper.
% Please note that these options may affect formatting.

\usepackage{lipsum} % Required to insert dummy text
\usepackage[version=4]{mhchem}
\usepackage{siunitx}
\usepackage{url}
\DeclareSIUnit\Molar{M}
\usepackage[italic]{mathastext}
\graphicspath{{figures/}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% IMPORTANT USER CONFIGURATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[most]{tcolorbox}
\usepackage{enumitem,amssymb}
\usepackage{textgreek}
\usepackage{changepage}
\usepackage{verbatim}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Added to allow customisation of table of contents
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tocloft}
\usepackage{xcolor}
\usepackage{todonotes}

% aux. comments Stefan Boresch -> Stefan Boresch
\newcommand{\sbnote}[1]{%
  {\bfseries{}[SB: }%
  {\textcolor{blue}{#1}}{\bfseries{}]}
}

% aux. comments Emilio Gallicchio
\newcommand{\egnote}[1]{%
  {\bfseries{}[EG: }%
  {\textcolor{green}{#1}}{\bfseries{}]}
}

\newcommand{\rref}{{\bfseries[REFs]}{}}

\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\versionnumber}{2.0} % you should update the minor version number in preprints and major version number of submissions.
\newcommand{\githubrepository}{\url{https://github.com/alchemistry/alchemical-best-practices}} %this should be the main github repository for this article
\newcommand{\expect}[1]{\left\langle{#1}\right\rangle}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE SETUP
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Best Practices for Single Alchemical Free Energy Calculations [Article v\versionnumber]}
\author[1*]{Antonia S. J. S. Mey}
\author[22]{Irfan Alibay}
\author[2]{Bryce K. Allen}
\author[11]{Agastya P. Bhati}
\author[18]{Stefan Boresch}
\author[3]{Hannah E. Bruce Macdonald}
\author[3*]{John D. Chodera}
\author[26]{Finlay Clark}
\author[11, 12, 13]{Peter V. Coveney}
\author[15]{Jonathan W. Essex}
\author[19]{Emilio Gallicchio}
\author[9]{Vytautas Gapsys}
\author[23,24]{Michael Gillhofer}
\author[9]{David F. Hahn}
\author[20]{Wei-Tse Hsu}
\author[25]{Sheenam Khuttan}
\author[1,10]{Maximilian Kuhn}
\author[15]{Oliver J. Melling}
\author[1]{Julien Michel}
\author[4*]{David L. Mobley}
\author[5]{Levi N. Naden}
\author[23,24]{Chris Oostenbrink}
\author[4]{Meghan Osato}
\author[15,16]{William G. Poole}
\author[6]{Samarjeet Prasad}
\author[21,22]{Benjamin Ries}
\author[2,7]{Andrea Rizzi}
\author[17]{Jenke Scheen}
\author[14]{David R. Slochower}
\author[8*]{Michael R. Shirts}
\author[9]{Gary Tresadern}
\author[2]{Huafeng Xu}

%
\affil[1]{EaStCHEM School of Chemistry, David Brewster Road, Joseph Black Building, The King's Buildings, Edinburgh, EH9 3FJ, UK}
\affil[2]{Silicon Therapeutics, Boston, MA, USA}
\affil[3]{Computational and Systems Biology Program, Sloan Kettering Institute, Memorial Sloan Kettering Cancer Center, New York NY, USA}
\affil[4]{Departments of Pharmaceutical Sciences and Chemistry, University of California, Irvine, Irvine, USA}
\affil[5]{Molecular Sciences Software Institute, Blacksburg VA, USA}
\affil[6]{National Institutes of Health, Bethesda, MD, USA}
\affil[7]{Tri-Institutional Training Program in Computational Biology and Medicine, New York, NY, USA}
\affil[8]{University of Colorado Boulder, Boulder, CO, USA}
\affil[9]{Computational Chemistry, Janssen Research \& Development, Turnhoutseweg 30, Beerse B-2340, Belgium}
\affil[10]{Cresset, Cambridgeshire, UK}
\affil[11]{Centre for Computational Sciences, Department of Chemistry, University College London, London WC1H 0AJ, United Kingdom}
\affil[12]{Advanced Research Computing Centre, University College London, London WC1H 9BT, United Kingdom}
\affil[13]{Computational Science Laboratory, Institute for Informatics, Faculty of Science, University of Amsterdam, Amsterdam 1012, The Netherlands}
\affil[14]{Vertex Pharmaceuticals, San Diego, CA, USA}
\affil[15]{School of Chemistry and Chemical Engineering, University of Southampton, Southampton, SO17 1BJ, United Kingdom}
\affil[16]{Astex Pharmaceuticals, 436 Cambridge Science Park, Milton Road, Cambridge, CB4 0QA, United Kingdom}
\affil[17]{Open Molecular Software Foundation, Davis, CA 95618, USA}
\affil[18]{University of Vienna, Faculty of Chemistry, Institute of Computational Biological Chemistry, Wahringer Str. 17, A-1090 Vienna}
\affil[19]{Department of Chemistry and Biochemistry, Brooklyn College of the City University of New York, New York, NY, 11210
Ph.D. Program in Chemistry, The Graduate Center of the City University of New York, New York, NY, 10016
Ph.D. Program in Biochemistry, The Graduate Center of the City University of New York, New York, NY, 10016}
\affil[20]{Department of Biochemistry, University of Oxford, Oxford OX1 3QU, United Kingdom}
\affil[21]{Boehringer Ingelheim Pharma GmbH \& Co KG, Medicinal Chemistry, Birkendorfer Str 65, 88397 Biberach an der Riss, Germany}
\affil[22]{Open Free Energy, Open Molecular Software Foundation, Davis, CA, 95616, United State}
\affil[23]{Institute of Molecular Modeling and Simulation, BOKU University, 1190 Vienna, Austria}
\affil[24]{Christian Doppler Laboratory for Molecular Informatics in the Biosciences, BOKU University, 1190 Vienna, Austria}
\affil[25]{SandboxAQ, Palo Alto, California 94301, United States}
\affil[26]{School of Natural and Environmental Sciences, Newcastle University, Newcastle upon Tyne NE1 7RU, United Kingdom}

\corr{antonia.mey@ed.ac.uk}{ASJSM}
\corr{john.chodera@choderalab.org}{JDC}
\corr{dmobley@mobleylab.org}{DLM}
\corr{michael.shirts@colorado.edu}{MRS}

\orcid{Antonia S. J. S. Mey}{0000-0001-7512-5252}
\orcid{Bryce Allen}{0000-0002-0804-8127}
\orcid{Stefan Boresch}{0000-0002-2793-6656}
\orcid{Hannah E. Bruce Macdonald}{0000-0002-5562-6866}
\orcid{John D. Chodera}{0000-0003-0542-119X}
\orcid{Maximilian Kuhn}{0000-0002-2811-3934}
\orcid{Emilio Gallicchio}{0000-0002-2606-4913}
\orcid{Julien Michel}{0000-0003-0360-1760}
\orcid{David L. Mobley}{0000-0002-1083-5533}
\orcid{Levi N. Naden}{0000-0002-3692-5027}
\orcid{Samarjeet Prasad}{0000-0001-8320-6482}
\orcid{Andrea Rizzi}{0000-0001-7693-2013}
\orcid{Jenke Scheen}{0000-0001-9781-0445}
\orcid{David R. Slochower}{0000-0003-3928-5050}
\orcid{Michael R. Shirts}{0000-0003-3249-1097}
\orcid{Gary Tresadern}{0000-0002-4801-1644}
\orcid{Huafeng Xu}{0000-0001-5447-0452}
\orcid{David F. Hahn}{0000-0003-2830-6880}
\orcid{Vytautas Gapsys}{0000-0002-6761-7780}
\orcid{Agastya P. Bhati}{0000-0003-4539-4819}
\orcid{Peter V. Coveney}{0000-0002-8787-7256}
\orcid{William G. Poole}{0009-0003-2441-8794}
\orcid{Oliver J. Melling}{0000-0001-6243-7433}
\orcid{Jonathan W. Essex}{0000-0003-2639-2746}
\orcid{Wei-Tse Hsu}{0000-0001-6167-5480}
\orcid{Benjamin Ries}{0000-0002-0945-8304}
\orcid{Meghan Osato}{0000-0002-2732-457X}
\orcid{Michael Gillhofer}{0000-0001-8081-6373}
\orcid{Chris Oostenbrink}{0000-0002-4232-2556}
\orcid{Irfan Alibay}{0000-0001-5787-9130}
\orcid{Sheenam Khuttan}{0000-0002-8873-6359}
\orcid{Finlay Clark}{0000-0003-0474-5475}


\blurb{This LiveCoMS document is maintained online on GitHub at \githubrepository; to provide feedback, suggestions, or help improve it, please visit the GitHub repository and participate via the issue tracker.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PUBLICATION INFORMATION
%%% Fill out these parameters when available
%%% These are used when the "pubversion" option is invoked
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pubDOI{10.33011/livecoms.2.1.18378}
\pubvolume{2}
\pubyear{2020}
\articlenum{18378}
\datereceived{5 August 2020}
\dateaccepted{25 November 2020}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE START
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{frontmatter}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Abstract
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

Alchemical free energy calculations are a useful tool for predicting free energy differences associated with the transfer of molecules from one environment to another.
The hallmark of these methods is the use of ``bridging'' potential energy functions representing \emph{alchemical} intermediate states that cannot exist as real chemical species. The data collected from these bridging alchemical thermodynamic states allows the efficient computation of transfer free energies (or differences in transfer free energies) with orders of magnitude less simulation time than simulating the transfer process directly. 
While these methods are highly flexible, care must be taken in avoiding common pitfalls to ensure that computed free energy differences can be robust and reproducible for the chosen force field, and that appropriate corrections are included to permit direct comparison with experimental data.

In this paper, we review current best practices for several popular application domains of  alchemical free energy calculations performed with equilibrium simulations, in particular relative and absolute small molecule binding free energy calculations to biomolecular targets.

\end{abstract}
\end{frontmatter}

\newpage

\tableofcontents

\newpage

%%%%%%%%%%%%%%%%%%%%
%  Introduction    %
%%%%%%%%%%%%%%%%%%%%

\section{What are alchemical free energy methods?}
\label{sec:intro}
Alchemical free energy calculations compute free energy differences associated with transfer processes, such as the binding of a small molecule to a receptor, the transfer of a small molecule from an aqueous to apolar phase~\cite{zwanzig1954hightemperature}, or the effects of protein side chain mutations on binding affinities or thermostabilities. 
 These calculations use non-physical\footnote{Here, the non-physical nature of the transformation is referred to as "alchemical", a term coined by Tembre and McCammon in Ref.~\cite{tembre1984ligandreceptor}.} intermediate states in which the chemical identity of some portion of the system (such as a small molecule ligand or protein sidechain) is changed by modifying the potential governing the interactions with the environment for the atoms being modified, inserted, or deleted. 

Fig.~\ref{fig:fig_what_is_alchemy} illustrates common free energy changes that may be difficult to compute with unbiased molecular dynamics methods, but are more tractable with alchemical methods.
In alchemical simulations, the introduction of intermediate \textit{alchemical states} that bridge the high-probability regions of configuration space between two physical endstates of interest, permits the robust computation of free energy for large transformations.
Alchemical calculations can be used in a variety of scenarios, such as: 
\begin{itemize}
\item computing the free energy of a conformational change for a molecule with a high barrier to interconversion (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{B});
\item computing partition ($\log P$) or distribution ($\log D$) coefficients between environments (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{A})~\cite{rustenburg2016measuring, bosisio2016blinded} 
\item determining partitioning between compartments into membranes (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{D})~\cite{corey2019insights}. 
\end{itemize}

Furthermore, alchemical calculations are frequently used to estimate changes in free energies upon modifying a ligand or protein: 
\begin{itemize}
\item a protein residue can be alchemically mutated to probe the impact on binding affinity (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{F})\cite{hauser2018predicting,aldeghi2018accurate} or changes in protein thermostability~\cite{seeliger2010protein,gapsys2016insights,gapsys2016accurate,aldeghi2019accurate}; 
\item the entire ligand can be alchemically transferred from protein to solvent in an absolute binding free energy calculation (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{C})~\cite{mobley2007predicting,aldeghi2015accurate,aldeghi2017predictions}; 
\item small alchemical modifications can be made between chemically related ligands to estimate relative differences in binding free energies (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{E})~\cite{wang2015accurate,mey2016blinded,song2019using,gapsys2020large,kuhn2020assessment}.
\end{itemize}


After an alchemical calculation is performed, which generally involves multiple simulations at a variety of alchemical states, the data must be analyzed to compute an estimate of the free energy for the transformation of interest.
 Early work used simple but statistically suboptimal estimators for this: free energy perturbation (FEP) used a simple (but highly biased) estimator based on the Zwanzig relation~\cite{zwanzig1954hightemperature} or numerical quadrature via thermodynamic integration (TI), for which the theory dates back the better part of a century but with the first computational applications emerging in the 1980's and 90's~\cite{kirkwood1935statistical, jorgensen1985monte, kollman1993free, wong1986dynamics, merz1989free}. %
 More recent developments have seen new, highly efficient statistical estimators that make better use of all the data, often building on the more efficient and less biased Bennett acceptance ratio (BAR)~\cite{bennett1976efficient}, producing multistate generalizations~\cite{shirts2008statisticallya} or removing the need for global equilibrium~\cite{wu2016multiensemble, mey2014xtram, wu2014statistically}.

Subsequent work in the 2000s led to improved implementations of alchemical methods in popular biomolecular simulation packages~\cite{shirts2003extremely,shirts2005solvation,vanderspoel2005gromacs, mermelstein2018fast, wang2015accurate, hedges2019biosimspace, riniker2011calculation}. 
 This foundational work, combined with the methodological, technological, and hardware improvements of the last 5--10 years, has led to an explosion of interest and direct commercial application of these technologies~\cite{wang2015accurate, fratev2019improved, schindler2020largescale, cournia2017relative, sherborne2016collaborating, kuhn2020assessment}.


As the field of molecular simulation can now routinely access microsecond timescales with the aid of GPUs~\cite{salomon-ferrer2013routine}, and millisecond timescales appear to soon be within reach, accurate alchemical calculations on even more challenging problems will become reasonable to perform. 
In the meantime, today's users may find it difficult to get started with these complex calculations whilst also keeping up with the fast pace of change. 
This Best Practices guide provides current recommendations and tips for users of all experience. Updates and suggestions are welcomed via our GitHub repository at \url{https://github.com/alchemistry/alchemical-best-practices}.    

\begin{figure*}
    \centering\includegraphics[width=0.85\linewidth]{figures/fig1_what_is_alchemy/Figure.pdf}   
    \caption{\textbf{Illustration of common types of free energies differences that can be calculated using alchemical free energy methods and a typical workflow for executing a relative binding free energy calculation (yellow box).} 
    \textbf{A}: Partition coefficient such as $\log P$ or $\log D$ depend on a change in free energy between different phases; here, as an example the partition coefficient between methanol and water is shown. \textbf{B}: Change in free energy due to a conformational change of the molecule across a high barrier, such as the torsion reaching from the aromatic ring to the hydroxyl group. \textbf{C}: Absolute free energies of binding of a small molecule to a host (e.g. protein). \textbf{D}: Free energy difference associated with the insertion of a molecule into a membrane. \textbf{E}: Relative free energy of binding of one molecule with respect to another, here toluene and benzyl alcohol. \textbf{F}: Effect of mutations of protein or host residues on free energies of binding. 
    \textbf{G.1}: the protein structure of the system is \textit{prepared} such that all erroneous patterns are resolved and proper protonation is applied. All query ligands are positioned into the binding site. \textbf{G.2}: $N=6$ compounds are predicted in this example. \textbf{G.3}: $n=7$ transformations (edges) are chosen in this example. \textbf{G.4}: for each transformation, a $\lambda$ decoupling parameter is applied to guide the transformation. \textbf{G.5}: for each transformation and $\lambda$ window a simulation is run. \textbf{G.6}: for each transformation, the relative binding free energy ($\Delta\Delta$G$_{bind}$) is calculated given $\lambda$. \textbf{G.7}: Each transformation (edge) has a corresponding binding free energy estimation. \textbf{G.8}: a final calculation is done to estimate the absolute binding free energy of each compound using for example a maximum-likelihood estimator. \textbf{G.9}: Absolute binding free energy estimates are ready to be used for prioritization in synthesis. \label{fig:fig_what_is_alchemy}
    }
\end{figure*}

%%%%%%%%%%%%%%%%%%%%
% Prerequesites    %
%%%%%%%%%%%%%%%%%%%%
\section{Prerequisites and Scope}
\label{sec:pre}

This Best Practices guide focuses on providing a good starting point for new practitioners and a reference for experienced practitioners. 
 For this purpose we provide a convenient checklist (Sec.~\ref{sec:checklist}) to help ensure all calculations can take advantage of currently-understood best practices for alchemical simulation and analysis. Where the best practices are currently not certain, we highlight areas where further research is needed to identify an unambiguous recommendation.
 This guide can also serve as a set of best practices to ensure simulation robustness and reproducibility which reviewers may wish to consider as they evaluate papers including alchemical free energy calculations.

In this best practices document, we assume that novice practitioners have at least moderate experience with molecular simulation concepts and use of simulation packages. 
We also assume basic familiarity with the principles of molecular mechanics, molecular dynamics simulations, statistical mechanics, and the biophysics of protein-ligand association. If you feel unfamiliar with some of these concepts, good starting points can be found in these references~\cite{braun2019best, grossfield2018best, klimovich2015guidelines, shirts2012best}. 

 While reading this Best Practices guide, it is important to bear in mind \emph{this is not a review} of all free energy calculation methods at the cutting edge of current research.
Instead this guide aims to answer the following questions:
\begin{itemize}
    \item Is my problem suitable for an alchemical calculation? 
     \item How do I select an appropriate simulation protocol? 
     \item What software tools are available to perform alchemical calculations? 
     \item How should I analyze my data and report uncertainties? 
\end{itemize}

Notably, this document---version 2.0 of the original guide---focuses specifically on best practices on single alchemical free energy calculations. A companion guide, Best Practices for Multiple Alchemical Free Energy Calculations, covers the considerations involved in high-throughput or large-scale campaigns, such as automation, perturbation network design, and campaign-level data management and analysis. Readers aiming to scale up to multiple calculations may find that guide more relevant to those aspects. 

In this guide, some other background information may be needed depending on the nature of the alchemical project. For example, often, if binding poses are not known, docking calculations or co-folding models can be used to generate an initial small molecule binding pose to start alchemical simulations\cite{scheen2025leveraging, thaler2025boltz}. This will require some basic familiarity on how to perform docking or using generative models. to generate reasonable simulation starting points~\cite{grinter2014challenges}. 

As some of the theoretical background can seem daunting, we do, however, provide a guide to the essential theory behind alchemical free energy calculations in Sec.~\ref{sec:theory}.
In the remainder of this paper, we will cover topics that are key to the preparation (Sec.~\ref{sec:prerequisites}), choice and use of correct protocols (Sec.~\ref{sec:simulation_protocol_choice}), and finally the best practices that should be used in the analysis of alchemical calculations (Sec.~\ref{sec:data_analysis}). 
We will give particular focus to aspects of the molecular simulations which are unique to alchemical calculations---these include the calculation of transfer free energies (hydration free energies, partition coefficients, etc.), and binding free energies (absolute and relative). We primarily focus on free energy calculations using simulations performed at \emph{equilibrium} in this Best Practices guide, as best practices for these are more developed, and non-equilibrium techniques may warrant their own guide as such practices evolve. 


While we try to address as many methods and practices as possible, the field of free energy calculations is broad, and there are many advanced topics that are left to future Best Practices documents focusing on specific issues. 
Below, we provide a non-exhaustive list of topics we have \emph{not} addressed, along with some references to provide starting points on these more advanced topics:
\begin{itemize}
\item covalent inhibition~\cite{lameira2019predicting}
\item free energies of mutation of protein side chains~\cite{gapsys2016accurate,aldeghi2018accurate}
\item nonspecific binding or multiple binding sites~\cite{gill2018binding}
\item approximate and often less accurate endpoint free energy methods such as MM-PBSA~\cite{genheden2015mm} and LIE~\cite{gutierrez-de-teran2012linear}
\item Free energy methods that extract the ligand using geometric order parameters and potential of mean force methods~\cite{heinzelmann2017attachpullrelease}
\item forcefield dependence for protein, ligand, ions, co-solvents, and co-factors. A number of different studies have looked at the influence of force fields and it is assumed the user has made an appropriate choice for the system under study~\cite{loeffler2018reproducibility, vassetti2019assessment, lopes2015current}. 
\item non-equilibrium free energy calculations~\cite{gapsys2020large}
\item Free energy calculations using QM/MM methods~\cite{beierlein2011simple,dybeck2016comparison,cave-ayland2015direct,Schoeller2023}.
\item Free energy calculations using machine learning methods~\cite{rufa2020chemical, scheen2020hybrid, cole2020machine,Karwounopoulos2024}
\end{itemize}

For convenience we have also compiled a list of common acronyms and common symbols (both in alphabetical order) used throughout this paper.
\begin{tcolorbox}[title=Acronyms, colback=blue!10!white]
    {\bf BAR} --- Bennett Acceptance Ratio\\
    {\bf CPU} --- Central Processing Unit\\
     {\bf FEP} --- Free Energy Perturbation\\
     {\bf GPCR} --- G-Protein Coupled Receptor\\
     {\bf GPU} --- Graphics Processing Unit\\
     {\bf MBAR} --- Multistate Bennett Acceptance Ratio\\
     {\bf MCSS} --- Maximum Common Substructure\\
     {\bf MD} --- Molecular Dynamics\\
     {\bf MUE} --- Mean Unsigned Error\\
     {\bf RMSE} --- Root Mean Square Error\\
     {\bf SAR} --- Structure-Activity Relationships\\
     {\bf TI} --- Thermodynamic Integration
\end{tcolorbox}


\begin{tcolorbox}[title=List of Symbols, colback=green!10!white]
$A$ --- Helmholtz free energy (free energy in the canonical ensemble) or Helmholtz function, with Helmholtz free energy used in the text.\\
$b$ --- reduced binding energy function \\
$C^{\circ}$ --- standard state concentration \\
$C_t$ --- discrete-time-normalized fluctuation auto-correlation function\\
$f$ --- reduced (dimensionless) free energy \\
$G$ --- Gibbs free energy (free energy in the isothermal isobaric ensemble), Gibbs function, or free enthalpy, though the most common term Gibbs free energy is used in the text\\
$g$ --- statistical inefficiency\\
$h$ --- Planck's constant \\
$\vec{h}$ --- a displacement vector in the ATM method
$k_B$ --- Boltzmann constant \\
$k_H$ --- Henry's constant \\
$K_b^{\circ}$ --- binding  constant \\
$L$ and $R$ --- generic names for ligand and receptor\\
$\mathcal{O}$ --- overlap matrix\\
$P^{\circ}$ --- standard pressure \\
$p$ --- pressure \\
$\vec{q}$ --- vector of a single configuration, i.e. $x$, $y$, $z$ coordinates of the simulation system\\
$T$ --- temperature \\
$t_0$ --- equilibration time \\
$U$ --- potential energy\\
$u$ --- reduced (dimensionless) potential describing a thermodynamic state \\
$w(b, \vec{\lambda})$ --- perturbation energy function \\
$Z$ --- partition function \\
$\beta \equiv (k_B T)^{-1}$ --- inverse thermal energy \\
$\Gamma$ --- configurational space accessible by simulations \\
$\Delta \hat{f}$ --- estimate from an estimator for the reduced free energy difference between two states\\
$\vec{\lambda}$ --- alchemical progress parameter, which may be multidimensional \\
$\mu$ --- chemical potential (grand canonical ensemble)\\
$\tau _{eq}$ --- integrated auto-correlation time\\
\end{tcolorbox}


%%%%%%%%%%%%%%%%%%%%
% Theory basics    %
%%%%%%%%%%%%%%%%%%%%
\section{Statistical mechanics demonstrates why alchemical free energy calculations work}
%\section{Statistical mechanics theory of solvation, solvent partitioning, and binding}
\label{sec:theory}


In this section, we use a statistical mechanics theory of dilute solutions to derive free energy expressions that form the basis of alchemical computational protocols to model non-covalent molecular binding, solvation, and solvent partitioning equilibria. The emphasis here is placed on bridging theoretical foundations and intuition. Since chemical equilibria are regulated by the chemical potentials of the species involved, we will start by considering a statistical mechanics expression of the chemical potential of a solute in a solvent. We will then combine chemical potentials to develop models for each process.

\subsection{The chemical potential}

The chemical potential of a solute $u$ in an ideally diluted solution in a solvent $v$ can be written as~\cite{guggenheim1952mixtures504,gilson1997statisticalthermodynamic,gilson2007calculation}
\begin{equation}
  \mu_u = -k_B T \ln \frac{q'_u}{C_u \Lambda_u^3}
  \label{eq:chemical-potential-definition}
\end{equation}
where $k_B$ is Boltzmann's constant, $T$ is the absolute temperature, $C_u = N_u/V$ is the number concentration of the solute, $\Lambda_u = h/\sqrt{2 \pi M_u k_B T}$ is the thermal De Broglie wavelength of the solute, where $h$ is Planck's constant and $M_u$ is the solute's total mass. The quantity $q'_u$ in Eq.~(\ref{eq:chemical-potential-definition}) is the molecular partition function of the solute at rest in the solvent
\begin{equation}
  q'_u = \frac{\Lambda_u^3}{\prod_i \lambda_i^3} 8 \pi^2 z_u
  \label{eq:intra-qpu-def}
\end{equation}
where $\beta = 1/(k_B T)$, $\lambda_i$ is the thermal De Broglie wavelength of the $i$-th atom of the solute, and $z_u$ is the intramolecular configurational partition function of the solute
\begin{equation}
  z_u = \int dx_u e^{-\beta \Psi_v(x_u)}
  \label{eq:intra-zu-def}
\end{equation}
where $x_u$ represents the collection of internal degrees of freedom of the solute (bond lengths, bond angles, and dihedral angles) with the corresponding volume element $dx_u$ assumed to include the appropriate Jacobian factors. The function $\Psi_v(x_u)$ in Eq.~\ref{eq:intra-zu-def} is the solvent-averaged potential of mean force of the solute in conformation $x_u$ in solvent $v$\cite{rouxandsimonson1999solventmodels} 
\begin{equation}
  e^{-\beta \Psi_v(x_u)} = \frac{1}{Z_{N_v}} \int d\vec{r}_v e^{-\beta U(x_u, \vec{r}_v)}
  \label{eq:solvent-pmf-def}
\end{equation}
where $\vec{r}_v$ represents the collection of Cartesian coordinates of the atoms of $N_v$ solvent molecules, $U(x_u, \vec{r}_v)$ is the potential energy of the solvent with one solute molecule in conformation $x_u$ placed in an arbitrary position in a volume $V$. When the potential energy function of the solution is separable into an intramolecular potential energy of the solute $U(x_u)$ and a solute-solvent non-bonded interaction energy, the potential of mean force can be written as the sum $\Psi_v(x_u) = U(x_u) + W_v(x_u)$ where $W_u(x_u)$ is the solvent potential of mean force, the solvation free energy of the solute fixed in configuration $x_u$.\cite{gilson2007calculation} However, the potential of mean force definition Eq.~(\ref{eq:solvent-pmf-def}) is valid in general. Finally, $Z_{N_v}$ is the configurational partition function of the pure solvent
\begin{equation}
  Z_{N_v} = \int d\vec{r}_v e^{-\beta U(\vec{r}_v)} \, .
  \label{eq:Z-pure-solvent}
\end{equation}


A few notes are in order. First, Eq.~(\ref{eq:chemical-potential-definition}) is derived using classical statistical mechanics theory.~\cite{hill1986statthermo} Classical mechanics is considered an excellent approximation for the room temperature processes studied here involving only changes in intermolecular interactions. A quantum mechanical treatment is necessary for processes not covered here, such as covalent binding, that involve breaking and forming chemical bonds. Classically, equilibrium thermodynamics properties, such as gas solubilities and binding constants, do not depend on atomic masses. Hence, while they are included in Eqs.~\ref{eq:chemical-potential-definition} and Eq.~\ref{eq:intra-qpu-def} for completeness, the thermal De Broglie wavelength terms coming from the partition functions of the momenta cancel in the resulting expressions below and we will no longer consider them.

Eq.~(\ref{eq:chemical-potential-definition}) is derived by writing the classical canonical configurational partition function $Z(N_u = 1, N_v)$ of one solute molecule in a solvent of $N_v$ molecules in a volume $V$ and multiplying and dividing it by configurational partition function of the pure solvent [Eq.~(\ref{eq:Z-pure-solvent})], and separating out the integration over the external degrees of freedom of the solute (translations and rotations) giving an $8 \pi^2 V$ term to yield $Z(N_u = 1, N_v) = Z_{N_v} 8 \pi^2 V z_u$ where $z_u$ is defined by Eqs.~(\ref{eq:intra-zu-def}) and (\ref{eq:solvent-pmf-def}). The canonical configurational partition function of $N_u$ independent solute molecules in a solvent is then obtained by considering the product of the solute terms $Z(N_u, N_v) = Z_{N_v} (8 \pi^2 V z_u)^{N_u}/N_u!$,~\cite{guggenheim1952mixtures504,simonson2016physical} where the factorial term takes care of indistinguishability. Finally, the canonical partition function $Q(N_u, N_v)$ of the solution is obtained by including the appropriate terms coming from the momenta and differentiating the resulting Helmholtz free energy $A(N_u, N_v) = -k_B T \ln Q(N_u, Nv)$ with respect to $N_u$ to obtain Eq.~(\ref{eq:chemical-potential-definition}).

The form Eq.~(\ref{eq:chemical-potential-definition}) for the solute chemical potential using the potential of mean force description is useful, as we will see, because it separates the solute's translational motion, which leads to the concentration dependence, from the intramolecular contributions. The potential of mean force description does not introduce approximations. With the exception of the use of classical statistical mechanics and the assumption of sufficient dilution so that the solute molecules can be considered independent, Eq.~(\ref{eq:chemical-potential-definition}) is rigorous. Due to rotation-vibration couplings, the separation of the solute's overall rotational motion leading to the $8 \pi^2$ term in Eq.~(\ref{eq:intra-qpu-def}) is not exact. However, it is not a strict requirement and the theory can be developed without it. The separation of rotational degrees of freedom is considered an excellent approximation at room temperature and a useful simplification, so it is adopted here.

We derived Eq.~(\ref{eq:chemical-potential-definition}) using the canonical (constant volume) partition function of the solution. Since the chemical potential can be equivalently obtained from the constant-volume differentiation of the Helmholtz free energy or the constant-pressure differentiation of the Gibbs free energy, Eq.~(\ref{eq:chemical-potential-definition}) is correct. However, the volume dependence of the chemical potential has to be considered when modeling the Gibbs free energy change for constant-pressure processes where the system's volume changes significantly.~\cite{gilson1997statisticalthermodynamic} Terms due to volume variations are generally considered small for most processes of solvation, solvent partitioning, and molecular binding at atmospheric pressure and are often ignored in alchemical calculations. Hence, we will use Eq.~(\ref{eq:chemical-potential-definition}) to derive expressions for $\Delta G$'s.

The standard chemical potential of a solute in an ideally dilute solution is obtained from Eq.~(\ref{eq:chemical-potential-definition}) by setting the concentration to the standard concentration $C^\circ$, generally $1$ mol/L equivalent to $1/1,661$ particles/\AA$^{3}$, 
\begin{equation}
  \mu_u^\circ = -k_B T \ln \frac{q'_u}{C^\circ \Lambda_u^3} \, .
  \label{eq:chemical-potential-standard}
\end{equation}
The standard state of a dilute solution is defined as an ideally dilute solution at concentration $C^\circ$.~\cite{levine2009physicalchemistrybook6ed} Hence, Eq.~(\ref{eq:chemical-potential-standard}) is formally correct for real solutions as well.

Next, we outline the application of the chemical potential statistical mechanics formalism for modeling key biophysical processes: solvation, solvent partitioning, and non-covalent molecular binding. Generally, turning statistical mechanics identities into computable quantities by molecular simulations involves expressing ratios of partition functions in terms of ensemble averages. In the present context, the quantity being averaged often turns out to be the exponential of a perturbation energy function (the \textit{Zwanzig relationship}~\cite{zwanzig1954hightemperature}), which is efficiently evaluated using the stratification algorithms and free energy estimators discussed in Sections \ref{subsec:formulations-abfe-rbfe}, \ref{subsec:numerical-implementations},  and \ref{subsec:estimators} rather than directly. Here we assume that an implementation is well-formed once it is expressed as a combination of exponential averages, assuming they can be evaluated in practice. As in the previous section, we use the solvent potential of mean force to lighten the notation when possible. The solvent degrees of freedom can be restored  in the resulting expressions using Eq.~(\ref{eq:solvent-pmf-def}). 

\subsection{Solvation}\label{sec:theory-solvation}

The standard molar Gibbs free energy of the solvation of a gas species $A$ in a solvent $v$
\begin{equation}
A(\mathrm{g})  \leftrightharpoons A(v)
\end{equation}
is
\begin{equation}
  \Delta G^\circ_{\mathrm{slv}} = \mu^\circ_{A(v)}  - \mu^\circ_{A(g)} = -k_B T \ln \frac{P^\circ}{C^\circ k_B T} - k_B T \ln \frac{z_{A(v)}}{z_{A(\mathrm{g})}}
  \label{eq:DG0-solvation-def}
\end{equation}
where we used Eq.~(\ref{eq:chemical-potential-standard}) for the solution and  Eq.~(\ref{eq:chemical-potential-definition}) for the gas (assumed ideal) at the standard gas concentration $C = P^\circ/k_B T$ where $P^\circ = 1$ bar is the standard pressure, and Eq.~(\ref{eq:intra-qpu-def}) noting that all momentum terms cancel. The first term in Eq.~(\ref{eq:DG0-solvation-def}) is an ideal term $\Delta G^\circ_{\mathrm{slv,ideal}}$ that accounts for the difference of standard states for solution and gases. The second term is the excess solvation free energy $\Delta G_{\mathrm{slv, exc.}}$ that can be evaluated by numerical alchemical calculations (see below). Hence Eq.~(\ref{eq:chemical-potential-standard}) can be used to compare calculated and experimental standard free energies of solvation.\cite{thompson2004new}

However, equilibrium experimental gas solvation data is most often available in terms of Henry's constants $k_H$. Setting $\Delta G_{\mathrm{slv}} = 0$ when the gas partial pressure and the solute's concentrations are equal to their equilibrium values $P_A$ and $C_A$, respectively, we obtain
\begin{equation}
  P_A = k_H C_A
  \label{eq:Henrys-law}
\end{equation}
where
\begin{equation}
  k_H = k_B T \frac{z_{A(\mathrm{g})}}{z_{A(v)}} \, .
  \label{eq:Henrys-constant}
\end{equation}
The relation above is used to connect alchemical calculations to Henry's constant values, often after converting them to the excess free energy scale~\cite{cabani1981group,nicholls2008predicting,mobley2014freesolv}
\begin{equation}
\Delta G_{\mathrm{slv, exc.}} = - k_B T \ln \frac{z_{A(v)}}{z_{A(\mathrm{g})}} = k_B T \ln \frac{k_H}{k_B T} \, .
\label{eq:DG-solvation-excess}
\end{equation}
Because it involves only intramolecular partition functions, Eq.~(\ref{eq:DG-solvation-excess}) states that the excess free energy of solvation corresponds to the process of moving the solute from a fixed position and orientation in the gas to a fixed position and orientation in the solvent. This is sometimes referred to as the solvation free energy in the Ben-Naim standard state.~\cite{bennaim1984solvation}

The next step is to express the ratio of intramolecular configurational partition functions in Eq.~(\ref{eq:DG-solvation-excess}) in an ensemble average form amenable to calculation by computer simulation. First, the potential of mean force in $z_{A(v)}$ [Eq.~(\ref{eq:intra-zu-def})] is replaced with its definition from Eq.~(\ref{eq:solvent-pmf-def}) to explicitly expose the coordinates of the solvent:
\begin{equation}
  \frac{z_{A(v)}}{z_{A(\mathrm{g})}} =
  \frac{
    \int dx_A d\vec{r}_v e^{-\beta U(x_A, \vec{r}_v)}
  }{
    \int dx_A d\vec{r}_v e^{-\beta [U(\vec{r}_v) + U(x_A)] }
  }
\end{equation}
where the integral $Z_{N_v}$ for the pure solvent from Eq.~(\ref{eq:Z-pure-solvent}) has been combined in the denominator with the integral $z_{A(\mathrm{g})}$ of the solute in the gas phase to obtain the configurational partition function of an artificial system where the solute is in the solvent but it is decoupled from it (note the absence of coupling terms between the degrees of freedom of the solvent and those of the solute).

Next, we multiply and divide by the integral $\int d\zeta$ of the six external degrees of freedom of the solute (the center of mass position and the orientation angles). These degrees of freedom, together with the internal degrees of freedom $x_A$, allow the recast the integrals in terms of the Cartesian coordinates $\vec{r}_A$ of the $n_A$ solute's atoms which are typically used in computer simulations, without restraining the position and orientation of the solute. Finally, we multiply and divide the integrand in the numerator by the integrand in the denominator to obtain
\begin{equation}
  \frac{z_{A(v)}}{z_{A(\mathrm{g})}} =
  \frac{
    \int d\vec{r}_A  d\vec{r}_v  e^{-\beta \{ U(\vec{r}_A, \vec{r}_v) -  [ U(\vec{r}_v) + U(\vec{r}_A) ] \}} e^{-\beta [U(\vec{r}_v) + U(  \vec{r}_A  )] } 
  }{
    \int d\vec{r}_A d\vec{r}_v e^{-\beta [U(\vec{r}_v) + U( \vec{r}_A  )] } 
  } = \langle e^{-\beta \Delta U} \rangle_0
  \label{eq:zratio-solv-average}
\end{equation}
where $\langle \ldots \rangle_0$ is an average in the decoupled ensemble and $\Delta U =  U(\vec{r}_A , \vec{r}_v) -  [ U(\vec{r}_v) + U(\vec{r}_A ) ]$ the change in the system's potential energy for coupling the solute to the solvent. Equivalently, we can consider the reciprocal of Eq.~(\ref{eq:zratio-solv-average}) and express it in terms of an ensemble average $\langle \ldots \rangle_1$ in the coupled ensemble:
\begin{equation}
  \frac{z_{A(v)}}{z_{A(\mathrm{g})}} = \frac{1}{\langle e^{\beta \Delta U} \rangle_1}
\end{equation}
where $-\Delta U = [ U(\vec{r}_v) + U(\vec{r}_A ) ] - U(\vec{r}_A , \vec{r}_v)$ is a decoupling energy.

Combining Eqs.~(\ref{eq:DG-solvation-excess}) and (\ref{eq:zratio-solv-average}) yields\cite{widom1982potential} 
\begin{equation}
  \Delta G_{\mathrm{slv, exc.}} = - k_B T \ln \langle e^{-\beta \Delta U} \rangle_0 = k_B T \ln \langle e^{\beta \Delta U} \rangle_1
  \label{eq:zratio-solv-dgexc}
\end{equation}
The objective of alchemical solvation free energy calculations is to implement Eq.~(\ref{eq:zratio-solv-dgexc}), by means of \emph{coupling} or \emph{decoupling} computational protocols and alchemical intermediate states as  discussed in section \ref{subsec:numerical-implementations}.

\subsection{Solvent partitioning}\label{sec:theory-partitioning}

The standard molar Gibbs free energy of transfer of a solute species $A$ from a  solvent $s$ to a solvent $v$
\begin{equation}
A(s)  \leftrightharpoons A(v)
\end{equation}
is
\begin{equation}
  \Delta G^\circ_{\mathrm{part}} = -k_B T \ln P_{sv} = \mu^\circ_{A(v)}  - \mu^\circ_{A(s)} = -k_B T \ln \frac{z_{A(v)}}{z_{A(s)}}
  \label{eq:DG0-partitioning-def}
\end{equation}
where $P_{sv} = C_{A(v)}/C_{A(s)}$ is the partition coefficient of $A$ for the two solvents.~\cite{rustenburg2016measuring} Eq.~(\ref{eq:DG0-partitioning-def}) 
immediately identifies the partition coefficient with the ratio of intramolecular configurational partition functions of $A$ in the two solvents:
\begin{equation}
  P_{sv} = \frac{z_{A(v)}}{z_{A(s)}} \, .
  \label{eq:partition-coefficient}
\end{equation}
This relation connects calculated ratios of partition functions to experimental partition coefficients. Similarly to Eq.~(\ref{eq:DG-solvation-excess}), Eq.~(\ref{eq:partition-coefficient}) corresponds to the process of transferring the solute from a fixed position and orientation in one solvent to a fixed position and orientation in the other.

The ratio of partition functions in Eq.~(\ref{eq:partition-coefficient}) can be treated in the same way as Eq.~(\ref{eq:zratio-solv-average}) to express it as the ensemble average in solvent $s$ of the change in potential energy $\Delta U$ for moving the solute to the other solvent $v$. However, in practice it has been more common to evaluate Eq.~(\ref{eq:DG0-partitioning-def}) as the difference of excess solvation free energies in the two solvents separately evaluated using Eq.~(\ref{eq:zratio-solv-dgexc}).~\cite{bosisio2016blinded} Formally, this approach is derived by multiplying and dividing Eq~(\ref{eq:partition-coefficient}) by $z_{A(\mathrm{g})}$ and expressing each terms as an ensemble average in the decoupled ensemble
\begin{equation}
  P_{sv} = \frac{z_{A(v)}}{z_{A(\mathrm{g})}}  \frac{z_{A(\mathrm{g})}}{z_{A(s)}} = \frac{\langle e^{-\beta \Delta U_{(v)}} \rangle_0}{\langle e^{-\beta \Delta U_{(s)} } \rangle_0 }
  \label{eq:partition-coefficient-coupling}
\end{equation}
where $\Delta U_{(v)}$ and $\Delta U_{(s)}$ are the solute's coupling energies to solvent $v$ and $s$, respectively. 
The implementation of Eq.~(\ref{eq:partition-coefficient-coupling}) in terms of decoupling
\begin{equation}
P_{sv} = \frac{\langle e^{\beta \Delta U_{(s)}} \rangle_1}{\langle e^{\beta \Delta U_{(v)} } \rangle_1 }
\label{eq:partition-coefficient-decoupling}
\end{equation}
is an example of a \emph{double-decoupling} alchemical computational protocol.~\cite{hermans1986freeenergy,gilson1997statisticalthermodynamic}

\subsection{Non-covalent molecular binding}
\label{sec:non-covalent-molecular-binding}

The standard Gibbs free energy of binding between a receptor $R$ and a ligand $L$ to form a complex $RL$ in a solvent $v$
\begin{equation}
  R(v) + L(v)  \leftrightharpoons RL(v)
  \label{eq:binding-reaction}
\end{equation}
is
\begin{equation}
  \Delta G^\circ_{b} = \mu^\circ_{RL(v)}  - \mu^\circ_{R(v)} - \mu^\circ_{L(v)} = -k_B T \ln K_b 
  \label{eq:DG0-binding-def}
\end{equation}
where~\cite{gilson1997statisticalthermodynamic,gilson2007calculation}
\begin{equation}
  K_b = \frac{C^\circ}{8 \pi^2} \frac{z_{RL(v)}}{z_{R(v)} z_{L(v)}}
  \label{eq:DG0-binding-constant-def}
\end{equation}
is the statistical mechanics expression for the binding constant. Eq.~(\ref{eq:DG0-binding-constant-def}) follows from the application of  Eq.~(\ref{eq:chemical-potential-standard}) for each of the three species and noting that the contributions of the momenta cancel. As discussed below, various alchemical protocols exist to evaluate the ratios of partition functions in Eq.~(\ref{eq:DG0-binding-constant-def}), providing a connection between the theory and observed binding affinities.

Eq.~(\ref{eq:intra-zu-def}) describes the intramolecular configurational partition functions $z_{R(v)}$ and $z_{L(v)}$ for the receptor $R$ and ligand $L$. The intramolecular configurational partition function $z_{RL(v)}$ of the complex is similar but the integration is limited to a chosen range of configurations in which receptor and ligand are considered ``bound''. To this end, Gilson et al.~\cite{gilson1997statisticalthermodynamic} introduced an indicator function $I(\zeta)$ equal to one when the six degrees of freedom of the complex that defines the position and orientation of the ligand relative to the receptor, collectively denoted as $\zeta$, are within the specified range of the bound state and equal to zero otherwise:
\begin{equation}
  z_{RL(v)} = \int dx_R dx_L d\zeta I(\zeta) e^{-\beta \Psi_v(x_R, x_L, \zeta)} \, .
  \label{eq:intra-zRL-def}
\end{equation}

The definition of the bound macrostate of the complex is an essential input of the theory. Unlike bond lengths, bond angles, and dihedral angles, the three degrees of freedom of the complex that correspond to the position of the ligand relative to the receptor are unbounded. Unless their extent is limited in some fashion, the bound state of the complex cannot be distinguished from the unbound state, and their free energy difference will be undefined. For example, it is reasonable to insist that the ligand be close to the receptor in configurations regarded as bound. The definition of the target macrostates is a requirement in many areas of computational chemistry and biophysics, such as when specifying the range of backbone angles to measure the relative population of $\alpha$-helical and $\beta$-strand conformations of peptides.  

Conversely, the value of the binding free energy depends on the chosen structural definition of the bound complex. The relationship between the predictions of this theory and experimental reporters (thermochemical, spectroscopic, inhibition kinetics, and others) of complex formation has been discussed.\cite{gilson1997statisticalthermodynamic,mihailescu2004theory,gallicchio2011recent,simonson2016physical,gallicchio2021comppeptsci} The interpretation of experimental reporters of binding is a complex issue in itself. Still, the consensus is that this theory gives nearly equivalent results when the binding is strong and specific, and the definition of the bound complex covers the major bound poses while excluding obvious unbound configurations. In some cases it is valuable to consider specific definitions of the complex by, for example, restricting the orientation of the ligand to pinpoint the relative contribution of different binding poses.

Eq.~(\ref{eq:DG0-binding-constant-def}) is the basis of a variety of alchemical computational implementations that have have been developed to study molecular binding by alchemical means. Some of these are discussed in Section \ref{subsec:formulations-abfe-rbfe}. Generally, to formulate the statistical mechanics expression of the binding constant Eq.~(\ref{eq:DG0-binding-constant-def}) as an ensemble average, we first need to ensure that the configurational integrals in the numerator and denominator are over the same set of degrees of freedom. Note that the intramolecular configurational partition function of the complex, $z_{RL(v)}$, includes six more degrees of freedom--the position and orientation of the ligand relative to the receptor collectively described by the variable $\zeta$--than the product of the intramolecular partition functions, $z_{R(v)} z_{L(v)}$, of the separated receptor and ligand. To correct this discrepancy, we multiply and divide the right-hand side of Eq.~(\ref{eq:DG0-binding-constant-def})  by the quantity
\begin{equation} \label{eq:Vsite-def}
    V_{\rm site} \Omega = \int d\zeta I(\zeta) \, ,
\end{equation}
which measures the extent of the binding pose macrostate, where $V_{\rm site}$ corresponds to the spatial extent and $\Omega$ the orientational extent. The right-hand side of Eq.~(\ref{eq:Vsite-def}) combined with the integrals $z_{R(v)}$ and $z_{L(v)}$ yields a partition function similar to Eq.~(\ref{eq:intra-zRL-def}) but corresponding to a complex in which ligand and receptor are uncoupled~\cite{gallicchio2011recent} as if they were at infinite distance apart. The result is
\begin{equation}\label{eq:DG0-binding-constant-def-average}
  K_b = C^\circ V_{\rm site} \frac{\Omega}{8 \pi^2} \langle e^{-\beta \Delta \Psi}  \rangle_0
\end{equation}
where, similarly to Eq.~(\ref{eq:zratio-solv-average}),
\begin{equation}\label{eq:pert-energy-def}
  \Delta \Psi(x_R, x_L, \zeta) =  \Psi_v(x_R, x_L, \zeta) - \left[  \Psi_v(x_R) + \Psi(x_L) \right]
\end{equation}
is the solvent-averaged binding energy of the complex when receptor and ligands are in intramolecular configurations $x_R$ and $x_L$, the ligand is in position and orientation $\zeta$ relative to the receptor (the uncoupled potential energy does not depend on  the position and orientation of the ligand relative to the receptor), and $\langle \ldots \rangle_0$ represents an ensemble average in the uncoupled ensemble. Finally, note that $\Omega = 8 \pi^2$ when the binding pose indicator function does not depend on the orientation of the ligand and Eq.~(\ref{eq:DG0-binding-constant-def-average}) simplifies to
\begin{equation}\label{eq:DG0-binding-constant-def-average-noOmega}
K_b = C^\circ V_{\rm site} \langle e^{-\beta \Delta \Psi}  \rangle_0 
\end{equation}
which, expressed in free energy units, yields
\begin{eqnarray}\label{eq:DG0-def-Vsite}
  \Delta G^\circ_b &=&  - k_B T \ln K_b = - k_B T \ln C^\circ V_{\rm site} - k_B T \ln \langle e^{-\beta \Delta \Psi}  \rangle_0 \nonumber \\
{\rm \ }  &=& \Delta G^\circ_{b,{\rm ideal}} + \Delta G_{b,{\rm exc.}}
\end{eqnarray}

The term $\Delta G^\circ_{b,{\rm ideal}} = - k_B T \ln C^\circ V_{\rm site}$ in Eq.~(\ref{eq:DG0-def-Vsite}) is interpreted as the \emph{ideal} component of the standard binding free energy, the binding free energy that would be observed in the absence of molecular interactions. Conversely, the term $\Delta G_{b,{\rm exc.}} = - k_B T \ln \langle e^{-\beta \Delta \Psi}  \rangle_0 $ is the \emph{excess} component that depends on the specific molecular composition of the system and on the corresponding interactions. The excess component is the target of the alchemical molecular simulations discussed here, in contrast to the ideal term that is generally evaluated analytically~\cite{boresch2003absolute}.

Eq~(\ref{eq:DG0-binding-constant-def-average-noOmega}) instructs to collect samples of the solvent-averaged binding energy $\Delta \Psi$ in the ensemble where ligand and receptor are not interacting. This can be done directly for simple solutes when the solvent is modeled implicitly.\cite{gallicchio2014virtual} However, with explicit solvation specialized techniques are required. We will discuss two: Double-Decoupling and Alchemical Transfer in section \ref{subsec:formulations-abfe-rbfe}.


\subsection{Simulating binding events is computationally expensive}

The appeal of alchemical approaches to study binding can be best appreciated by considering the alternative of evaluating the binding constant directly from the law of mass action definition
\begin{equation}\label{eq:law-mass-action}
 K_b = C^{\circ}\frac{[RL]}{[L][R]},
\end{equation}
where $[RL]$, $[L]$, and $[R]$ are the equilibrium concentrations of complex, ligand, and receptor, respectively, by, for example, monitoring the relative population $P(RL)/P(R+L)$ of bound and unbound configurations in molecular dynamics simulations.~\cite{jong2011determining,pan2017quantitative}

The computational protocol based on this idea can be formally derived from Eq.~(\ref{eq:DG0-binding-constant-def}) by multiplying and dividing it by
\begin{equation}
z_v = \int dx_R dx_L d\zeta e^{-\beta \Psi_v(x_R, x_L, \zeta)}
\end{equation}
that, because, unlike Eq.~(\ref{eq:intra-zRL-def}), the position of the ligand is not limited by the indicator function, corresponds to a system in which the ligand $L$ is freely moving in a box of solvent of volume $V$ containing the receptor $R$. The ratio between $z_{RL(v)}$ and $z_v$ is the ensemble average of $I(\zeta)$ or the probability $P(RL)$ that $L$ is in the binding site of the receptor $R$. To measure the probability $P(R+L)$ of the $R+L$ unbound state, we consider an indicator function $I_{\mathrm{out}}(\zeta)$ which is one when the ligand, as measured from the center of mass position for example, is far away from the receptor. The volume of the far away region is
\begin{equation}
8 \pi^2 V_{\mathrm{out}} = \int d\zeta I_{\mathrm{out}}(\zeta)
\end{equation}
where the $8 \pi^2$ term comes from the integration of the ligand's orientations not limited by $I_{\mathrm{out}}(\zeta)$. Next, multiply the ratio $z_{R(v)} z_{L(v)}/z_v$ by $\int d\zeta I_{\mathrm{out}}(\zeta)$ and divide it by $8 \pi^2 V_{\mathrm{out}}$ yielding
\begin{equation}
K_b = C^\circ V_{\mathrm{out}} \frac{P(RL)}{P(R+L)}
\end{equation}
where we have used the identity
\begin{equation}
P(R+L) = \langle I_{\mathrm{out}}(\zeta) \rangle_v = \frac{\int dx_R dx_L d\zeta I_{\mathrm{out}}(\zeta) e^{-\beta \Psi_v(x_R, x_L, \zeta)}}{\int dx_R dx_L d\zeta e^{-\beta \Psi_v(x_R, x_L, \zeta)}} \, .
\end{equation}

While simulating explicit binding events has been used to estimate binding constants~\cite{jong2011determining,pan2017quantitative} or to get insights into the binding pathways and kinetics of receptor-ligand systems~\cite{teo2016adaptive,votapka2017seekr,doerr2014onthefly,plattner2015protein,dixon2018predicting}, the computational cost of these calculations is usually dominated by the rate of dissociation, which can be on the microsecond timescale even for millimolar binders~\cite{pan2017quantitative} and reaches the microsecond to second timescale for a typical drug~\cite{basavapathruni2012conformational,hyre2006cooperative}.
Depending on system size and simulation settings, common molecular dynamics software packages can reach a few hundreds of ns/day using currently available high-end GPUs~\cite{eastman2017openmm,kutzner2019more}, making these type of calculations unappealing and irrelevant on a pharmaceutical drug discovery timescale.
Other methods compute the free energy of binding by building potential of mean force profiles along a reaction coordinate~\cite{woo2005calculation,velez-vega2013overcoming,limongelli2013funnel,heinzelmann2017attachpullrelease}, but these methods require prior knowledge of a high-probability binding pathway, which is not easily available, especially in the prospective scenarios typical of the drug development process.

Similarly, because of the long time-scale of transition events and the need to observe many events to extract probabilities, it would be very difficult to estimate solvation free energies and solvent partition coefficients by simulating explicitly the motion of solutes in and out of solutions.

\subsection{Alchemical Binding Free Energy Methods Formulations}
\label{subsec:formulations-abfe-rbfe}

\subsubsection{Absolute binding free energy (ABFE)}

In the alchemical literature, the term ``absolute binding free energy'' is another name for the standard binding free energy $\Delta G^\circ_b = - k_B T \ln K_b$. Here, we discuss two methods, Double-Decoupling (DDM) and Alchemical Transfer (ATM), used to evaluate it by alchemical computer simulations.

\paragraph{Double Decoupling}

The double-decoupling formula is derived from the statistical mechanics theory
by inserting the definition of the solvent potential of mean force [Eq.~(\ref{eq:solvent-pmf-def})] in each of the configurational partition functions in  Eq.~(\ref{eq:DG0-binding-constant-def}). For example, after expanding the solvent potential of mean force, the configurational partition function of the complex becomes
\begin{equation}\label{eq:partfunct-ratio-explsolv-1}
z_{RL(v)} = \frac{Z_{N_v, RL}}{Z_{N_v}}
\end{equation}
where
\begin{equation}\label{eq:partfunct-ratio-explsolv-2}
Z_{N_v, RL} = \int d\vec{r}_v dx_R dx_L d\zeta I(\zeta) e^{-\beta U(x_R, x_L, \zeta, \vec{r}_v)}
\end{equation}
is the configurational partition function of the complex in a fixed position and orientation in $N_v$ solvent molecules, and $Z_{N_v}$ is the configurational partition function of the pure solvent. This process leads to an expression for the binding constant in terms of products of ratios of partition functions analogous to those encountered in Section \ref{sec:theory-solvation} to model solvation
\begin{equation}
  K_b = \frac{C^\circ}{8 \pi^2} \frac{Z_{N_v,RL}}{Z_{N_v,R} z_{L(g)}} \frac{Z_{N_v} z_{L(g)}}{Z_{N_v,L}}
  \label{eq:ddm-ratios-1}
\end{equation}
where we multiplied and divided by the internal configurational partition function of the ligand in vacuum
\begin{equation}
z_{L(g)} = \int dx_L e^{-\beta U(x_L)}
\end{equation}
We recognize that the second ratio of partition functions in Eq.~(\ref{eq:ddm-ratios-1}) is the inverse of Eq.~(\ref{eq:zratio-solv-average}), hence it is related to the free energy $\Delta G_1$ of decoupling the ligand from the solvent
\begin{equation}
\frac{Z_{N_v} z_{L(g)}}{Z_{N_v,L}} = \langle e^{\beta \Delta U}  \rangle_{L(v)} = e^{-\beta \Delta G_1}
\end{equation}
where $\Delta U$ is the coupling energy between the ligand and the solvent and $\langle \ldots \rangle_{L(v)}$ is an average over the ligand solution ensemble [see Eq.~(\ref{eq:zratio-solv-dgexc})].
The ratio of partition functions in Eq.~(\ref{eq:ddm-ratios-1}) involving the ligand-receptor complex is expressed as an ensemble average by multiplying it and dividing it by Eq.~(\ref{eq:Vsite-def}) in the same way that Eq.~(\ref{eq:DG0-binding-constant-def}) is cast as Eq.~(\ref{eq:DG0-binding-constant-def-average}). The result is the ratio of the partition functions of the complex in solvent, $Z_{N_v,RL}$, and the partition function $Z_{N_v,R + L(g)}$  of the same system when the ligand is decoupled from the
receptor and the solvent but is restrained into the binding site region ($I(\zeta) = 1$)
\begin{equation}
\frac{Z_{N_v,RL}}{Z_{N_v,R+L} z_{L(g)}} = \frac{8 \pi^2 V_{\rm site} Z_{N_v,RL}}{Z_{N_v,R+L(g)}} = 8 \pi^2 V_{\rm site} \langle e^{\beta \Delta U}  \rangle_{RL(v)} = e^{\beta \Delta G_2}
\end{equation}
Collecting the terms, the double-decoupling standard binding free energy is finally expressed as
\begin{equation}\label{eq:ddm-dg1-dg2}
\Delta G^\circ_b = -k_B T \ln K_b = -k_B T \ln C^\circ V_{\rm site} + (\Delta G_1 - \Delta G_2)
\end{equation}
which includes the ideal term [see Eq.~(\ref{eq:DG0-def-Vsite})], and the difference of decoupling free energies of the ligand from the solvent and from the binding site of the receptor in solution. As illustrated in Figure \ref{fig:fig_absolute_thermodynamic_cycle}, the decoupling free energies are commonly computed in separate simulations using the alchemical techniques discussed in the following sections.

\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/fig5_thermo_cyc_abs/Figure.png}
    \caption{\textbf{Thermodynamic cycle for an absolute binding free energy calculation with auxiliary restraints} The fully interacting ligand in water (\textbf{A}), has its charges turned off to pass to (\textbf{B}) followed by turning off van der Waals terms, resulting in a non-interacting ligand in water (\textbf{C}). The receptor-ligand complex (\textbf{D}) is defined by binding site restraints (dotted oval). Auxiliary restraints are often introduced (\textbf{E}) to improve convergence while the charges and van der Waals interactions are turned off (\textbf{F} and \textbf{G}). The free energy cost of releasing the auxiliary restraints (\textbf{G} to \textbf{H}) and transferring the non-interacting ligand from the standard state volume to the binding site (\textbf{C} to \textbf{H}) must be accounted for. The standard binding free energy is computed from this cycle as $\Delta G^{\circ}_{\mathrm{bind}} = (\Delta G^{\mathrm{elec}}_{\mathrm{solv}}+ \Delta G^{\mathrm{VdW}}_{\mathrm{solv}}) + \Delta G^{\circ}_{\mathrm{ideal}} -(\Delta G_{\mathrm{aux.restr.}}+\Delta G^{\mathrm{elec}}_{\mathrm{bound}}+ \Delta G^{\mathrm{VdW}}_{\mathrm{bound}}+\Delta G_{\mathrm{release}})$. Many variations of the route between the free (\textbf{A}) and bound (\textbf{D}) states can be used -- for example, state \textbf{H} is commonly skipped and the free energy cost of moving from \textbf{C} to \textbf{G} is calculated directly.}
    \label{fig:fig_absolute_thermodynamic_cycle}
\end{figure}


\paragraph{Alchemical Transfer}

In the alchemical transfer approach, the standard binding free energy is obtained by a coordinate translation that brings the ligand from the solvent to the receptor binding site~\cite{wu2021alchemical} rather than by decoupling it from the system, as in the double-decoupling method. The method derives from Eq.~(\ref{eq:DG0-binding-constant-def}) by inserting the solvent degrees of freedom similarly to the double-decoupling method, except that the product $z_{R(v)} z_{L(v)}$ of partition functions of the unbound state is represented collectively as one explicit solvent system in which the ligand is placed in a region spanned by an indicator function $I^\ast(\zeta)$ identical to the one used to define the binding site region but placed at some arbitrarily large distance from the receptor:
\begin{equation}
  z_{R(v)} z_{L(v)} =
  \frac{
    \int d\vec{r}_v dx_R dx_L d\zeta I^\ast(\zeta) e^{-\beta U(x_R, x_L, \zeta, \vec{r}_v)}
  }{
    8 \pi^2 V_{\rm site} Z_{N_v}
  }
\end{equation}
where, as above, we multiplied and divided by the volume of the binding site, assuming for simplicity that the indicator function does not depend on the orientational degrees of freedom of the ligand. Combining this result with Eq.~(\ref{eq:partfunct-ratio-explsolv-1}) for the complex and canceling the common partition function of the pure solvent, leads with Eq.~(\ref{eq:DG0-binding-constant-def})  to an expression for the binding constant in terms of ratios of partition functions in explicit solvent that differ only by the location of the indicator function (in the binding site or in the solvent region):
\begin{equation}\label{eq:atm-partfunc-ratio}
  K_b = C^\circ V_{\rm site} \frac{
    \int d\vec{r}_v dx_R dx_L d\zeta I(\zeta) e^{-\beta U(x_R, x_L, \zeta, \vec{r}_v)}
  }{
    \int d\vec{r}_v dx_R dx_L d\zeta I^\ast(\zeta) e^{-\beta U(x_R, x_L, \zeta, \vec{r}_v)}
  }
\end{equation}
The idea of alchemical transfer, illustrated in Figure \ref{fig:atm-illustration}A, is to cast Eq.~(\ref{eq:atm-partfunc-ratio}) as an ensemble average by a change of coordinates noting that $I(\zeta) = I^\ast(\zeta - \vec{h})$ where $\vec{h}$ is the fixed vector distance between the binding site and solvent locations spanned by the two indicator functions. The symbol $\zeta$ represents the position and orientation of the ligand relative to the receptor, so here $\zeta - \vec{h}$ is the operation of shifting the position of the ligand by the displacement $\vec{h}$ without changing its orientation. Hence, by applying the change of variable $\zeta \rightarrow \zeta - \vec{h}$ to the integral in the numerator of Eq.~(\ref{eq:atm-partfunc-ratio}), we arrive at the following expression for the binding constant, equivalent to Eq.~(\ref{eq:DG0-binding-constant-def-average-noOmega}):
\begin{equation}\label{eq:atm-average-abfe}
K_b = C^\circ V_{\rm site} \langle e^{-\beta \Delta U} \rangle_0
\end{equation}
where
\begin{equation}\label{eq:atm-deltaU-def}
\Delta U(x) = U(x_R, x_L, \zeta + \vec{h}, \vec{r}_v) - U(x_R, x_L, \zeta, \vec{r}_v)
\end{equation}
is the perturbation energy of the method, and the ensemble average $\langle \ldots \rangle_0$ is over the unbound ensemble when the ligand is limited to the solvent region far away from the receptor. Eq.~(\ref{eq:atm-average-abfe}) instructs to simulate the unbounded system where the ligand is limited to a region in the solvent and to sample the change of potential energy $\Delta U$ resulting from transferring the ligand from the solvent to the receptor binding site by a fixed displacement of the ligand as a whole.

While Eq.~(\ref{eq:atm-average-abfe}) is formally rigorous, it is numerically necessary to divide the alchemical transfer ABFE calculation in explicit solvent into two legs~\cite{wu2021alchemical,azimi2022relative} that connect the unbound and bound states by a suitable alchemical intermediate state. Current implementations use an alchemical intermediate state midway between the bound and unbound states with the symmetric hybrid potential energy function
\begin{equation}\label{eq:atm-intermediate-pot}
U_{1/2}(x) = \frac12 [ U(x_R, x_L, \zeta + \vec{h}, \vec{r}_v) + U(x_R, x_L, \zeta, \vec{r}_v)  ] 
\end{equation}
To include the alchemical intermediate, Eq.~(\ref{eq:atm-partfunc-ratio}) is multiplied and divided by the partition function of the system with the hybrid potential energy function in Eq.~(\ref{eq:atm-intermediate-pot}), each serving as the sampling state for each leg. The expression for the binding constant becomes a ratio of ensemble averages
\begin{equation}\label{eq:atm-average-abfe-intermediate}
  K_b = C^\circ V_{\rm site} \frac{
    \langle e^{-\beta \Delta U_1} \rangle_{1/2}
  }{
    \langle e^{-\beta \Delta U_2} \rangle_{1/2}
  }
\end{equation}
where $\Delta U_1$ and $\Delta U_2$ are the perturbation energies of the bound and unbound states relative to the alchemical intermediate. For example,
\begin{equation}
\Delta U_1(x) = U(x_R, x_L, \zeta + \vec{h}, \vec{r}_v) - U_{1/2}(x)
\end{equation}
Setting,
\begin{equation}
\Delta G_1 = -k_B T \ln \langle e^{-\beta \Delta U_1} \rangle_{1/2}
\end{equation}
and similarly for the second leg, we recover Eq.~(\ref{eq:ddm-dg1-dg2}) obtained for double-decoupling. This shows that, while the thermodynamic path and the meaning of the $\Delta G_1$ and $\Delta G_2$ free energy components differ, the double-decoupling and alchemical transfer formulations both connect the unbound and bound states through an auxiliary intermediate state: the ligand decoupled state for double-decoupling, and the symmetric alchemical intermediate for alchemical transfer.~\cite{azimi2025potential} However, alchemical transfer simulates both legs with a single simulation system, while double-decoupling accomplishes them in separate simulations.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.95\linewidth]
    {figures_atm/atm_scheme_abfe_rbfe.pdf}
    \caption{\small Alchemical transfer method illustrated for (\textbf{A}) Absolute Binding Free Energy (ABFE) and (\textbf{B}) Relative Binding Free Energy (RBFE) calculations. In (A), the receptor (blue) is shown with the ligand in bulk solvent being translated to the active site along a vector $+h$. In (B), the RBFE setup is shown with two ligands: one in the binding site and the other in bulk solvent. A vector $h$ separates the ligands, and the perturbation energy is evaluated by virtually swapping their positions at each MD step.}
    \label{fig:atm-illustration}
\end{figure}

\subsubsection{Relative binding free energy (RBFE)}

In many cases, the quantity of interest is the change in binding affinity $\Delta \Delta G_b$ between a compound $A$ and a related compound $B$ (e.g., by modifying one of the drug scaffold's substituents, see (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{E})) for the same receptor. If the ligands are sufficiently similar, evaluating the Relative Binding Free Energy (RBFE) is often more convenient than taking the difference of their ABFEs. Formally, these approaches seek to compute the ratio $K_b(B)/K_b(A)$ of the binding constants of the two ligands rather than each binding constant individually. Here we present an RBFE formulation based on the double-decoupling ABFE approach, which we call double-transformation, and the RBFE formulation based on alchemical transfer.

\paragraph{Double Transformation for RBFE estimation}

To derive an RBFE formulation from double-decoupling, we write expressions for the binding constants of $A$ and $B$ using Eq.~(\ref{eq:ddm-ratios-1}) and taking their ratio. While doing so, the standard state, pure solvent, and gas-phase terms cancel, and we obtain
\begin{equation}\label{eq:double-transformation-Kb-rbfe}
\frac{K_b(B)}{K_b(A)} = \frac{Z_{N_v,RB}}{Z_{N_v,RA}} \frac{Z_{N_v,A}}{Z_{N_v,B}}
\end{equation}
where the first ratio of partition functions involves receptor-ligand complexes and the second only the ligands in solution. Eq.~(\ref{eq:double-transformation-Kb-rbfe}), suggests that the relative binding free energy, $\Delta \Delta G_b$, of $B$ relative to $A$ can be expressed as the difference of the free energies, $\Delta G_{\rm bound}$ and $\Delta G_{\rm unbound}$, of ``mutating'' ligand $A$ into ligand $B$ in the presence and absence of the receptor, respectively (Figure \ref{fig:fig_binding_thermodynamic_cycle}):~\cite{tembre1984ligandreceptor,gilson1997statisticalthermodynamic,mobley2012perspective,cournia2017relative,jiang2019computing,lee_jcheminfmodel_2020_v60_p5595}
\begin{equation}\label{eq:double-transformation-dg-rbfe}
\Delta \Delta G_b = -k_B T \ln \frac{Z_{N_v,RB}}{Z_{N_v,RA}} - (-k_B T \ln \frac{Z_{N_v,B}}{Z_{N_v,A}}) = \Delta G_{\rm bound} - \Delta G_{\rm unbound}
\end{equation}

In practice, each partition function ratio must first be converted into an ensemble average to be evaluated. Similar to the preceding case, this step requires manipulating the integrals so that they are carried over the same set of degrees of freedom. As discussed in Section \ref{sec:relative-fe-protocol}, this step involves using alchemical topologies that can describe both ligands. For example, among other features, alchemical topologies include atoms common to both ligands and dummy atoms that exist in one but not in the other ligand (Figure \ref{fig:fig_topology}). A key aspect of constructing a suitable alchemical topology is the requirement that the additional degrees of freedom do not affect the RBFE estimate.

In the dual coordinate dual topology method (discussed in Section \ref{sec:relative-fe-protocol}), which is helpful for pairs of compounds that do not share the same scaffold, all atoms of both ligands are present but intermolecular interactions between the two ligands are turned off, and the partition functions in Eq.~(\ref{eq:double-transformation-dg-rbfe}) differ in which ligand is coupled to the system. An example of this formulation is the Separated Topologies (SepTop) approach~\cite{rocklin2013separated,baumann2023broadening}, which decouples one ligand as the coupling of the second is turned on. Additionally, the SepTop approach can estimate the relative binding free energies of pairs of ligands that do not share the same binding pose by employing different binding site indicator functions in the definitions of the partition functions of the complexes, $Z_{N_v,RA}$ and $Z_{N_v,RB}$, in Eq.~\ref{eq:double-transformation-dg-rbfe}.

\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/fig2_therm_cyc/Figure.pdf}
    \caption{{\bf Thermodynamic cycle for computing the relative free energy of binding ($\Delta \Delta G$) between two related small molecules to a supramolecular host or a rigid receptor.}
    The relative binding free energy difference between two small molecules, $\Delta \Delta G_{\mathrm{bind}, A \rightarrow B} \equiv \Delta G_{\mathrm{bind}, B} - \Delta G_{\mathrm{bind}, A}$---here benzyl alcohol (top) to toluene (bottom)---can be computed as a difference between two alchemical transformations, $\Delta G_\mathrm{bound} - \Delta G_\mathrm{solvated}$, where $\Delta G_\mathrm{bound}$ represents the free energy change of transforming $A \rightarrow B$ in complex, i.e. bound to a host molecule, and $\Delta G_\mathrm{unbound}$ the free energy change of transforming $A \rightarrow B$ in solvent, typically water.}
    \label{fig:fig_binding_thermodynamic_cycle}
\end{figure}

\paragraph{Alchemical Transfer for RBFE Estimation}

The RBFE alchemical transfer formulation follows closely the ABFE formulation. Similar to the dual coordinate dual topology method, the simulation system includes both ligands, one in solution and the other in the binding site, and the coordinate transformation involves displacing them in opposite directions so that they switch places. Formally,~\cite{azimi2022relative} the method derives from Eq.~(\ref{eq:DG0-binding-constant-def}) for each binding constant
\begin{equation}
\frac{K_b(B)}{K_b(A)} = \frac{z_{RB(v)} z_{A(v)}}{z_{B(v)} z_{RA(v)}}
\end{equation}
and noting that the numerator represents a system with $B$ bound and $A$ unbound, and in the denominator, the roles are switched. Next, the solvent PMF is used to indicate the solvent degrees of freedom explicitly, and the indicator functions $I^\ast(\zeta_A)$ and $I^\ast(\zeta_b)$ are introduced to keep the unbound ligands in the solvent, similarly to Eq.~(\ref{eq:atm-partfunc-ratio}). The result is
\begin{equation}\label{eq:atm-partfunc-ratio-rbfe-1}
  \frac{K_b(B)}{K_b(A)} = \frac{
    \int d\vec{r}_v dx_R dx_A d\zeta_A dx_B d\zeta_B I^\ast(\zeta_A) I(\zeta_B)  e^{-\beta U(x_R, x_A, \zeta_A, x_B, \zeta_B, \vec{r}_v)}
  }{
    \int d\vec{r}_v dx_R dx_A d\zeta_A dx_B d\zeta_B I(\zeta_A) I^\ast(\zeta_B)  e^{-\beta U(x_R, x_A, \zeta_A, x_B, \zeta_B, \vec{r}_v)}
  }
\end{equation}
where $x_A$ and $x_B$ are the internal coordinates of the ligands and $\zeta_A$, $\zeta_B$ are their external coordinates relative to the receptor.  Next we apply the change of variables $\zeta_B \rightarrow \zeta_B + \vec{h}$ and $\zeta_A \rightarrow \zeta_A - \vec{h}$ to the partition function in the numerator to obtain
\begin{equation}\label{eq:atm-partfunc-ratio-rbfe-2}
  \frac{K_b(B)}{K_b(A)} = \frac{
    \int d\vec{r}_v dx_R dx_A d\zeta_A dx_B d\zeta_B I(\zeta_A) I^\ast(\zeta_B)  e^{-\beta U(x_R, x_A, \zeta_A + \vec{h}, x_B, \zeta_B - \vec{h}, \vec{r}_v)}
  }{
    \int d\vec{r}_v dx_R dx_A d\zeta_A dx_B d\zeta_B I(\zeta_A) I^\ast(\zeta_B)  e^{-\beta U(x_R, x_A, \zeta_A, x_B, \zeta_B, \vec{r}_v)}
  }
\end{equation}
which can be written as an ensemble average
\begin{equation}\label{eq:atm-partfunc-ratio-rbfe-average}
\frac{K_b(B)}{K_b(A)} = \langle e^{-\beta \Delta U}\rangle_{RA+B}
\end{equation}
where
\begin{equation}\label{eq:atm-partfunc-ratio-rbfe-pert}
\Delta U = U(x_R, x_A, \zeta_A + \vec{h}, x_B, \zeta_B - \vec{h}, \vec{r}_v) - U(x_R, x_A, \zeta_A, x_B, \zeta_B, \vec{r}_v)
\end{equation}
is the perturbation energy for displacing the two ligands in opposite directions, and the ensemble average $\langle \ldots \rangle_{RA+B}$ is carried out with $A$ bound and $B$ in the solvent. Except for the coordinate displacement, Eq.~(\ref{eq:atm-partfunc-ratio-rbfe-average}) is implemented similarly to the alchemical transfer ABFE protocol, including the use of the symmetric alchemical intermediate as in Eq.~(\ref{eq:atm-average-abfe-intermediate}).

\subsection{Numerical Implementations of Alchemical Transformations}
\label{subsec:numerical-implementations}

\paragraph{How are alchemical transformations performed in practice?}

As discussed below, because of poor ensemble overlap, in most cases of interest, alchemical free energy calculations cannot be carried out directly by ensemble averages collected only at the reference or target states. Instead, in a process called stratification,~\cite{chipot2007free} we take advantage of the state function property of the free energy and break up the transformation into a series of manageable steps, distributed along an alchemical pathway, whose combination is equivalent to the desired transformation (see Section \ref{sec:important_path}). Intermediate alchemical states are typically defined in terms of one or more alchemical progress parameters $\vec{\lambda}$ controlling the potential energy function $U(\vec{q};\vec{\lambda})$ such that the potential energies of the initial and final states are recovered at two particular values $\vec{\lambda}_0$ and $\vec{\lambda}_1$.

In the case of a relative binding free energy calculation, for example, this might be achieved by simulating a ``chimeric'' molecule composed of enough atoms to represent both $A$ and $B$. A subset of the energetic terms in $U(\vec{q};\vec{\lambda})$ is then modulated by $\vec{\lambda}$ so that at $\vec{\lambda}_A$, the atoms that form molecule $A$ are activated and those belonging exclusively to $B$ are non-interacting ``dummy atoms'', while the opposite occurs at $\vec{\lambda}_B$ (see Sec.~\ref{sec:relative-fe-protocol} for details).

We can rigorously account for fluctuations in other thermodynamic parameters such as changes in volume $V$ when simulating at constant pressure $p$ or changes in number of molecules $N_i$ of species $i$ at constant chemical potential $\mu_i$ (e.g., number of waters or ions) by introducing the \textit{reduced potential}~\cite{shirts2008statisticallya}
\begin{equation}\label{eq:reduced-potential}
u(\vec{q};\vec{\lambda}) \equiv \beta \left[ U(\vec{q};\vec{\lambda}) + p \, V(\vec{q}) + \sum_i \mu_i \, N_i(\vec{q}) + \cdots \right] \, .
\end{equation}
Here, the collection of thermodynamic and alchemical parameters $\{\beta, \vec{\lambda}, p, \mu, \ldots\}$ defines a \emph{thermodynamic state}.
In the context of alchemical calculations, in which the thermodynamic states vary only in their value of $\vec{\lambda}$, these are also referred to as \emph{alchemical states}.
The free energy of mutating $A$ to $B$ in any environment ($\Delta G_{\mathrm{env}}$ e.g., binding site, solvent) can then be computed as
\begin{equation}\label{eq:delta-G-env}
    \Delta G_{\mathrm{env}} = - k_BT \ln \frac{Z(\vec{\lambda}_B)}{Z(\vec{\lambda}_A)} = - k_BT \ln \frac{\int_{\Gamma_{\mathrm{env}}} \exp\left( u(\vec{q}; \vec{\lambda}_B) \right) \, d\vec{q}}{\int_{\Gamma_{\mathrm{env}}} \exp\left( u(\vec{q}; \vec{\lambda}_A) \right) \, d\vec{q}} \, ,
\end{equation}
over the configurational space of the environment ($\Gamma_{\mathrm{env}}$).
While it is generally not feasible to compute the two partition functions $Z(\vec{\lambda})$, several estimators have been devised to robustly estimate the ratio of partition functions in Eq.~\ref{eq:delta-G-env} (see Sec.~\ref{subsec:estimators}) from a set of configurations usually collected with MD simulations from the thermodynamic states defined at $\vec{\lambda}_A$ and $\vec{\lambda}_B$ and intermediates thereof.

\paragraph{Why do alchemical calculations need unphysical intermediate states?}
While it is theoretically possible to estimate the ratio of partition functions from samples collected only at states $\vec{\lambda}_A$ and $\vec{\lambda}_B$, the efficiency of the free energy estimators rapidly decreases as the phase-space overlap between the two states also decreases~\cite{wu2005phasespace, wu2005phasespacea}.
Roughly, the phase-space overlap between two thermodynamic states measures the degree to which high-probability configurations (i.e., those with very negative potential energy) in one state are also high-probability configurations in the other state (see Sec.~\ref{sec:are-they-good} and Fig.~\ref{fig:fig_what_is_lambda}).

Equilibrium free energy calculations, our focus here, solve the problem of having poor overlap between the states of interest by introducing multiple intermediate alchemical states at values $\vec{\lambda}_A = \vec{\lambda}_0, \vec{\lambda}_1, \cdots, \vec{\lambda}_K = \vec{\lambda}_B$ so that each pair of consecutive states $\vec{\lambda}_k, \vec{\lambda}_{k+1}$ share good overlap.
Each intermediate state models a ligand that is neither $A$ nor $B$ but a interpolation of the two.
Many estimators (e.g., exponential reweighting (EXP)~\cite{zwanzig1954hightemperature} and Bennett's acceptance ratio (BAR)~\cite{bennett1976efficient,shirts2003equilibrium}) can then be used to compute the free energy as
\begin{equation}
    \Delta G_{\mathrm{env}} = k_BT \sum_{k=0}^{K-1} \Delta f(\vec{\lambda}_k, \vec{\lambda}_{k+1}),
\end{equation}
from samples collected at all the alchemical states $\{\vec{\lambda}_k \}$, where $\Delta f$ is the \emph{unitless free energy difference}
\begin{equation}
    \Delta f(\vec{\lambda}_k, \vec{\lambda}_{k+1}) = f(\vec{\lambda}_{k+1}) - f(\vec{\lambda}_k) = - \ln \frac{Z(\vec{\lambda}_{k+1})}{Z(\vec{\lambda}_k)} \, .
\end{equation}
While this strategy usually results in sampling thermodynamic states whose Boltzmann distributions are very similar, thus collecting information that is to some degree redundant, some estimators, such as the Multistate Bennett acceptance ratio (MBAR)~\cite{shirts2008statisticallya}, can exploit similarities between states to improve the precision of the estimates. This is achieved by using the configurations sampled at all alchemical states $\{\vec{\lambda}_k \}$ to compute the free energy difference $\Delta f(\vec{\lambda}_i, \vec{\lambda}_{j})$ between any pair of states $i,j$ (see Sec.~\ref{subsec:estimators}).

Non-equilibrium free energy techniques provide an alternate approach to this problem, driving $\lambda$ between states (see Sec.~\ref{sec:sampling_schemes}).~\cite{jarzynski1997nonequilibrium,jarzynski1998equilibrium,crooks2000pathensemble, gapsys2020large}

\paragraph{How do absolute free energy calculations differ from relative?}

While absolute and relative free energy calculations have subtle differences in their practical applications (e.g., use of restraints, handling of the standard state), the fundamental ideas and concepts of relative free energy approaches remain unaltered in other types of alchemical calculations.
Absolute binding, hydration, and partition free energies still use thermodynamic cycles that enable computing transfer free energies without actually simulating the physical transfer from one environment to another.

The main difference in these approaches lies instead in the thermodynamic cycle to which this strategy is applied.
For example, a typical thermodynamic cycle for an alchemical absolute binding free energy calculation is represented in Fig.~\ref{fig:fig_absolute_thermodynamic_cycle}.
In this case, two independent calculations compute the free energy of removing the interactions between the ligand and its environment in solvent or in the binding site respectively through a series of intermediate states in which the energy terms are only partially deactivated.




%%%%%%%%%%%%
% Step 0   %
%%%%%%%%%%%%
\section{What can be expected from alchemical simulations?}
\label{sec:step0}
When starting an alchemical free energy project, a key first step is to decide whether free energy calculations are really the right tool. Particularly, count the cost of your
project: Can you even hope to tackle the problem with available resources and, if successful, will it
be worth it in terms of human and computational cost?

\subsection{How accurate are alchemical free energy calculations?}
\label{subsec:expectation}
We first note that the accuracy of any free energy calculation method will depend on the quality of the underlying force field.  Therefore, any description of the force field for the molecules under study must be carefully checked to be sufficiently accurate to experiment. In particular, one must make sure that if using automatically generated molecular descriptions from either one's own workflow or some other computational chemistry program, there are no obvious problems in these files either through errors in the workflow, or lack of chemical coverage in the data used to construct the molecular description. Torsional parameters, in particular can be misassigned or improperly parameterized. 

Alchemical free energy calculations involving small molecules seem to achieve, in favorable cases, root mean square (RMS) errors relative to experiment around 1-2 kcal/mol depending on force field, system, and a variety of other factors such as simulation time, sampling method, and whether the calculations employed are absolute or relative. A small selection of example datasets and case studies can be found in Sec.~\ref{sec:benchmark} at the end of this document.
However, the domain of applicability is a significant concern~\cite{sherborne2016collaborating, cournia2017relative}, especially for relative calculations, which typically require a high quality and usually experimental bound structure of a closely
related ligand as a starting point. Additional factors such as slow protein or ligand rearrangements, uncertainties in ligand binding mode, or charged ligands can make these calculations far less reliable and more of a research effort.

It is worth noting that the accuracy of free energy calculations is highly variable across different protein targets, and likely across different ligand chemotypes as well.
For instance, FEP+ with OPLS3 achieves an RMSE of 0.62 kcal/mol for a set of 21 compounds binding to JNK1 kinase, but an RMSE of 1.05 kcal/mol for a set of 34 compounds binding to P38$\alpha$ kinase~\cite{harder2016opls3}.
Furthermore, perturbations for the same chemotype in different pockets of the BACE enzyme gave varied errors~\cite{keranen2017acylguanidine}. Here the errors refer to the difference in $\Delta G$ derived from calculated $\Delta \Delta G$'s while fitting a constant offset to best reproduce the experimental binding free energies for known compounds~\cite{wang2015accurate}. Each $\Delta \Delta G$ is associated with a particular free energy calculation or transformation, which can be thought of as an edge in the graph spanning the compound series, see examples of such graphs in Fig.~\ref{fig:fig_types_of_networks}.

The fact that we can analyze both $\Delta G$ values and $\Delta \Delta G$ values raises an important question about analysis -- which calculated values should we assess? It is important to be clear on what error to report: $\Delta G$ after shifting by a constant to minimize the RMSE, unshifted $\Delta G$, $\Delta \Delta G$ of computed edges, or $\Delta \Delta G$ of all edges. (See recommendations for reporting best practices, Sec.~\ref{sec:plot_data}.) Additionally, as it is possible to perform calculations on a set of ligands using different pairwise comparisons of molecules, the performance of the method may be biased based on which pairs of comparisons are performed. Additionally, it is possible that the error associated with the relative free energy between a two ligands that was not directly computed,  but can be deduced using one or more thermodynamic paths involving other ligands will likely be more uncertain.
Given the need to understand the performance of the system with alchemical free energy calculations, we recommend that retrospective studies for a particular target and a particular chemical series be performed for each application case.

\subsection{How reproducible are alchemical free energy calculations?}
\label{subsec:reproducible}
We restrict our analysis here to repetitions of the same calculation performed with precisely the same force field, as different force fields used to describe the same molecule can lead to wide differences in free energies in some cases.  

Simulations carried out with molecular dynamics or Monte Carlo techniques are fundamentally stochastic calculations, and two simulations can never match exactly.  Even though Newton's equations of motion are deterministic, molecular systems are chaotic, and very small changes, like differences in rounding of floating point numbers due to different software versions or architectures, let alone different random number seeds used to initialize the velocities will lead to different results obtained with each repetition of a simulation. Any sort of agreement will only be up to this stochastic source of uncertainty, and one needs to have an understanding of how accurate one needs comparison to be, as well as a proper handling of statistics to decide if differences in simulations are statistically significant or not.  Because free energy differences are calculated from ensemble averages, collecting more data will result in improved agreement in almost all cases, thanks to the central limit theorem, but the amount of simulation needed to converge to a desired level of statistical precision varies dramatically on the system. So the key consideration is how reproducible alchemical free energy calculations are in practice, and how large a difference between two measurements is required to be scientifically useful.

There are two types of reproducibility that are important to examine.  One is reproducibility between different research groups attempting to reproduce the same results, which is relevant when new users might be trying to see how well their calculations match with published calculations. The second is reproducibility between one researcher running the same calculation, up to differences in starting configurations, multiple times.  This can be particularly relevant in determining the statistical uncertainty of the calculation, as discussed in Sec~\ref{subsec:uncertainty}.

%Even within this restriction, finite computing resources necessarily limit the generated number of uncorrelated samples of potential energy surfaces, and therefore alchemical free energy calculations only give free energy estimates to within finite precision. 

The differences in free energies between different research groups, due to differences in choices of simulation parameters, simulation packages, and analysis treatments can be significant. Issues of reproducibility of free energy calculations across different simulation packages have recently attracted attention ~\cite{loeffler2018reproducibility,rizzi2019sampl6, wade2022, herz2025modular}. Greater variability is expected between simulations carried out between packages, as opposed to ones carried out with the same package, due to methodological differences such as integrators, thermostats, barostats, treatment of long-range electrostatics, and potentially other factors. For absolute and relative hydration free energies of small organic molecules a variability of ca. 0.2 kcal/mol between popular simulation packages has been reported~\cite{loeffler2018reproducibility}. In the recent SAMPL6 SAMPLing challenge a larger variability of 0.3 to 1.0 kcal/mol was noted in the computed absolute binding free energies of host/guest systems even though the study sought to use identical input and simulation parameters~\cite{rizzi2019sampl6} and, in many cases, single-point energies were identical or nearly so.  For more complex use cases such as protein-ligand binding free energies the repeatability is often substantially worse~\cite{rizzi2019sampl6}.   For benchmark simulations of some relative binding free energies, differences of {\color{red}Can we put some more citations here?} 

A different situation is the amount of reproducibility researchers should expect when performing repeated simulations of their own systems, perhaps with the same starting point. In simple cases, such as absolute hydration free energies of small organic molecules, or relative hydration free energy calculations between structurally similar small organic molecules, it should be possible to obtain highly precise estimates with a given software package, i.e., with a sample standard deviation under 0.01 kcal/mol possible~\cite{rizzi2019sampl6}, and agreement under 0.05 kcal/mol routine for simulations lasting 10's of ns~\cite{paliwal2011benchmark} {\color{red}This could use some more citations here from other studies.} However, for complex systems, the reproducibility can be signficantly worse, as two simulation of the same system can explore very different configurational ensembles.  If the timescales of the slow scales of motion are comparable to or longer than the timescales of the simulation, then differences of up to multiple kcal/mol can be possible for absolute and even relative free energy calculations. 

In fact, the amount of reproducibility between repeated calculations is an important measure of whether a particular choices of simulation methods and approaches are appropriate.  Large differences between results carried out with different initial velocities, or better yet started from points along a single initial long simulations can indicate that the sampling of the system is particularly hard and will require additional simulation and/or advances sampling methods.  In fact, journals such as the Journal of Chemical Information and Modeling require that any results be confirmed by simulations run in at least triplicate~\cite{soares2023guidelines}. The question of how to combine results from ensembles of simulations for lowest bias and best reporting of statistical uncertainty are discussed in section~\ref{subsec:uncertainty}.

%MRS: some good points here below, but this isn't the right place, since this is explicitly talking about reproducibility between simulations, i.e. if you run a simulation, how different do you expect it to be. This MOTIVATES a discusion of ensemble averaging in some other section for robustness, but should be  separate sections discussing ensembles vs. simgle trajectories, putting all these differences in the same place, rather than sprinkled throughout.  Also, some of the claims are too broad as stated, and it included information about free energy calculation methods that doesn't fit here. 

%MD trajectories are extremely sensitive to their starting conditions and hence single simulationscan never be reproducible~\cite{coveney2016, MDbook2025, caves_locally_1998}. Thus, it is recommended to perform ensemble simulations in order to perform ensemble averaging to obtain thermodynamic quantities in a reliable manner. Bhati \textit{et al.} developed the TIES method~\cite{bhati2017, bhati2022, bhati2025} which is based on the use of ensemble methods, where the ensemble size can be adjusted based on available computational resource and required precision~\cite{wan2023}. Studies have shown that, in general, an ensemble size of 5 and 10 members is a reasonable starting point for alchemical RBFE and ABFE calculations, respectively, but recommendations are provided to adjust them based on some rules of thumb~\cite{bhati2022, bhati2025}. 


%MRS: Should be in a separate section. 
%The sample standard deviation will give a crude estimate of the reliability of the estimates, and whether the precision is sufficient for the problem at hand.

%To estimate ensemble averages and provide robust error statistics generally three independent repeats of simulations are recommended. In this case a repeat or replica are taken as synonyms. As such other approaches use even larger ensembles of simulations such as in the TIES method~\cite{bhati2017} developed by Bhati et al., where a minimum of 5 to 10 replicas are recommended to make up the ensemble for RBFE and ABFE calculations respectively~\cite{bhati2022, bhati2025}. Typically single free energy differences across multiple replicas are expected to be reproducible within 1 kcal/mol.

% Add something on RBFE calculations across engines.
% I think one of the points here that may be one for the other paper is that we are really just looking at a per edge DDG basis. 
% - https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/684b48f03ba0887c33ef29e7/original/modular-and-interoperable-workflows-for-benchmarking-alchemical-binding-free-energy-calculation-methodologies.pdf
% - other references?

A recent study demonstrates reproducibility across software packages as well as free energy estimators, but only when ensemble simulations are employed~\cite{wade2022}. The authors reported results from two different MD engines (NAMD and OpenMM) as well as two free energy estimators (FEP and MBAR) for a set of 54 protein-ligand complexes which were found to be in good agreement when ensemble simulations were used to control uncertainties. To conclude, ensemble simulations can remove the aleatoric uncertainties in MD based predictions, however, further work is needed to ensure reproducibility across software packages arising due to systematic/parametric uncertainties.

\subsection{Is my problem suitable for alchemical free energy calculations?}
\label{subsec:suitability}
Before even planning free energy calculations to study binding to a
particular target, it is important to assess what is known about the
system and its timescales and its suitability for free energy
calculations, as well as the \emph{purpose} of the calculations and
the amount of available computer resources. In some cases, predicting accurate binding free energies for a particular target might be
\emph{more} challenging than simply measuring them! This is
often the case when dealing with database screening problems, where
compounds might be easily and quickly available commercially for
testing and free energy calculations could consume far more resources. Free energy calculations typically only
appeal when (slow or costly) synthesis would be required or experiments are otherwise cost-prohibitive.

Sometimes, however, free energy calculations can provide answers that are not
readily available from experiments. For example, type II kinase
inhibitors selectively bind to different kinases in the so-called
DFG-out conformations~\cite{schindler2000structural}. The selectivity of such
inhibitors may be attributed either to their differential binding to
different kinases in the DFG-out conformations, or to different
stability of the DFG-out conformations of different kinases. 

Let
$K_C$ be the equilibrium constant between DFG-in and DFG-out
conformations of one kinase, and $K_D^\ast$ be the dissociation
constant of a type II inhibitor against this kinase, the apparent
binding constant of this inhibitor against this kinase is then
\begin{equation}
  K_D = K_D^\ast \frac{1 + K_C}{K_C}
  \label{eqn:conformational-binding}
\end{equation}

Since binding experiments cannot resolve $K_D^\ast$ and $K_C$ individually, such experiments cannot address the basis of selectivity of the type II inhibitors. Absolute binding free energy calculations, in contrast, can take advantage of the slow kinetics of DFG-in/out conversion, and estimate the conformation-specific binding constant $K_D^\ast$, thus yielding clues as to the source of selectivity.

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Simulation prerequisites  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{Simulation prerequisites}
\label{sec:prerequisites}
Alchemical free energy protocols as discussed below (Sec.~\ref{sec:simulation_protocol_choice}) are defined for a specific type of free energy calculation, i.e. a free energy of solvation or a free energy of binding. Different types of simulations require different choices for ligands, solvent, and host molecules (in the case of the estimation of free energies of binding). 

\subsection{Free energies of solvation or partition coefficients}
As described in Section~\ref{sec:theory-solvation}, the theory and equations for computing solvation free energies are well established. Here, we focus instead on practical considerations for applying these methods to hydration and partition coefficient calculations.

\label{subsec:hydration}
Preliminary considerations necessary for using free energy methods to compute partition coefficients are generally more straightforward. For example, a 3D minimized structure of a solute can be generated with a simple tool such as Open Babel and solvated to prepare the input to compute a free energy of hydration~\cite{oboyle2011open}. Despite their relative simplicity, care should still be taken when preparing these systems to avoid introducing systematic errors.

\paragraph{The choice of solvent force field may impact the calculation}
A careful choice of force field for the organic solvent model, as well as water model is essential. A critical aspect of these calculations is the preparation of the system ahead of simulation. The choice of force field for both the solute and solvents involved is critical. Accurate modeling of the solute's solvation behavior hinges on realistic representations of the solvent (for partition coefficient calculations). See for example~\cite{bosisio2016blinded,rustenburg2016measuring} for a good discussion of these choices.  Beyond water, the same level of scrutiny is needed for organic solvents such as octanol, cyclohexane, or others used in partitioning studies. For example, in a study by Open Force Field, they found that the general AMBER force field (GAFF)\cite{wang2004gaff} and Open Force Field Sage \cite{boothroyd2023sage} force fields produced different results in non-aqueous solutions. Care should be taken when choosing the forcefield as solvent model parameters may vary substantially between force fields \cite{jambeck2003, kadaoluwa_2021, mobley_2007charge} and impact results accordingly.

\paragraph{Equilibration of the Solvent}
Before computing solvation or partition free energies, it is important to ensure that the solvent itself is adequately equilibrated. While water typically equilibrates rapidly, especially when prepared using standard protocols, some organic solventsparticularly those with long hydrocarbon chainscan require substantially longer equilibration times\cite{fan2021sampl7}. Failing to properly equilibrate the solvent can introduce systematic errors in free energy calculations, as the solvent structure and density may not reflect the true thermodynamic ensemble of the target environment\cite{zhang2017solventmodel}.

\paragraph{Validation through experimental comparisons}  
Finally, experimental comparisons in these systems are often more direct than in binding free energies. Hydration and partition coefficients are frequently measured with high precision, enabling rigorous validation of computational protocols. Calculating solvation free energies for charged solutes, however, remains particularly challenging, as long-range electrostatics, finite-size artifacts, and treatment of counterions can significantly affect results. Moreover, direct experimental determination of ionic hydration free energies is generally not feasible; instead, such values are inferred by decomposing the solvation free energy of ion pairs \cite{mobley2014freesolv}. This has led to their prominent use in blind challenges such as SAMPL \cite{skillman2012sampl3, mobley2014sampl4, bergazin2021sampl7}, where participants predict hydration or partition free energies of small molecules using a variety of force fields, solvent models, and sampling strategies. These exercises have repeatedly shown that small changes in simulation parameters or protocols can result in significant deviations from experimental results, reinforcing the need for careful setup and validation even in seemingly "simple" solvation systems.

\subsection{Free energies of binding}
\label{subsec:binding}
In principle, in the limit of sufficient configurational sampling, the free energy changes estimated from an alchemical free energy calculation should be independent of the system's initial coordinates. However, in practice, because simulations are of finite duration (typically 1-100 ns per state at present), this is only true for certain classes of alchemical free energy calculations such as relative or absolute free energies of hydration of small and relatively rigid organic molecules. Protein-ligand complexes typically exhibit slowly relaxing degrees of freedom that significantly exceed the duration of an alchemical free energy calculation, and host-guest calculations can be susceptible to these issues as well, depending on timescale and system. It is therefore generally important to carefully select input coordinates to obtain satisfactory results. The above considerations in Section \ref{subsec:hydration} on preparing solvation free energy and partition coefficient calculations also apply to binding free energy calculations. 
In addition to the above, the following questions may be relevant before diving into the binding free energy simulation setup.

\begin{itemize}
    \item Do I have one or multiple good receptor structures? (e.g. a good resolution X-ray crystal of the protein target)
    \item Do I have information on one or all of the ligand binding sites? (e.g. an X-ray structure)
    \item Should I include buried waters, or other small molecules that can be found in an X-ray structure?
    \item Are my ligands part of a congeneric series? (i.e. simple R group substitutions around the same scaffold)
    \end{itemize}

\paragraph{Are there good X-ray structures available?}
As with any simulation, care should be taken in selecting available X-ray structures in the Protein DataBank~\cite{berman2003announcing}. In some cases it may be wise to choose multiple starting structures to account for variability in receptor conformations as well as the accuracy of available X-ray structures. Typically, clustering of receptor structures can be used to identify different receptor conformations near the binding site, as well as assessing relevant side chain placements from the X-ray structure, see for example~\cite{mey2016blinded}. In terms of set up and other choices, following general best practice guidelines is advisable~\cite{braun2019best}.

Many free energy calculations focus on a congeneric series of ligands, which can make these calculations suitable for relative free energy protocols (see Sec.~\ref{sec:simulation_protocol_choice}). For relative calculations, some care has to be taken selecting binding poses for these ligands. Generally, a common assumption for a congeneric series is that the binding mode is conserved. Therefore, if an X-ray structure of one of the ligands is available, this should be used to position the ligands in the putative binding site in an energetically reasonable conformation without steric or electrostatic mismatch with the receptor. Checking the X-ray structure versus the experimental electron densities is important, as the position of part of the ligand or important sidechains may be based on the interpretation of the crystallographer rather than the available electron density, especially in cases of missing density. For example, looking at a cyclohexane ring density, a chair configuration is vastly more likely than that of a boat and, if a boat configuration is present in the structure, it may be worth inspecting the density to ensure it adequately supports this choice. 

\paragraph{Are you prepared to deal with any binding mode challenges?}
Generally, binding modes within congeneric series are conserved~\cite{wacker2010conserved}, however, exceptions exist~\cite{brandt2011congeneric,nazare2005probing}, as discussed in more detail in Sec.~\ref{sec:multiple_binding_modes}. Certain functional groups may be particularly prone to this due to symmetries or near symmetries. One such issue involves a 180 degree flip in the dihedral angle of an aromatic ring, or five-membered ring leading to a different spatial position of ortho- or meta- substituents that otherwise should overlap within a series. The 180 degree flip of the ring may not occur enough during simulations (due to steric obstructions) to overcome bias due to the starting configuration. Another scenario may be equatorial and axially substituted saturated rings (e.g. cyclohexane derivatives). This situation may be addressed by explicitly modelling different binding modes of the same ligand and combining later computed free energy differences for different binding modes into a relative free energies of binding~\cite{kaus2015how}.

\paragraph{Have you considered stereoisomers and enantiomers?}
Congeneric series can contain stereoisomers or enantiomers, which can bind very differently, resulting in large errors if treated incorrectly. For racemates, the relative abundance of each stereoisomer is normally not known, however when there is only one stereocenter in the molecule it can often be fair to assume that the substance is a 50\%:50\% mixture of the two. If one enantiomer is active (eutomer) and the other is inactive (distomer), this corresponds to the effective concentration of your bioactive molecule being half of what is expected in the assay, which corresponds to a ~0.2 pIC50 loss in potency relative to the pure eutomer being tested, which could be captured within the associated error calculations.\cite{h2011significance} If possible, both enantiomers could be considered computationally, however if a series contains multiple stereocenters, or multiple compounds within the series have stereocenters, this may be computationally restrictive. If compounds contain multiple undefined stereoecenters, the error and complication of understanding predictions may become prohibitive. Therefore, the experimental activity associated with just one stereoisomer/enantiomer is more uncertain. If enumerating unknown stereocenters is not tractable, modeling using just the conformation that best fits the active site is reasonable, however this clearly introduces potential for larger errors compared to experiment. Despite this, we can see that care and further testing is needed in this scenario, and the quality of the predictions may suffer. Additionally, unexpected changes in what stereoisomer binds experimentally, if they occur, could pose significant challenges for modelling efforts.

\paragraph{Are there cofactors expected to be present?}
Crystallographic structures can contain cofactors, which may be close to the ligand series of interest, and understanding if they are required or not for simulation can be an interdisciplinary effort between the modeller, crystallographer and bioligists to establish if they are a crystallographic artifact, or if they are likely to be present in the assay. In addition to both the crystallographic and assay conditions, what is most relevant \textit{in vivo} might be a third, equally difficult consideration. Following this, if a cofactor is considered to be included in the calculations, it is worth considering the appropriate forcefield for the cofactors. Cofactors, in particular metal ions can be challenging\cite{mobley2017predicting, guven2024protocols}. If the congeneric series of ligands is expected to interact with the cofactors differently, such as metal ions in different charge states, or to displace the cofactor for some of the molecules then this is likely beyond current modelling techniques. If there is still uncertainty around cofactor binding, running free energy calculations for a set of molecules both with and without the cofactor and comparing the relative rank-ordering of molecules could provide a sanity check.
 

\paragraph{Conserved binding site waters can play an important role in binding free energies}
Binding site water molecules may form water mediated protein-ligand interactions which can pose challenges whenever exchange with bulk water is slow compared to simulation timescales. This can happen in buried binding sites~\cite{laage2017water}. Overlaying multiple protein X-ray structures can identify conserved water molecules or those that are associated only with certain ligands in a series and are therefore important to include in calculations. In cases where water molecules are known to play an important role in ligand binding, for example if the presence of electron density suggests they are tightly bound (indicated by a high EDIA score~\cite{nittinger2015evidence,meyder2017estimating}), software implementations that use water sampling facilitated by Grand Canonical Monte Carlo methods may be useful~\cite{michel2010prediction}. Other tools such as WaterMap~\cite{abel2008role,young2007motifs} or open source equivalents (SSTMap~\cite{haider2018solvation}, GIST~\cite{ramsey2016solvation}, and others) can be used to define the hydration states for systems with no experimental evidence of water sites~\cite{wang2011ligand}. Well-known protein systems with water mediated ligand interactions are for example: HSP90 which formed part of the D3R grand challenge 2015~\cite{mey2016blinded}, A2A~\cite{brucemacdonald2018ligand}, MUP~\cite{ross2015water}, ~\cite{deflorian2020accurate}, and others~\cite{michel2009energetics}.

In the context of relative binding free energy calculations, determining the correct hydration pattern for the two endpoints may not be sufficient for an accurate and reproducible calculation. If the locations of the bound water molecules differs at the two endpoints - e.g. if a perturbation to the ligand displaces a bound water molecule - then the network needs to be able to adapt during the perturbation. Otherwise, it is likely that the estimated relative binding free energies will be dependent on the direction in which the perturbation is performed~\cite{ross2020enhancing}.

In absolute binding free energy calculations, a ligand is fully decoupled from a binding site cavity which may otherwise be hydrated in the \textit{apo} state. In this case, the sampling of water molecules must be sufficient to hydrate the binding pocket as the ligand is decoupled (or vice versa for the reverse). When the binding site is exposed and water can move freely between the site and bulk solvent, then sampling is often not an issue. However, in the case of more buried sites or sites which form complex water networks, enhanced water sampling may be required to ensure an accurate binding affinity.

\paragraph{Membrane proteins require additional care}
Integral membrane proteins require embedding in a suitable model membrane to remain stable during simulations. Lipids are usually not included in protein force fields and, although they may be covered by generic small molecule force fields, have often been parameterized separately (e.g., AMBER's Lipid21 \cite{AMBERLipid21} and the CHARMM lipid force field \cite{CHARMMLipidFF}). Membrane systems can be simulated in multiple thermodynamic ensembles, but the semi-isotropic scheme $NP_{z}P_{xy}T$ is frequently employed, allowing the pressure in the bilayer plane ($xy$) to scale independently \cite{LipidBestPracticesCOMS}. These systems require more extensive equilibration than soluble proteins. Some workflows, such as CHARMM-GUI or Desmond membrane preparation, recommend a multi-protocol to relax membrane systems \cite{https://doi.org/10.1002/jcc.23702,DesmondManual}. 

Alchemical transformations that involve net charge changes can provide difficulties for membrane systems; phospholipids carry functional groups with nonzero formal charge and cannot be treated as a solvent with a uniform dielectric in the same way as water. Several approaches are reviewed in \cite{wu2022correction-51c}. The authors recommend the use of a co-alchemical ion, specifically making an ion of equivalent charge appear alongside the disappearing charged molecule to maintain system neutrality.

In the case of a lipid-facing binding site, there are three additional challenges. First, simulation time should be extended to ensure sufficient sampling of lipid configurational space. Lipids may either bind alongside small molecules, acting as cofactors, or be displaced from the binding site by a ligand. If lipids participate in binding through protein-lipid or ligand-lipid interactions, it is necessary to sample these intermolecular interactions through additional $\lambda$ windows, longer simulation times, or different alchemical protocols. Displacing a lipid will have its own free energy cost which may take a long time to converge if it requires diffusion and rearrangement of nearby lipids. Second, considering the free energy cost of a ligand partitioning into the membrane may provide additional insights \cite{doi:10.1021/acs.jcim.1c01147}. Third, the free energy of binding for a small molecule may be strongly coupled to the lipid species. In some cases, the identity of the lipid may be known. But in other cases, it may be difficult to discern the identity of the lipid from X-ray or cryo-EM structures due to the flexible nature of lipid head groups and benchmarking is recommended to match experimental data.

\paragraph{Protonation states depend on the pH of the experimental assay}
Care should be taken when preparing ligands and proteins to match the pH of the experimental assay, if known. As mentioned above in Sec.~\ref{subsec:exp_condition}, the pH of the assay can differ from neutral pH and will determine the protonation states of the proteins and ligands. Since the pKa of reference amino acid sidechain residues is known, but can vary in the protein environment, many different tools have emerged for predicting sidechain pKa in proteins, such as the H++ server, ProPKa, APBS, and Maestro ~\cite{anandakrishnan2012automating, sondergaard2011improved, jurrus2018improvements, 2020schrodinger}. Strongly acidic (Glu, Asp) or basic (Arg, Lys) sidechains can reliably be predicted to be ionized, but care is still needed as the local environment can modify expected ionization states, such as  the catalytic Asp dyad in proteases. Histidine is notoriously more difficult to predict as its pKa suggests it ionizes closer to the experimental pH range. For ligands, often the pKa needs to be determined, if it is not known experimentally. There are many different available tools for this purpose, but common choices may be propKa~\cite{olsson2011propka3,sondergaard2011improved}, Chemicalize (\url{https://chemicalize.com/welcome}), or Maestro~\cite{2020schrodinger}. Still, accurate pKa prediction for small molecules remains a challenging problem, even with dedicated tools~\cite{isik2018pka}. While often it can be assumed that the protonation state of a ligand and protein will remain the same as the ligand binds, some care needs to be taken with systems where the protonation state may change upon binding~\cite{onufriev2013protonation}. BACE~\cite{kim2015conformational}, for example, famously undergoes a protonation state change on ligand binding.


\paragraph{Congeneric series often need alignment}
Input coordinates for a congeneric series may be generated by docking calculations, or by ligand alignment using MCSS algorithms. The latter tends to produce alignments that are more conserved and more consistent free energy changes across a dataset, but will struggle to yield reasonable results for relative binding free energy calculations that involve a significant binding mode rearrangement. This may also lead to steric clashes with the receptor coordinates of the reference ligand if structural rearrangements are needed to accommodate different members of the congeneric series. Small steric clashes may be resolved during subsequent simulation equilibration prior to data collection, but there is a risk that the complex relaxes to an alternative metastable state. 

An additional consideration arises for single topology relative free energy calculations. In this class of alchemical free energy calculations, it is necessary to generate a molecular topology that may describe the initial and final states of the perturbation (see Fig.~\ref{fig:fig_topology}). In cases where the end states have high topological similarity and high structural overlap this is relatively straightforward and typically handled by use of MCSS calculations. In situations where the end state topologies differ significantly, or where there is relatively little spatial overlap between the two end states, some user intervention may be necessary to produce a satisfactory input topology.

If the binding site location is uncertain but the structure of the receptor is well defined and plausible binding sites are identified, it may be more useful to choose an absolute free energy protocol to compute the standard free energy of binding of the ligand to a set of binding sites. This requires the user to prepare input files describing the bound conformation in different putative binding sites~\cite{evoli2016multiple}. The apparent binding free energy of the ligand may be obtained by combining the individual binding site free energies, which also indicate where the ligand is more likely to bind. In this case a docking program can generate initial structures. Different commercial and non-commercial tools are available, such as rDock~\cite{ruiz-carmona2014rdock}, Autodock Vina~\cite{trott2010autodock}, Glide~\cite{friesner2004glide}, or Flare, to name a few~\cite{kuhn2020assessment}. 

If the putative binding sites are not apparent, for instance due to significant induced-fit effects, it may be challenging to obtain meaningful free energies of binding. One may have to account for the free energy cost of forming a binding site in the target receptor which may not be feasible on alchemical simulation timescales.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Choice of simulation protocol and implementation of alchemical transformations   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Choice of simulation protocol and implementation of alchemical transformations}
\label{sec:simulation_protocol_choice}
Alchemical free energy calculations can be grouped into two main categories, ``absolute'' (see Fig.~\ref{fig:fig_absolute_thermodynamic_cycle}) and ``relative''\footnote{The distinction is a bit of a misnomer, since both compute ratios of partition functions relative to another state and in that sense are relative, while neither computes an absolute free energy.} (see Fig.~\ref{fig:fig_binding_thermodynamic_cycle}), which differ in whether they compute properties for a single molecule (absolute) or compare properties of different, usually closely related, molecules (relative).
To use binding as a concrete example, in absolute binding free energy calculations, we compute the binding free energy of a ligand to an individual receptor relative to a standard reference concentration. In contrast, in relative binding free energy calculations, we compare the binding free energy of two related ligands to determine the potency difference.

\subsection{Absolute and relative free energy calculations have important differences}
Many of the issues around simulation setup and protocol choice for alchemical calculations are common, but there are some differences between absolute and relative calculations. We will consider protocol differences before treating the common elements.

\subsubsection{Choices unique to relative free energy calculations}
\label{sec:relative-fe-protocol}

\paragraph{Topologies} In regular biomolecular simulations one studies physical systems or, in other words, all entities in the system, e.g., protein, ligand and waters, represent real molecules. For the following, it is helpful to classify such simulation systems as having a {\em chemical} topology. In relative free energy calculations, however, one has to transform, e.g., ligand A into ligand B etc. (see \sbnote{appropriate cross-reference!}). The required alchemical transformations can be realized in several ways, each with distinct advantages and disadvantages. In the first relative free energy calculations, these transformations were achieved with the help of chimeric entities, capable of representing both ligand A or ligand B. The important point here is that there is a single set of coordinates for this chimeric ligand, but its ``topology'' is flexible and can, for the same set of coordinates, represent either end state. We will consider this class of approaches as using an {\em alchemical} topology with a single set of coordinates. The construction of these chimeric intermediates quickly gets complicated and is difficult to automate; therefore, approaches have been developed in which both end states (e.g., ligand A and B) are present simultaneously. Thus, we have dual coordinates, but chemical topologies for each of the entities. In the following, we outline these approaches in more detail, together with additional considerations how the various approaches differ in practical use. While we will point out the respective advantages and disadavantages, we stress that the user's option in practice often are limited by the choice of simulation software.

\paragraph{Single coordinate approaches --- alchemical topologies}

When operating with a single set of coordinates for the region undergoing the alchemical transformation, a key distinction between approaches concerns the atom mapping between end state molecules. %Often this is predetermined by the choice of simulation software.
As first suggested by Pearlman, these have been referred to as \emph{dual topology} versus a \emph{single topology} \cite{Pearlman_1994}. The distinction between single and dual topology can be illustrated by considering a hypothetical transformation from molecule A to molecule B, where both atoms share a common substructure but differ in their substituents; in particular, consider a transformation of benzene to benzyl alcohol shown in Fig.~\ref{fig:fig_topology}. The single and dual topology approaches as proposed by Pearlman correspond to the left and middle paths of Fig.~\ref{fig:fig_topology}.  %\sbnote{Fig.~3 needs to be updated for dual coordinate methods and corrected, some bonds for the dummy atoms have the wrong anchor atom!}
The common substructure between the two molecules is the benzene ring, though in practice the substructure may be selected to be larger depending on the mapping chosen, as we discuss below.

In single topology calculations, the overall transformation is set up to involve as few additional atoms as possible, so benzene would be typically changed into benzyl alcohol by first changing one of the hydrogens into a carbon. The site of this transformation will also be the future home of two additional hydrogen atoms and a hydroxyl group bound to the new carbon, so these must initially be present as non-interacting atoms called ``dummy atoms'' (labelled Du in Fig.~\ref{fig:fig_topology}), which retain their bonded interactions but do not interact with the rest of the system.  Bond parameters as well as partial charges between the changing atoms are adjusted accordingly between the initial and final states; see below for further details. In a single topology calculation, atoms may change their type, ensuring minimal dummy atoms are created. This is illustrated in the left arm of Fig.~\ref{fig:fig_topology}. At intermediate states, atoms behave as 'mixed' (M), either interpolating between two physical atoms, e.g., in the example, the hydrogen becomes a carbon, or between dummy and physical atoms.

\begin{figure}
    \includegraphics[width=0.95\columnwidth]{figures/fig3_topol/Figure.pdf}
    \caption{\textbf{Strategies for alchemical calculations: single coordinate single and dual topology vs.\ dual coordinate dual topology.} \textbf{Left}: A single coordinate single topology converts from one type of atom to another. Dummy atoms (Du) are used when there is no corresponding maximum common substructure match between the two molecules for certain atoms, using a soft-core interaction to improve overlap between the dummy atoms and the "real" atoms. At intermediate states, 'mixed' atoms (M) are present, either interpolating between physical atoms, e.g., a hydrogen to a carbon, or between physical and dummy atoms.  \textbf{Middle}: The single coordinate dual topology does not convert one species to another, but only converts between Du atoms and an interacting species, typically using soft-core potentials for this. Here, 'mixed' intermediate atoms (M) always interpolate between physical and dummy atoms. Thus, 'mixed' atoms are used in both single coordinate approaches (single and dual topology), but the way the transformation occurs and the end states differ.
      %Following the arrow along the left and right illustrate the differences.
\textbf{Right}: In the dual coordinate dual topology approach both end states are present as separate molecules simultaneously.  Initially, benzyl alcohol is not interacting with the environment, at intermediate states the environment sees a mixture of the interactions of the two solutes, and, finally, benzene is not interacting with the environment. The two solutes are kept on top of each other by suitable restraints, indicated by the black ``spring'', and  the two molecules never see each other.  Figure adapted from the one used in V1 of this manuscript; adapted and extended by Sara Tkaczyk.
      % \url{http://www.alchemistry.org/wiki/Constructing_a_Pathway_of_Intermediate_States}
    }
    \label{fig:fig_topology}
\end{figure} 

In contrast, in a dual topology alchemical free energy calculation, \emph{no atoms are allowed to change type}~\cite{boresch1999role, shirts2012best}. This means that the benzene to benzyl alcohol transformation involves starting with benzene plus the non-interacting dummy atoms making up the hydroxymethyl group, then passing through an intermediate state where some atoms are partially interacting---particularly, those atoms which are becoming dummy atoms or ceasing to be dummy atoms~\cite{mobley2014blind}. The transformation finally culminates in a state where benzyl alcohol is present along with the additional dummy atom which was previously a corresponding hydrogen of the benzene. Fig.~\ref{fig:fig_topology}'s middle branch depicts how such a dual topology works. Note that the two groups that are switched on or off never see each other. The 'mixed' intermediate atoms (M) are used as well, but they strictly interpolate between physical and dummy atoms, or vice versa.
Bhati \textit{et al.}~\cite{bhati2017, bieniek2021} presented a variant of the single coordinate dual topology approach which is used in the TIES method. It involves a unique post-processing of the initial MCSS to ensure that the final MCSS is both structurally and chemically identical and has a single set of coordinates while maintaining dual topology for the alchemical parts.

%\sbnote{This probably needs to be rewritten\ldots}
As far as we are aware, the distinction between (single coordinate) single and dual topology approaches has been made primarily for two main reasons. First, this choice affects the alchemical pathway followed, and thus may affect convergence properties---though we are not yet aware of a study of the relative efficiency and merits of these two approaches. Additionally, historically, some simulation packages implemented only one approach and not the other, meaning that the distinction was functional. For an in-depth analyis of differences resulting from the use of a  single vs.\ a dual topology approach (single coordinate in both cases) see Ref.~\cite{Boresch_2002}.

\paragraph{Dual coordinate approaches --- dual chemical topologies}

The chimeric constructs needed in single and dual topology approaches in the sense of Pearlmans definition just described quickly become non-trivial to set up and require care to avoid artifacts (see below). %\sbnote{See below; where do we place the dummy atom discussion?}.
Some of these difficulties might be avoided by having the initial and final state present as separate molecules with separate coordinate sets. To the best of our knowledge, such an approach was first described by Axelsen and Li \cite{Axelsen_1998}. Both initial and final state are present simultaneously; the two copies never see each other and interactions with the environment are turned on/off as a function of $\lambda$. Harmonic restraints between corresponding atoms in the initial and final state copy prevent the two molecules (sets of atoms from drifting apart). %Unfortunately, Axelsen and Li referred to their ansatz also as dual-topology, though in practice it is quite different from Pearlmans meaning of the term.
A recent implementation of this idea is Restraintmaker \cite{Ries_2022}, a tool to automatically assign the distance restraints needed to keep the two molecules / regions (one for each of the physical endstates) on top of each other. The idea is illustrated in the right branch of Fig.~\ref{fig:fig_topology}.  Somewhat unfortunately, Axelsen and Li, as well as Ries et al refer to their approach as dual topology. Ries et al suggested to use the term hybrid topology for (single coordinate) dual topology in the sense of Pearlman. We will attempt a disambiguation of the various nomenclatures below.

Another variant of a dual coordinate approach is implemented in NAMD \cite{jiang2019computing}. Whereas Ries et al.\  use distance restraints to keep two molecules on top of each other, corresponding atoms in NAMD are held on top of each other by constraints; in practice, this means that these coordinates are forced to be identical. AMBER's free energy implementation recently switched to a similar approach \cite{lee2023aces,York_ACSPhysChemAu_2023_v3_p478}.
While the implementation technically uses two sets of coordinates for the entire transforming region, selected atoms that have a direct atom-atom mapping are constrained to have common coordinates (sometimes referred to as a "common core"), while others that are mapped into dummy atoms and are treated with softcore potentials~\cite{Lee_JChemTheoryComput_2020_v16_p5512,Tsai_JChemTheoryComput_2023_v19_p640} have separable coordinates.  Thus the common core part of the dual topology are constrained to have the same coordinates to maximize phase space overlap, whereas the softcore region has separate coordinates.  The two topologies do not see each other, and this property enables this approach to be leveraged in the alchemical enhanced sampling (ACES) method~\cite{lee2023aces,Tsai_JChemInfModel_2024_v64_p7046,Zhang_JChemTheoryComput_2024_v20_p3935}.
%The authors refer to this approach as hybrid single-dual topology. While it technically uses two separate sets of coordinates, the constraint that corresponding atoms have identical coordinates makes it effectively a single coordinate method; hence, I consider NAMDs approach to be a variant of Pearlmans (single coordinate) dual topology. 

Dual coordinate approaches with chemical topologies encompass a third group of methods, where essentially two absolute free energy calculations are carried out in opposite directions at the same time.
The so-called ``separated topologies'' (SepTop) method \cite{rocklin2013separated,Baumann_2023} and the ``alchemical transfer method'' (ATM) \cite{azimi2022relative} belong into this category. In SepTop, the two copies are held on top of each other via restraints with respect to the protein/receptor they bind to (as opposed to Restraintmaker, where the molecules are restrained to each other). %In ATM, a restraint is used to keep the bound ligand 1 and the free ligand 2 always some minimum distance apart; during exchange moves, suitable rigid-body rotations/translations are applied to move the free ligand into a position/orientation as similar as possible to the one of the bound ligand.
In ATM, restraints are used to keep the bound and free ligands at some distance apart and in the same orientation, so that during the translation move the free ligand is placed into a position and orientation as similar as possible to that of the bound ligand. Recently, a variant of $\lambda$-dynamics that uses chemical topologies (separate coordinates for each state) has been proposed \cite{Liesen_2024}.

%Other methodologies also use both end states simultaneously; examples are the Separated Topologies (SepTop) approach [Baumann2023] and the ATM method [Azimi2022]. In the former, the two copies are held on top of each other via restraints with respect to the protein/receptor they bind to. Ries et al. refer to such an approach as separated dual topology, whereas they label their approach as linked dual topology. In ATM, a restraint is used to keep the bound ligand 1 and the free ligand 2 always some minimum distance apart; during exchange moves, suitable rigid-body rotations/translations are applied to move the free ligand into a position/orientation as similar as possible to the one of the bound ligand. Both copies are present simultaneously, but they do not occupy the same space.

%One final approach, so far in its infancy, has been called ``separated topologies'' and essentially consist of two absolute free energy calculations in opposite directions at the same time, turning one molecule's interactions with the environment off, while turning the other molecule's interaction on~\cite{jiang2019computing, rocklin2013separated}.

\paragraph{Summary, comparison of single and dual coordinate methods, orthogonal classifications:}

%Some additional terms have also been employed to talk about these different intermediate pathways . Particularly, some studies refer to a ``hybrid'' topology approach to free energy calculations~\cite{gapsys2015pmx, gapsys2016accurate, gapsys2020large}, though this term may not yet have achieved widespread use. In this case, "hybrid" seems to indicate that the set up of these free energy calculations involves a hybrid of the two molecules, and much of what is done in these studies uses a single topology approach~\cite{gapsys2020large}.

Unfortunately, during the past years the use of the terms single and dual topology has proliferated, often with quite different meaning from the original intentions. The above presentation makes clear that the primary difference between approaches is the use of separate coordinates for each end state (chemical topology) or the use of an alchemical chimera with a single set of coordinates (alchemical topology). We therefore suggest the following classification
\begin{itemize}
\item Single coordinate (SC) --- Alchemical topology
  \begin{itemize}
  \item Single topology (SCST)
    \item Dual topology (SCDT)
  \end{itemize}
  \item Dual coordinate --- Chemical topology (DC)
  \end{itemize}
For completeness, we list some additional terminology that has been used: Some studies refer to a ``hybrid'' topology approach to free energy calculations~\cite{gapsys2015pmx, gapsys2016accurate, gapsys2020large}, though in our view these calculations should be classified as single coordinate single topology \sbnote{Check whether this is correct!}. %this term may not yet have achieved widespread use. In this case, "hybrid" seems to indicate that the set up of these free energy calculations involves a hybrid of the two molecules, and much of what is done in these studies uses a single topology approach~\cite{gapsys2020large}.
Ries et al.\ suggested terminology \cite{Ries_2022} in which single topology corresponds to SCST, hybrid topology to SCDT, and dual topology to DC.

The practical implementation of the approaches to carry out alchemial transformations above leads to additional, often non-trivial differences within each methodology. In the description of DC approaches we already pointed out that the two sets of coordinates can be held on top of each other by constraints \cite{jiang2019computing,lee2023aces} or restraints. In the latter case, the restraints may couple the two set of coordinates directly \cite{Axelsen_1998,Ries_2022}, or the restraints may be defined relative to a common reference frame \cite{rocklin2013separated,Baumann_2023}. Finally, in ATM the two copies of the coordinates are held separate \cite{azimi2022relative}.

Concerning SC approaches, Pearlmans usage of the term single topology not only meant a chimeric construct as depicted in Fig.~\ref{fig:fig_topology}, but specifically implied that the coupling parameter $\lambda$ was applied to the force field parameters. E.g., a bond stretching energy term changing from C-H to C-C has the functional form $U_{bond}(\lambda)=K(\lambda)(r-r_0(\lambda))^2$. For $\lambda=0$, $K(\lambda)$ and $r_0(\lambda)$ correspond to the values appropriate for a C-H bond, and for $\lambda=1$ to those for a C-C bond. Other force field parameters are treated analogously. The single topology paradigm as just summarized was the default mode of alchemical transformations in AMBER and GROMOS at that time.  More recently, this implementation of single topology has been referred to as parameter interpolation or mixing \cite{Giese_2018}. 

The $\lambda$-dependent interpolation can also be accomplished by mixing the energies and forces of the initial ($\lambda=0$) and final state ($\lambda=1$), e.g., linearly according to $U(\lambda)=(1-\lambda) U_0+\lambda\,U_1$. Other -dependencies can be used, and soft-cores \rref may be used for Lennard-Jones and electrostatic interactions to avoid endpoint problems. Giese et al. \cite{Giese_2018} refer to this approach as energy mixing (interpolation).%; it requires two separate calls to the energy/force routines, but since only a fraction of interactions is affected by the alchemical changes, various optimizations are possible to keep the computational overhead manageable.
An early example of energy mixing for SCST is the PERT free energy module of CHARMM (written by Bernie Brooks around 1990 and briefly described in Ref.~\cite{brooks_2009}).

Any SCDT approach requires two energy/force calculations and, thus, uses energy mixing. Therefore, approaches that implement energy mixing together with an alchemical topology (a single set of coordinates) often support both SCST and SCDT. E.g., CHARMM's PERT module just mentioned could be used to set up either of the SC approaches sketched in Fig.~\ref{fig:fig_topology}. Finally, all DC approaches require two energy/force evaluations.

Any energy mixing approach, whether in a SC or DC context, requires two energy/force evaluations. While various optimizations keep the computational overhead significantly below a factor of two,  parameter mixing, if applicable, is the compuationally most efficient approach. However, it is closely tied to SCST and the more complicated the alchemical transformation, the more challenging a strict SCST approach becomes. Also, the mixing of partial charges and the calculation of $\partial U/\partial\lambda$ for the reciprocal space particle-mesh Ewald (PME) summation is tricky. Giese et al.\ described how to do this \cite{Giese_2018}, but most energy mixing implementations calculate the PME term twice and mix the resulting energy and forces.

\sbnote{I think this should get its own paragraph/subsection; to be expanded!} Software packages vary in their use of single or dual topology approaches; for example, AMBER TI uses a dual topology approach, while BioSimSpace uses a single topology approach. Please make sure to check what approach is used with your software package of choice, or whether it supports your choice of approach (GROMACS and GROMOS, for example, support both). 
To our knowledge, efficiency differences have not been thoroughly explored, though conventional wisdom suggests that fewer dummy atoms are better, as introducing or removing atomic sites is usually more difficult, requiring more intermediate steps ~\cite{liu2013lead, mobley2012perspective}.

Because they duplicate the common region, dual coordinate formulations are not generally applicable to small modifications of large molecules, such as single-point mutations of proteins. An exception, and an example of the variety of alchemical approaches, is the Alchemical Transfer with Coordinate Swapping method~\cite{gallicchio2025mutants}, which is a dual coordinate approach with similar convergence characteristics of single- and dual-topology formulations. It works by exchanging the coordinates of the corresponding atoms of the common substructure of the free and bound ligands and displacing the atoms of the variable substituents. The net effect is the switching of the positions of the two ligands (Figure \ref{fig:atm-illustration}\textbf{B}) by the transfer of only their variable regions.

\paragraph{Atom mapping} \label{subsec: Atom Mapping}
Following the choice of system representation and sampling strategy, it might be required to generate a atom mapping. This is the case especially for system representations using a single coordinate set (Type 1. \& 2), however a dual coordinate set approach could use an atom mapping as well, depending on the sampling method, this will be explained in the next steps.
Once a single coordinate set approach is selected, a crucial next step is to identify the common atoms which will not be perturbed between the two molecules (respectively end-states).
Rigorously, this process typically comprises a MCSS search of the molecules involved to identify the common substructure.\cite{ries2024kartograf}


\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/fig4_mcs/Figure.pdf}
    \caption{\textbf{Illustration of maximum common substructure matches} MCSS is shown in green for when (\textbf{A}) a restrictive MCSS match is used and in (\textbf{B}) ring breaking is allowed, meaning there is no MCSS match between the two compounds.}
    \label{fig:fig_mcss}
\end{figure} 

In general, there are many ways to calculate an MCSS. One of the most prominent approaches is to estimate the MCSS with a 2D subgraph isomorphism solver(SIS) using the 2D topological stuructre information of molecules\cite{raymond2002maximum}.
A large number of software tools can compute SIS MCSS matches using different cheminformatics packages. Some rely on RDKit~\cite{rdkit2019Dec}, such as pmx~\cite{gapsys2015pmx}, LOMAP~\cite{liu2013lead}, SMArt~\cite{petrov2021perturbation}, and partially BioSimSpace~\cite{hedges2019biosimspace}, while others such as fkcombu~\cite{kawabata20143d} are standalone tools. Schr\"{o}dinger's FEP+ planning tool was originally based on a version of LOMAP, and it also uses MCSS matching as well as 3D considerations to plan the network of single topology calculations between molecules~\cite{wang2015accurate}. 

SIS based methods were shown to struggle with 3D properties of the molecules that need to be mapped, like for example stereochemistry. Therefore, some packages developed a post-mapping step, where they filtered for atom distances, and, therefore, added 3D information into the mapping.
Still SIS MCSS searches can be relatively time consuming as the algorithmic complexity is classified as NP-complete, so if the goal is to assess a library of ligands to identify promising pairs for relative calculations, it can be helpful to use faster approaches such as shape similarity to perform an initial similarity assessment and then use MCSS only to identify final mappings for relative calculations~\cite{raymond2002maximum,klabunde2012mars,jones2009elucidating, Duesbury2018Comparison}. The SIS MCSS approach, though relatively standard, takes into account only topological similarity. It is possible that changes in binding mode could actually require a different choice of mapping, so in some cases mappings may need to be planned differently depending on 3D positioning of atoms in space. 

Here an alternative way to estimate the MCSS is to calculate a bipartite graph matching based on the 3D positions of two molecules. These approaches tend to be very fast (can have algorithmic complexity of $O(n)=N^3$) and geometric accurate in their mapping (e.g. stereochemistry or binding mode differing).
The geometric approaches additionally allow mappings of differing binding modes of the same molecule, or can be even used for significant larger molecules like proteins, due to the speed increase.
A disadvantage of these approaches is the strong dependency on the coordinate sets being well aligned. Another aspect is taking the topology changes of the molecules not into account, which can be done if necessary in a next step with a filtering approach, like checking for changes in ring hybridization or ring breaking (this problem is discussed below)|.
Tools that can be used to estimate the MCSS this way are contained for example in pmx \cite{gapsys2015pmx} or Kartograf \cite{ries2024kartograf}.

In any case, visual inspection prior to simulation is recommended to ensure that the mapping criteria correspond to the expected binding mode. If the mapping protocol returns simulations that correspond to different binding modes of a ligand within a perturbation map, this can cause large hysteresis.

A next step for atom mappings, would be to support multistate methods (e.g. RE-EDS~\cite{sidler2016replica}, A-EDS~\cite{perthold2020toward} or Ladybugs~\cite{robo2023fast}) with efficient mapping algorithms. There are starting points, suggesting protoype algorithms for solving this problem, but to our knowledge, there is only few published work on this aspect. \cite{petrov2021perturbation}

Single coordinate set relative calculations and calculations based on substructure searches only work if in fact the ligands share a common substructure, e.g. are part of a congeneric series, see Fig.~\ref{fig:fig_mcss}.
If no common substructure is shared, then dual coordinate sets methods like linked-dual or separated topology free energy calculations are needed. One would co-localize a pair of compounds in a binding site, exclude their interactions with one another, and compute the relative binding free energy by turning one molecule on from being dummy atoms while turning the other off.
For such approaches it is crucial to find a good set of restraints, that keep the ligands colocalized over the time of the simulation . This problem is similar to the required restraints in ABFE Calculations (see \ref{sec:standardstate-restraints} ). Few descriptions of possible approaches in RBFE calculations can be found for such approaches like the one suggested by \textit{Baumann et al.}~\cite{baumann2023broadening} based on Boresch style restraints~\cite{boresch2003absolute}, with an elaborate automatic atom selection approach, for the seperated topology approach, or Restraintmaker~\cite{ries2022restraintmaker} for the linked-DCDT approaches, which finds a small set of atoms to be linked via distance restraints, with a small distance to each other. 
However the implementation and testing of an fully automatized dual-topology pipeline for RBFE dual topology approaches is still to our knowledge a remaining research problem and was only tested with small datasets. \cite{jespers2019qligfep, rieder2022lev}

\paragraph{Dummy atoms} \label{subsec: Dummy Atoms}

In practically all relative free energy simulations, regardless of the approach, SCST, SCDT, or DCDT, dummy atoms (non-interacting placeholder atoms) are required. We stress this point, as sometimes dummy atoms are viewed as something specific to SCST. In SC approaches, dummy atoms may even be required if the number of atoms between initial and final state of the system is identical, consider, e.g., tautomeric forms of a molecule.

The need for and role of dummy atoms is clearly visible in Fig.~\ref{fig:fig_topology}: One or more dummy atoms are attached to the physical molecule. A crucial requirement is that these atoms, typically connected through bonded energy terms (bond stretching, angle bending, dihedral angles) do not affect equilibrium and dynamical properties of the physical system. However, since a physical molecule + dummy atoms attached to it can or must be viewed as a modified physical molecule, the partition function of the molecules with and without dummy atoms will NOT be identical. In other words, a single free energy difference between two molecules A and B will be different from that of A(+D) and B(+D), where the (+D) indicates the presence of one or more dummy atoms needed so that the alchemical transformation can be carried out. When a dual coordinate approach is used, the noninteracting part of the respective other endstate is tied to the physical one, and will contribute to the partition function. By construction, relative free energy simulations involve two analogous alchemical transformations, e.g., A(+D) -> B(+D) in gas phase and aqueous solution (RSFEs), or in the bound and unbound state (RBFEs). If dummy atoms  interact with the physical system in such a way that $\mathsf{Z = Z(R) \times Z(R\text{-}D) \times Z(D)}$, where Z is the total partition function, Z(R) the partition function of the physical system, Z(D) the partition function contribution resulting from interactions between only the dummy atoms, and Z(R-D) the contribution resulting from the bonded connections between the physical atoms and dummy atoms, then their contributions (Z(D) and Z(R-D)) factor from the total partition function. As dummy atoms do not interact with the environment, their contribution, therefore, is identical in the two alchemical transformations required in the two legs of the relative transformation and will cancel exactly from the double free energy difference of interest.

While some early work on the correct treatment of dummy atoms, i.e., how to treat them so that their contribution to the partition function factors, has been available for years \cite{Boresch_2002,Shobana_2000,Wang_2012}, most workers seem to mostly turn off nonbonded interactions for dummy atoms, but leaving all bonded interactions intact \sbnote{To all: While I am quite sure that this is what most of us have been doing most of the time, I wonder whether this has been epxlicitly described anywhere?}. Since current force fields use multiple angle and torsion terms for each atom, there are often a large number of bonded energy terms connecting dummy atoms to the physical molecule. However, as already described in the early studies and repeated in a more recent study focusing on the correct treatment of dummy atoms \cite{Fleck_2021}, the desired factorization can only be guaranteed if any dummy atom connected to the physical molecule is held by exactly three (non-redundant) degrees of freedom. Naive application of the three-degree-of-freedom per dummy atom rule (for dummy atoms having at least one joint bonded term with the physical molecule), however, can result in simulations where the dummy part adopts unphysical configurations/conformations; Fleck et al.\ referred to this as flapping. Thus, depending on the details of the physical molecule -- dummy atom(s) junction, the three degree of freedoms need to be selected with care, or a carefully chosen additional redundant degree of freedom may be needed. In the latter case, the factorization of the partition function is not exact, but the overall error can still be made arbitrarily small. For the full details, we refer the reader to Ref.~\cite{Fleck_2021}. 

One situation involving dummy atoms that needs to be avoided is the creation of a cyclic structure involving dummy atoms, i.e., whenever the (group of) dummy atom(s) is attached to two different parts of the physical molecule. In this case, the factorization of the partition function is never possible \cite{Shobana_2000}. It follows that ring opening or closing is extremely challenging to carry out using SCST approaches \cite{liu2015ring}; these difficulties have in part motivated the development and adoption of dual coordinate approaches. For more on ring opening/closing, see also below. Nevertheless, DC approaches are susceptible to exactly this type of problem: to keep the noninteracting molecule on top of the interacting one, typically multiple bonded restraints (e.g. harmonic bonds) are used \cite{Axelsen_1998,Ries_2022}. These effectively, are equivalent to the formation of cyclic structures with potential erroneous contributions to the double free energy difference of interest. The type of restraints used in SepTop \cite{rocklin2013separated,Baumann_2023} and ATM \cite{azimi2022relative} avoid this problem.
Additionally, SCDT approaches, such as TIES~\cite{bhati2017}, circumvent this issue by design as they do not need any restraints to hold MCSS together between the two end-points.

The influence from an incorrect treatment of dummy atoms (e.g., leaving all bonded terms intact) is difficult to estimate, though it may be small in many cases \cite{Fleck_2021}. Nevertheless, some guidelines should be followed:
\begin{itemize}
  \item Obviously, a system with and without dummy atoms should have the same energetic minimum; practitioners should test this as follows. Note that in larger groups of dummy atoms, redundant bonded terms involving only dummy atoms will be essential to avoid flapping, and the energy of the optimized geometry may be different from that of the physical system without dummy atoms. Thus, a \underline{necessary} condition is as follows: Optimize the geometry of the physical system (no dummy atoms); the final energy is the reference value. Optimize the geometry of the same molecule in the presence of dummy atoms; the final energy may well be different from the reference energy. Now delete the dummy atoms and recompute the energy \underline{without} further minimization. The energy after the deletion of the dummy atoms must be identical to the reference energy. 
\item The above is only a \underline{necessary} criterion, and the dummy atoms may still influence the dynamical behavior of the physical molecule. Furthermore, overzealous removal of redundant energy terms may result in flapping of the dummy atoms. If one suspects the latter, then a short simulation in the gas phase should reveal flapping. Unfortunately, while straightforward in principle, both checks described are hard to automate, which is essential in large RFEs campaigns. 
\item The correct treatment of dummy atoms can be validated by closing a suitable thermodynamic cycle.  E.g., Fleck et al.\ calculated ASFEs for each of their endstates, as well as the RSFE between them \cite{Fleck_2021}. In all cases when dummy atoms were treated according to best practices, the cycle closure error was well within the statistical uncertainty, which was well below 0.1 kcal/mol. A related, earlier study by Loeffler et al. also reported ASFEs and RSFEs. If one attempts to close the cycle based on the numbers reported there, cycle closure error was nonnegligible in some cases \cite{loeffler2018reproducibility}. 
\item While solvation free energies can nowadays be computed quite fast, their systematic calculation would nevertheless be too costly. The role of solvent can be replaced by some external restraint, distorting the average geometry of the physical molecule. If one computes the free energy cost of applying the restraint with and without dummy atoms, the two numbers must agree within statistical significance. While much faster than full solvation free energy calculations, applying a restraint in the gas phase requires careful thermalization of the simulation system, and automation is difficult.
  \end{itemize}
%Further work automating the correct setup and treatment of dummy atoms is necessary.


\paragraph{Ring breaking and forming} \label{subsec: Ring breaking and forming}
Relative free energy calculations for ring breaking and forming are particularly challenging/problematic (see Fig.~\ref{fig:fig_mcss}\textbf{B}), in part because relative calculations rely on the free energy contributions of dummy atoms cancelling between different legs of the thermodynamic cycle, which may not be true whenever dummy atoms are involved in rings~\cite{liu2015ring}.
Some approaches have attempted to address this using a single coordinate sets and with soft bond approaches ~\cite{clark2019relative,wang2017accurate} or dual coordinate set approach \cite{jespers2019qligfep, ries2022relative, bhati2017, bieniek2021} but a general solution is not yet in mainstream use. Still, FEP+ implements one solution\cite{wang2017accurate}.
%TIES overcomes this issue by ensuring that MCSS atoms are structurally and chemically identical while allowing for partial rings~\cite{bhati2017, bieniek2021}.

\paragraph{Constraints and relative free energy calculations}
One issue which requires particular care is the use of constraints.
Commonly, bonds involving hydrogen are constrained to a fixed length using algorithms such as SHAKE or LINCS, allowing the use of longer timesteps~\cite{krautler2001fast}.
However, in single topology relative free energy calculations, the atoms involved might be mutated to other atom types---for example, in a mutation of methane to methanol, one hydrogen might become an oxygen atom. The bonds with such atoms might not have any constraints, or if all bonds are constrained, would have constraints of different lengths. 
Some molecular dynamics engines are not set up to recognize this change, or at least not to correctly include contributions to the free energy from changing constraints/constraint length, so results for a transformation can be erroneous.
At present the most general solution to this problem is simply to avoid the use of constraints (and thus use a smaller timestep if necessary, usually of around 1 fs) in any relative free energy calculation involving a transformation of a constrained bond. Individual software programs and settings can handle such issues. For example, bonds can be transformed in both GROMACS and GROMOS, because contributions of LINCS (GROMACS) and SHAKE (GROMOS) constrained bonds are added to the $\frac{dH}{d\lambda}$ term~\cite{pearlman1993determining, straatsma1992holonomic, pearlman1991overlooked, gunsteren1989computer}. However, the constraints are not taken into account when calculating energy differences to other intermediate states as the effect is entropic, not energetic. User manuals should carefully checked for how these effects are included if a constrained bond changes in length. 

\subsubsection{Absolute free energy calculations must handle the standard state and use binding site restraints}
\label{sec:standardstate-restraints}

%this was moved to the theory section, keeping it for now for reference
\begin{comment}
An absolute binding free energy calculation yields the standard free energy of formation of the molecular complex from the separated receptor and ligand species. Hence, as discussed in \ref{sec:non-covalent-molecular-binding}, it must depend on the standard state concentration $C^\circ$ (here $1 \, {\rm M} = 1 \, {\rm molecule}/1660$~\r{A}$^3$) and on the definition of the complex, that is on the specific binding pose for which the binding free energy is requested. Omitting the standard state concentration would yield an undefined result that would vary with the choice of concentration units. A similar vague estimate would result from omitting the binding pose definition that, for example, could equally describe binding to a specific site of the receptor or unspecific binding throughout the receptor surface depending on the extent of conformational sampling (see Sec.~\ref{sec:weak-binders}).

In the statistical mechanics formulation of Gilson et al.~\cite{gilson1997statisticalthermodynamic}, described in Section \ref{sec:non-covalent-molecular-binding}, the standard state concentration appears explicitly in Eq.~(\ref{eq:DG0-binding-constant-def}) and the binding pose is defined by the indicator function $I(\zeta)$ that characterizes the partition function of the complex; Eq.~(\ref{eq:intra-zRL-def}).  The role of the standard state and binding site definitions are particularly evident when expressing Eq.~(\ref{eq:DG0-binding-constant-def}) in terms of an ensemble average. To do so, we express the integrals in the numerator and denominator of Eq.~(\ref{eq:DG0-binding-constant-def}) over the same set of degrees of freedom. Note that the intramolecular configurational partition function of the complex, $z_{RL(v)}$, includes six more degrees of freedom--the position and orientation of the ligand relative to the receptor collectively described by the variable $\zeta$--than the product of the intramolecular partition functions, $z_{R(v)} z_{L(v)}$, of the separated receptor and ligand. To correct this discrepancy, we multiply and divide the right-hand side of Eq.~(\ref{eq:DG0-binding-constant-def})  by the quantity
\begin{equation} \label{eq:Vsite-def}
    V_{\rm site} \Omega = \int d\zeta I(\zeta) \, ,
\end{equation}
%\Omega is in my opinion a better symbol of the orientational extent than \xi_L. Lowercase greek letters are usually used
%for dynamical variables rather than integrated quantities
which measures the extent of the binding pose macrostate, where $V_{\rm site}$ corresponds to the spatial extent and $\Omega$ the orientational extent. The right-hand side of Eq.~(\ref{eq:Vsite-def}) combined with the integrals $z_{R(v)}$ and $z_{L(v)}$ yields a partition function similar to Eq.~(\ref{eq:intra-zRL-def}) but corresponding to a complex in which ligand and receptor are uncoupled~\cite{gallicchio2011recent} as if they were at infinite distance apart. The result is
\begin{equation}\label{eq:DG0-binding-constant-def-average}
K_b = C^\circ V_{\rm site} \frac{\Omega}{8 \pi^2} \langle e^{-\beta \Delta \Psi}  \rangle_0 
\end{equation}
where, similarly to Eq.~(\ref{eq:zratio-solv-average}),
\begin{equation}\label{eq:pert-energy-def}
\Delta \Psi(x_R, x_L, \zeta) =  \Psi_v(x_R, x_L, \zeta) - \left[  \Psi_v(x_R) + \Psi(x_L) \right]
\end{equation}
is the solvent-averaged binding energy of the complex when receptor and ligands are in intramolecular configurations $x_R$ and $x_L$, the ligand is in position and orientation $\zeta$ relative to the receptor (the uncoupled potential energy does not depend on  the position and orientation of the ligand relative to the receptor), and $\langle \ldots \rangle_0$ represents an ensemble average in the uncoupled ensemble. Finally, note that $\Omega = 8 \pi^2$ when the binding pose indicator function does not depend on the orientation of the ligand and Eq.~(\ref{eq:DG0-binding-constant-def-average}) simplifies to
\begin{equation}\label{eq:DG0-binding-constant-def-average-noOmega}
K_b = C^\circ V_{\rm site} \langle e^{-\beta \Delta \Psi}  \rangle_0 
\end{equation}
which, expressed in free energy units, yields
\begin{eqnarray}\label{eq:DG0-def-Vsite}
  \Delta G^\circ_b &=&  - k_B T \ln K_b = - k_B T \ln C^\circ V_{\rm site} - k_B T \ln \langle e^{-\beta \Delta \Psi}  \rangle_0 \nonumber \\
{\rm \ }  &=& \Delta G^\circ_{b,{\rm ideal}} + \Delta G_{b,{\rm exc.}}
\end{eqnarray}

The term $\Delta G^\circ_{b,{\rm ideal}} = - k_B T \ln C^\circ V_{\rm site}$ in Eq.~(\ref{eq:DG0-def-Vsite}) is interpreted as the \emph{ideal} component of the standard binding free energy, that is the binding free energy that would be measured in the absence of ligand-receptor interactions ($\Delta \Psi = 0$) and when the ligand's concentration is $C^\circ$. The ideal term is responsible for the dependence of the standard binding free energy on the standard state concentration. The arguably inappropriate term ``standard state correction'' is sometimes used in the literature to refer to $\Delta G^\circ_{b,{\rm ideal}}$. As seen above, the ideal term is a fundamental aspect of the statistical mechanics theory of molecular binding rather than a mere correction to an inexact formulation. 

Conversely, the term $\Delta G_{b,{\rm exc.}} = - k_B T \ln \langle e^{-\beta \Delta \Psi}  \rangle_0 $ is the \emph{excess} component of the standard free energy of binding, which is the term that depends on intermolecular interactions and the specific chemical composition of the system. The excess component is the target of the alchemical molecular simulations discussed here, in contrast to the ideal term that is generally evaluated analytically~\cite{boresch2003absolute}.
\end{comment}

As discussed in Sections \ref{sec:theory-solvation} and \ref{sec:theory-partitioning}, the handling of the standard state in solvation and solvent partitioning free energy calculations is typically straightforward. Eq.~(\ref{eq:DG0-solvation-def}) identifies the ideal and excess components of the standard solvation free energy in terms of the standard gas pressure $P^\circ$, standard solution concentration $C^\circ$, and ensemble averages typically evaluated by alchemical free energy simulations. These relations provide simple recipes to relate computational estimates to experimental values obtained under different conditions. Moreover, typical experimental reporters (Henry's constants and partitioning coefficients) directly probe the excess term calculated by molecular simulations, which is independent of the standard state.

As discussed above, the situation for binding is more complex and requires special care. The first important aspect is that binding free energy calculations must be performed with binding site restraints that implement the binding site indicator function $I(\zeta)$ by forcing the ligand to occupy the binding site even when it is decoupled from the receptor. Doing otherwise would fail to specify the bound macrostate of the complex and return undefined binding free energy estimates. However, in practice, calculations lacking binding site restraints often return reliable binding free energy estimates due to the kinetic trapping of the ligand in the binding site region during the relatively short molecular dynamics sampling typical of alchemical binding free energy simulations. Nevertheless, longer calculations could display persistent drift of the estimate as new regions of conformational space are sampled. A more serious consequence of neglecting binding site restraints is the possibility of the ligand leaving the binding site when it is not coupled to the receptor. Such occurrence indicates a serious violation of the theory. Alchemical binding free energy simulations where the ligand leaves the binding site are not set up correctly and can return grossly inaccurate binding free energy estimates.

Because it is a discontinuous function of the position and orientation of the ligand relative to the receptor, molecular dynamics implementations often approximate the indicator function by means of flat-bottom restraints~\cite{chen2007can, wu2021alchemical} (see below). Harmonic restraints are not as suitable in this respect because they favor a specific microstate at the bottom of the harmonic potential rather than specifying a region of conformational space.

Note that the ideal binding free energy term $\Delta G^\circ_{b,{\rm ideal}}$ in Eq.~(\ref{eq:DG0-def-Vsite}) is independent of the chemical nature of the binding partners, and it is the same for all complexes sharing binding site definitions. The latter is why the ideal term cancels out when taking the difference of absolute binding free energies when estimating relative binding free energies (RBFEs). However, while it does not appear explicitly in its definition in Eq.~(\ref{eq:DG0-def-Vsite}), the excess component of the binding free energy $\Delta G_{b,{\rm exc.}}$ depends implicitly on the definition of the binding site through the ensemble average in the uncoupled ensemble, which includes only ``bound'' configurations according to the definition of the indicator function $I(\zeta)$. Varying the binding site definition affects both the ideal and excess binding free energy terms such that their sum (the standard binding free energy) is often only weakly dependent on the binding site definition~\cite{gilson1997statisticalthermodynamic,gallicchio2011recent}. Conversely, great care should be exercised when comparing calculated excess binding free energy values corresponding to different binding site definitions. Similarly, the outcome of a binding free energy calculation conducted without a binding site definition, i.e.\ without binding site restraints, is, in principle, undefined. The latter is also true for relative binding free energies because while the ideal term cancels out, the difference in excess binding free energies depends on the binding pose definition. 



\paragraph{Several choices of restraints are possible in binding free energy calculations.}
A variety of restraint types are commonly used in alchemical binding free energy calculations. Before going into their characteristics, we must acknowledge an important and often unrecognized distinction between the binding site restraints corresponding to the indicator function $I(\zeta)$ necessary for the implementation of the theory and optional auxiliary restraints and biasing potentials sometimes used to speed up the convergence of free energy calculations. Binding site restraints are an integral part of the molecular complex definition and are typically maintained throughout the alchemical process. In particular, they must be present unchanged at the unbound and bound states. In contrast, unless thermodynamic reweighting is applied in post-processing, auxiliary restraints cannot be present at the endstates to avoid affecting their free energies. Hence, typically the free energy cost of turning them on is computed at the uncoupled state, and the free energy gain of releasing them is calculated near the bound state. In the alchemical binding free energy literature, often harmonic restraint potentials imposed in an initial stage and removed in a final stage are described as implementing binding sites restraints. However, because they utilize harmonic potentials that cannot correctly describe the binding pose macrostate (see above) and because they are turned on and then off, these are instead auxiliary restraints introduced to enhance convergence without affecting, in principle, binding free energy estimates.

Binding site restraints implement the $I(\zeta)$ indicator function. They, therefore, can depend at most on the six rigid-body external coordinates of the ligand governing the position and orientation of the ligand relative to the receptor. Any other choice would affect the intramolecular conformational distribution of the ligand or the receptor and would  bias the binding free energy estimate. The external degrees of freedom introduced by Boresch et al.~\cite{boresch2003absolute,leitgeb2005alchemical} are a popular choice. The Boresch coordinates, as well as other similar approaches, involve selecting anchor atoms of the receptor and the ligand. In principle, the choice of anchor atoms is arbitrary, provided adequate simulation time is available, and as long as it leads to similar binding pose definitions. However, practical considerations may be important. For example, some choices of Boresch-style anchor atoms can be numerically unstable. Additionally, anchor atoms should likely be placed in a part of the molecule that defines the binding orientation well rather than in a floppy, solvent-exposed tail. Several automated methods have been proposed to select anchor points for Boresch restraints, which typically involve analysing a simulation of the fully-interacting receptor-ligand complex~\cite{alibay2022evaluating, alibay2021mdrestraintsgenerator, baumann2023broadening, chen2023enhancing, hedges2023suite, wu2025optimizing}.

As discussed above, binding site restraints are commonly implemented using quadratic flat-bottom restraints, which impose a restoring harmonic  force similar to harmonic potentials but only if the ligand leaves a specific region~\cite{chen2007can}. Often, binding site restraints do not limit the rotational degrees of freedom of the ligand, and the corresponding standard state term is zero; see Eq.~(\ref{eq:DG0-def-Vsite}). However, it might be challenging to fully explore the bound macrostate at all alchemical states when it is only limited by receptor-ligand positional restraints. As further discussed below, auxiliary restraints are particularly helpful in the latter circumstance to limit the extent of conformational sampling necessary to achieve rapid convergence of binding free energy estimates.

Most current binding free energy workflows do not use binding site restraints present at all stages of the simulation and implicitly assume that $V_{\rm site}$ in Eq.~(\ref{eq:Vsite-def}) is the volume of the simulation box $V$. In the absence of binding site restraints, only the protein-ligand interactions prevent the ligand from slipping out from the binding site and wandering throughout the simulation box within the simulation time frame. However, observations of ligands leaving the binding site become more likely as simulation times increase, especially when analyzing weak binders and non-binders (see below). Moreover, there is no obstacle for the ligand to diffuse away from the binding site at the decoupled state when protein-ligand interactions are turned off.

In practice, because they often implement auxiliary restraints, binding free energy prediction workflows that omit binding site restraints rarely yield grossly erroneous predictions. Auxiliary restraints are introduced gradually as protein-ligand interactions are turned off or are introduced at the bound state when the ligand is naturally trapped in the binding site. Either way, the free energy of imposing them can be tracked while preventing the ligand from leaving the binding site at the decoupled state. Provided that the interacting ligand samples only bound configurations, i.e., it behaves as if binding site restraints were present, the current practice of not using them is likely to incur only minor or insignificant errors. 

The Boresch harmonic restraints~\cite{boresch2003absolute,baumann2023broadening} are a popular choice as auxiliary restraints because they are based on interatomic distances, bond angles, and dihedral angles degrees of freedom already implemented in molecular mechanics codes that do not interfere with intramolecular conformational distributions. Moreover, the free energy of releasing Boresch restraints within the simulation box volume $V$ is easily computed analytically~\cite{boresch2003absolute, boresch2024analytical}.

By reducing the conformational space to be sampled, auxiliary restraints are often crucial for obtaining converged binding free energy estimates, even when binding site restraints are employed.
Auxiliary restraints take a variety of forms, such as distance restraints between the ligand and the protein~\cite{mobley2006use,clark2023comparison} as well as flat-bottom restraints. The choice of degrees of freedom and restraining potentials for auxiliary restraints is not as restrictive as for those for binding site restraints, provided that the free energy terms of restraining collective variables that couple protein and ligand degrees of freedom are adequately accounted for to avoid serious systematic errors~\cite{clark2023comparison}.
For example, the overall ligand RMSD has been used~\cite{woo2005calculation} for this purpose. Auxiliary restraints are designed to reduce the amount of conformational sampling at intermediate $\vec{\lambda}$ values. However, more computational effort is required to compute the free energy when the restraints are turned on and off. Additionally, such restraints can limit the exploration of alternative binding modes. This restriction may be undesirable when using Hamiltonian $\lambda$ exchange or expanded ensemble techniques where allowing the ligand to exchange binding modes when it is non-interacting could provide sampling benefits~\cite{wang2013identifying}.
More specifically, flat-bottom restraints allow a ligand to explore multiple binding sites, and harmonic restraints allow the exploration of multiple binding modes within a site, while Boresch restraints only allow a single binding mode within a single site.
See additional discussion of the possibility of multiple binding modes in Sec.~\ref{sec:multiple_binding_modes} below.

Recently, degrees of freedom for binding site and auxiliary potentials based on larger sets of atomic positions of the receptor and ligand have been put forward.
Fu et al. suggested restraining the six relative rigid-body degrees of freedom derived by finding the rotation of the ligand, which minimises the RMSD to a reference structure of the receptor-ligand complex (after accounting for rotation and translation of the receptor)~\cite{fu2017new}. Salari et al. proposed restraining the ``distance-from-bound-configuration'' (DBC) variable, which is the RMSD of ligand coordinates in the frame of reference of the binding site~\cite{salari2018streamlined, ebrahimi2022symmetry}. DBC may allow the binding pose to be closely preserved as the ligand intermolecular interactions are removed, but has the disadvantage of coupling the internal and relative external degrees of freedom of the receptor and ligand, making them unsuitable for describing the binding site macrostate and the corresponding standard state terms. However, these restraints are practical as auxiliary restraints when additional steps are used to introduce and release them. Moreover, because they are based on flat-bottom potentials encompassing the desired binding poses, the free energy of releasing them in the bound state can be safely neglected in most cases. The restraint schemes discussed here are implemented in open-source workflows~\cite{fu2021bfee2, fu2022accurate, santiago-mcrae2023computing, clark2023comparison, hedges2023suite}.

\subsection{Absolute and relative calculations deal with some of the same issues} 

\paragraph{Handling weak binders}\label{sec:weak-binders}
According to the non-covalent statistical mechanics theory of bimolecular binding (Sec.~\ref{sec:theory}), only the conformations in which the receptor and ligand form a bound complex are sampled. Determining an appropriate definition of the bound macrostate can be challenging for weakly bound ligands. For tightly bound ligands, virtually all reasonable definitions of the bound state will lead to equivalent free energies since the partition function will be dominated by a relatively limited ensemble of low-energy poses. However, this simplification breaks down for weak binders.  In fact, there might not be a perfect correspondence between the structural definition of the complex on which current alchemical models are based~\cite{gilson1997statisticalthermodynamic} (Sec.~\ref{sec:theory}) and experimental reporters~\cite{mihailescu2004theory}. For example, isothermal titration calorimetry (ITC) or surface plasmon resonance (SPR) measurements effectively define a binding state that encompasses all ligand conformations complexed with the protein, regardless of where they bind the protein. In contrast, fluorescence polarization competition assays measure binding to only a single location, where the ligand of interest displaces a competing binder. Therefore, care must be taken to ensure that a reasonable definition of the binding site is used~\cite{wang2013identifying}.

Apart from the difficulty of selecting an appropriate definition of the binding site region that relates to the experimental technique, the alchemical theory and the computational procedures are the same whether strong, weak, or non-binders are considered. The alchemical binding free energy calculation will report the binding free energy for the selected binding pose specified, for example, by the region allowed by flat-bottom binding site restraints. Changing the definition of the binding pose will yield a binding free energy for the new pose, which will generally differ from the first. 

Especially when simulating non-binders that are not tightly associated with the receptor, it is likely to observe the ligand exploring the boundaries of the allowed binding site region. In such occurrences, which can also occur when the allowed binding site region is too restrictive, and the ligand is attempting to access a lower free energy pose or when the ligand is initially docked in a high energy pose, it can be expected that the choice of the binding site restraints will have a significant effect on the binding free energy estimate. However, in practice, alchemical binding free energy models are typically employed to identify binders and optimize the affinity of strong binders. Hence, it is often not critical to quantitatively pinpoint the binding free energies of weak and non-binders, as well as their dependence on the binding site definition.

\subsubsection{Changes in net charge can be challenging/problematic.}
\label{subsec:net charge}
If the net charge of the system changes as the alchemical variable changes during the calculation, this can pose major challenges.
Specifically, finite-size effects can introduce significant charge-dependent artifacts into computed binding free energies, in part because typical schemes for long-range electrostatics, including particle mesh Ewald (PME) and reaction field, do not handle free energy contributions from such changes as they would be handled in a hypothetical macroscopic bulk solution. The outcome depends either on the size of the cutoff for reaction field methods or on the size of the simulation box when using lattice sum methods due to periodic boundary conditions~\cite{lin2014overview, ohlknecht2020correcting, rocklin2013calculating}.

Lattice summation methods (e.g. PME) effectively neutralize the simulation box by applying an implicit homogeneously distributed background counter charge~\cite{figueirido1995finite,hummer1996free}. The background charge can be interpreted as a converged distribution of counterions and may be a reasonable choice for computing hydration free energies of monovalent ions (finite size effect corrections can be applied in these cases)~\cite{hummer1996free}. In inhomogeneous systems with different dielectrics, e.g. solvated protein or lipid bilayer in a water box, assuming uniform background countercharge distribution is unphysical, as the higher countercharge density should be located in the regions of higher dielectric~\cite{hub2014pme}. This, in turn, causes significant artifacts in sampled population densities of charged molecules, i.e. errors in calculated free energy differences.

There are two main classes of approaches to address artefacts introduced by changes in net charge during alchemical free energy calculations: (1) avoiding changing the net charge altogether and (2) post-processing approaches to correct for artefacts using continuum electrostatics.
Many relative free energy planning tools have been set up to avoid changing the net charge of the systems considered, including LOMAP~\cite{liu2013lead} and Schr\"{o}dinger's FEP+~\cite{wang2015accurate}. In absolute free energy calculations, it is often difficult to avoid a change in the net charge. One way to avoid charge changes is to ensure that, as a charged ligand is removed, a charged counterion of opposite sign is also removed, or one of the same sign is inserted. This is sometimes referred to as a co-alchemical ion approach to deal with the required charge change. This approach is easily supported in most free energy calculating programs, as it merely involves an additional simultaneous modification.
There are special flavours of the co-alchemical ion approach, such as proposed by Gapsys et al.~\cite{gapsys2015calculation}, which uses a double-system/single-box setup. Here, the two branches of a thermodynamic cycle used in relative free energy calculations are placed in one simulation box, effectively circumventing a change in the overall net charge during a perturbation. 
Note that the co-alchemical approaches only avoid finite-size effects with lattice-sum methods such as PME.
The Alchemical Transfer approach,\cite{wu2021alchemical,azimi2022relative} discussed in Section \ref{subsec:formulations-abfe-rbfe}, is naturally free of charge-changing artefacts because it encodes alchemical binding processes by coordinate transformations that conserve the system's net charge.

Charge-change correction schemes have been explored and offer potentially viable solutions for the problem~\cite{mey2018impact}, where artifacts introduced by finite-size effects are corrected a posteriori from Poisson-Boltzmann calculations ~\cite{chen2018accurate, ohlknecht2020correcting, rocklin2013calculating,Reif2014chargecorrection}. However, application of such corrections is typically inconvenient and computationally demanding. High grid resolutions for the Poisson-Boltzmann calculations are required to avoid numerical artifacts, and it may be necessary to average over multiple representative configurations to obtain reliable results. Furthermore, they rely on continuum electrostatic models, which cannot fully capture phenomena arising from discrete solvent effects. These effects can be quantified in the orientational-disorder limit such that analytical correction terms for this effect exist for solvent models with a single van der Waals interaction site. Readers interested in these conceptual and technical limitations are referred to detailed analyses by Hnenberger and co-workers~\cite{kastenholz2006solvfe, rocklin2013calculating}.
Alternatively, Reif and Oostenbrink demonstrated in a proof-of-concept study that on-the-fly corrections to the physical forces can be effectively used to eliminate finite-size and approximate electrostatic artifacts~\cite{Reif2015onthefly}.

Petrov et al.~\cite{Petrov2024guidelines} investigated the box-size dependencies of alchemical free energy calculations using PME together with the co-alchemical ion approach. They concluded that in neutral simulation boxes with a minimal distance to the box wall larger than 1 nm, finite-size artifacts could be made negligible. The following recommendations should be followed to minimize finite-size artifacts, when using lattice-sum electrostatics: (a) setup of free energy calculations such that there is no net charge change whenever possible, (b) ensuring an overall neutral simulation box, (c) use of a sufficiently large distance between the solute and the box wall, at least 1 nm, and (d) use of salt if possible to screen finite-size periodicity artifacts~\cite{chen2018accurate}. In cases where these recommendations are not practical for specific applications, such as small simulation boxes or when reaction field methods are preferred, charge-change corrections may be applied to reduce artifacts. Though both post-processing corrections and the co-alchemical ion approach come at a cost of increased uncertainties. The Poisson-Boltzmann calculations are approximate due to finite-grid sizes and are applied only to a subset of the ensemble. Co-alchemical ion approaches introduce additional degrees of freedom and increase sampling requirements.

\subsubsection{Handling poorly sampled water networks}
The location of any water molecules within the binding site of interest must be determined prior to carrying out a free energy calculation. Experimental structures, such as those determined by X-ray crystallography and cryo-EM, are often sufficient for this, provided the resolution is good enough. However, we recommend using grand canonical sampling methods\cite{melling2023enhanced, samways2020grand} as a means of verifying the experimental water placement and determining any potential differences owing to the classical forcefield used. Many other water placement methods are available, all varying in their methodology, computational cost and accuracy. Details of these methods can be found in the publication from Samways et al.\cite{samways2021water}.

In relative binding free energy calculations, if the hydration patterns differ between the two ligand endpoints then careful consideration will need to be given to the adaptation of the water network during the free energy calculation. We recommend performing the free energy calculation in the conventional way, i.e. with no enhanced water sampling, to determine whether the water network can adapt to the ligand perturbation itself. This is likely to happen if the hydration site is not particularly occluded from bulk solvent and water molecules can move freely from bulk into the binding site. Similarly, performing calculations in both directions (i.e. using both endpoints as the starting structure) can aid understanding the effect of the water network on the estimated binding affinities. Replica exchange moves in lambda space, instigated from correctly equilibrated water distributions at the end points, may be sufficient to sample water distributions appropriately across a ligand perturbation.

If a conventional sampling method, such as molecular dynamics or Monte Carlo, is unable to rearrange the water network with sufficient efficacy to accommodate the perturbation, then an enhanced sampling method will be required to achieve accurate and converged results. One such approach is to include an absolute free energy calculation of the water molecule into the thermodynamic cycle\cite{ross2020enhancing, hamelberg2004standard, barillari2007classification, yu2008free, ge2022abfewat} such that the free energies of both the ligand transformation, and the decoupling of any displaced water molecules, are calculated separately and combined to achieve the total free energy change for the process. This method can be difficult to use in practice as the water molecule needs to be carefully restrained while being decoupled, and care needs to be taken to ensure water does not diffuse back into the hydration site as the water is decoupled.

Monte Carlo approaches such as the hybrid MC/MD approach proposed by Bergazin et al.\cite{bergazin2021enhancing, ben-shalom2021fast, ge2022enhancing} allow waters to move between bulk solvent and the binding site with greater frequency by proposing MC moves that translate the water molecules within a spherical region that encompasses both bulk solvent and the binding site. This avoids the difficulty of performing a decoupling calculation on the bound waters but can be time-consuming and risks computational time being wasted on move proposals that are not of interest.

Grand canonical (GC) methods propose the addition and removal of water molecules to and from a binding site in accordance with a defined chemical potential. Several implementations of GC moves being coupled to RBFE calculations exist, such as in Schrodinger's FEP+ package, introduced by Ross et al.\cite{ross2020enhancing} with moves proposed both within the binding site (to ensure the correct hydration pattern) and also within bulk solvent (to enhance the sampling of the bulk density). A cavity-bias technique was used for the binding site moves. Grand canonical alchemical perturbation (GCAP)\cite{brucemacdonald2018ligand} is also available in ProtoMS\cite{woods2018protoms}, whereby 2-dimensional titrations are performed in both lambda and chemical potential space. However, given ProtoMS only allows MC sampling to be performed, the configurational sampling of the protein is restricted.

More recently, an OpenMM-based implementation allows for GC moves to be carried out during both equilibrium and nonequilibrium (NES) RBFE calculations\cite{melling2025developing}. These moves are performed in the form of grand canonical nonequilibrium candidate Monte Carlo (GCNCMC) moves\cite{melling2023enhanced} and are run during the equilibration phase at each lambda window in the case of equilibrium FEP calculations, or during the nonequilibrium switch in the NES calculations.

Although often water sampling is less of an issue in ABFE calculations, handling changes to water networks in buried pockets during ligand coupling/decoupling can be addressed in a similar fashion to RBFEs with grand canonical methods.

% in ABFE calculations is less established, although in principle, the same rules apply. When conventional sampling of water is insufficient such that water does not efficiently bind during ligand decoupling, performing extra ABFE calculations for the removal or addition of water molecules to the thermodynamic cycle is one way of ensuring the contribution of these solvent effects is captured. Performing grand canonical water moves along side a more traditional ABFE calculation of a ligand will ensure that any changes to binding pocket hydration states are sampled \textit{in situ}.

Employing the techniques described above with care should allow the water network to adapt during the perturbation of the ligand, ensuring more accurate and converged affinity estimations that are independent of the starting configuration and direction in which the calculation is performed.

\subsubsection{The importance of the alchemical pathway
\label{sec:important_path}}
\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/fig7_what_is_lam/Figure.pdf}
    \caption{Alchemical intermediates are created by making the potential energy depend on an additional variable $\vec{\lambda}$ that interpolates between the chemical endpoints. In (\textbf{A}), at $\vec{\lambda}=0$ the molecule is a fully interacting phenol and at $\vec{\lambda}=1$,  a fully interacting benzene. (\textbf{B}) shows an illustration of the probability distribution of the potential energies as the switching function takes values of $\vec{\lambda}=0$ to $\vec{\lambda}=1$. Intermediates states are required for a sufficient overlap in potential energies to estimate a free energy difference between $\vec{\lambda}=0$ and $\vec{\lambda}=1$.
    Soft-core potentials provide one of the most efficient families of intermediate pathways, with a $\vec{\lambda}$ dependence. In (\textbf{C}) the potential energy surface is coloured according to $\vec{\lambda}$ with blue being $\vec{\lambda}=0$ and $\vec{\lambda}=1$ orange. In (\textbf{D}) the potential is coloured according to the potential energy. Note how as $\vec{\lambda}$ approaches 0, the energy smoothly approaches zero at all $r$, a necessary requirement for efficient and stable calculations.  }
    \label{fig:fig_what_is_lambda}
\end{figure}

Both absolute and relative calculations must choose an alchemical pathway connecting initial and final states. In principle, because of the path independence of the free energy, any arbitrary pathway will give the correct free energy change, but the choice of pathway will greatly affect the efficiency of the calculations. Some choices are particularly crucial---for example, transformations involving insertions or deletions of atoms should employ a soft-core potential path for Lennard-Jones or other interactions with repulsive interactions that go to infinite energy at small radius~\cite{beutler1994avoiding, beutler1994molecular,gapsys2012new}.

The key consideration for choosing alchemical pathways is that the intermediate states that a given pathway produces should sample configurational ensembles that change as slowly as possible as $\vec{\lambda}$ changes, while still managing to go from the initial state to the final state as $\vec{\lambda}$ goes from 0 to 1.

Another way of stating this is that intermediate states should sample molecular configurations that are as similar as possible to their neighboring states. The more similar the configurations are between intermediate states, the lower the statistical uncertainty is in the estimate of free energy between intervals. This can be proven directly from the BAR and MBAR formulas~\cite{bennett1976efficient,klimovich2015guidelines}, though the exact same principles apply for TI. For a 'good' path to work and give a sequence of states with maximally similar configurations, sufficient similarity in potential energies is required. Fig.~\ref{fig:fig_what_is_lambda}\textbf{A} and \textbf{B} illustrate this. Fig.~\ref{fig:fig_what_is_lambda}\textbf{A} shows in a pictorial way a soft-core potential can be applied across different $\vec{\lambda}$s. Fig.~\ref{fig:fig_what_is_lambda}\textbf{B} illustrates the potential energy distributions at the different $\vec{\lambda}$ intermediates, with sufficient overlap between neighboring $\vec{\lambda}$ states to ensure that reweighting estimators such as MBAR can be used for analysis (see Sec.~\ref{subsec:estimators}). The actual transformation is best handled with soft-core potentials of the form shown in Fig.~\ref{fig:fig_what_is_lambda} \textbf{C} and \textbf{B}, with more details given below. 

So what are the options to adjust the potentials between the two end states based on $\vec{\lambda}$? The simplest possible alchemical pathway is a \textit{linear} pathway:
\begin{equation}
U(\vec{q},\vec{\lambda}) = (1-\vec{\lambda}) U_0(\vec{q}) + \vec{\lambda}U_1(\vec{q}) \end{equation},

so-called because the dependence on $\vec{\lambda}$ is linear. This clearly satisfies the basic requirement that it gives the initial endpoint potential energy $U_0(\vec{q})$ when $\vec{\lambda}=0$ and final endpoint energy $U_1(\vec{q})$ when $\vec{\lambda}=1$. 

For many energy terms this is a very good approach, \textit{as long as a repulsive core remains on}. For example, it can be shown that if van der Waals repulsions are left on, then the linear approach is very nearly the optimal path possible for changing, removing, or inserting the electrostatic energy terms, with the alchemical path being within about 10--20\% of the minimum possible uncertainty~\cite{naden2015linear} for a fixed amount of simulation time, as well as being nearly optimally efficient for van der Waals attractive terms with repulsion terms turned on~\cite{naden2014linear}. Although we are not aware of any quantitative tests for dipolar or higher multipole terms, theoretically it should behave equally well for those systems.

However, this approach ends up being terrible for removing or adding repulsive potentials that go to infinity quickly at or near the origin. One way to look at this is to examine how low $\vec{\lambda}$ values must go to reduce the energy at $0.5\sigma$ (the atomic size parameter) down to 1 $k_BT$, where thermal fluctuations make it possible for other atomic sites to penetrate routinely that deep. Assume we are trying to go from a particle being present, and desire to make it disappear alchemically. If the repulsive terms are of the form $\epsilon(\frac{\sigma}{r})^{12}$, and if $\epsilon$ is 1 $k_BT$ at the temperature of interest, and we start with the particle present, we may solve for $(1-\vec{\lambda})(1 k_B T)\left(\frac{\sigma}{0.5\sigma}\right)^{12} = 1 k_B T$. This yields $\vec{\lambda} = 1-2^{-12} \sim 0.999976$. At this point,  we have gone virtually all the way to the end of the transformation, but there is still an impenetrable post in the middle of our simulation! This is not very much like the desired final state of no interactions between the particle and its environment. We can play around with a few ways of modifying this, like simulating many more intermediate states near $\vec{\lambda}=1$. However, various analyses have shown that this is not a very good strategy~\cite{pham2011identifying, beutler1994avoiding, zacharias1994separationshifted, blondel2004ensemble, gapsys2012new}.

What we need instead is a function that smoothly gets rid of this infinity. A large number of schemes have been tried~\cite{beutler1994avoiding, zacharias1994separationshifted, blondel2004ensemble, pham2011identifying, pham2012optimal, naden2014linear, donnini2005incorporating}, but the most common strategy that appears to be the best practice is to use a "soft-core" potential, of the form:

\begin{equation}
    U(\vec{r_{ij}},\vec{\lambda}) = 4\epsilon_{ij} \vec{\lambda} \left(\frac{1}{(\alpha(1-\vec{\lambda}) + (r_{ij}/\sigma_{ij})^6)^2} -  \frac{1}{\alpha(1-\vec{\lambda}) + (r_{ij}/\sigma_{ij})^6}\right)
    \label{eq:softcore},
\end{equation}

where $r_{ij}$ is the distance between two particles $i$ and $j$, $\epsilon_{ij}$ and $\sigma_{ij}$ are the Lennard-Jones parameters corresponding to the interaction between particles $i$ and $j$, and $\alpha$ is a constant. In particular, $\alpha=0.5$ is statistically optimal for the specific functional form shown above. This functional form has exactly the property we are looking for: it recovers the Lennard-Jones potential when $\vec{\lambda}=1$, and the at other endpoint ($\vec{\lambda}=0$), it is exactly zero for all $r_{ij}$ everywhere, and as $\vec{\lambda}$ goes to zero, the $\alpha(1-\vec{\lambda})$ term lowers the infinite energy in the core. There are several different variants of the same functional form~\cite{zacharias1994separationshifted, beutler1994avoiding,pham2011identifying,Lee_JChemTheoryComput_2020_v16_p5512,Tsai_JChemTheoryComput_2023_v19_p640}, but the one given in eq.~\ref{eq:softcore} is easy to understand and implement and fairly numerically stable. This functional form is shown in \textbf{C} and \textbf{D} of Fig.~\ref{fig:fig_what_is_lambda}.

It has been shown that more complicated forms are not significantly more efficient than eq.~\ref{eq:softcore}~\cite{pham2012optimal}. We therefore recommend using the soft-core potential given in eq.~\ref{eq:softcore}, unless there is a compelling reason otherwise. Using a similar equation to eq.~\ref{eq:softcore} may be acceptable in most circumstances if that is what is supported in your chosen software. However, if you are inserting or removing entire atomic sites, we heavily recommend against using the linear approach; it will be very difficult to get correct or converged results. 

So far in this section, we have discussed optimal ways of disappearing or appearing Lennard-Jones interaction sites and turning on and off electrostatics terms. What about performing both transformations at the same time? We cannot turn off the electrostatics linearly at the same time we turn off the Lennard-Jones terms, as it would leave infinitely large attractive and repulsive electrostatic terms "bare" at small $\vec{\lambda}$, resulting in the simulation crashing. It \textit{is} possible to apply the same soft-core approach to the Coulomb interaction as to the van der Waals interaction, and this is indeed done in a number of implementations. In this case, it is important that the Coulomb interaction is softened as rapidly or more rapidly than the Lennard-Jones interaction to avoid charge penetration issues into the repulsive core, which  can be tricky to ensure for multiple types of perturbations simultaneously~\cite{steinbrecher2011softcore}. 

A safe but potentially more computationally expensive approach is to perform the transformations in sequence; first, turning off all electrostatics for atoms that must be removed, inserting and removing Lennard-Jones sites (both the insertion and removal can be done simultaneously), and then turning electrostatics for the introduced particles on. Again, if there are no removals or additions to atomic sites, then it is reasonable to change the interactions in the first and third steps  linearly. 

Other issues, such as whether absolute calculations should retain or remove intramolecular non-bonded interactions
through either annihilation~\cite{hermans1997inclusion, mann2000modeling, boresch2003absolute, wang2006absolute, mobley2006use} or decoupling~\cite{fujitani2005direct, mobley2006use}, must be considered. Reasonable efficiency can be often obtained with either choice even if some are somewhat better or worse than others, and there is no consensus on which is better in most given situations. Our recommendation is to leave the intramolecular interactions on during the transformation for simplicity if there are no other known issues with this approach. The key feature of the simulation to watch out for is whether the total potential energy, and therefore the intermediate ensembles sampled, changes smoothly from beginning to end. Problems of discontinuous changes of the potential energy can be diagnosed by noticing lack of configuration space overlap between different simulations (see Sec.~\ref{sec:are-they-good}).

Relative calculations introduce additional choices, such as the order in which to modify nonbonded interactions.
A common process in single topology relative calculations is, as noted above, to first remove electrostatic interactions of any atoms which will be deleted, then modify other non-bonded interactions, then restore electrostatic interactions of any atoms which are being inserted. Although this is a simpler path to understand cognitively and can take advantage of the soft-core potential from Eq.~\ref{eq:softcore}, this can lead to more intermediate steps and thus be more computationally expensive.
Other schemes, such as simultaneously changing electrostatic and Lennard-Jones interactions with electrostatic soft-core potentials~\cite{steinbrecher2007nonlinear}, as already discussed above, may be implemented with fewer intermediate states but could require fine-tuning of electrostatic and Lennard-Jones soft-core parameters to avoid numerical instabilities~\cite{Tsai_JChemTheoryComput_2023_v19_p640}. 
At the time of writing, there has not been conclusive evidence to suggest the separate or simultaneous approach is in general better than the other, all factors considered, so discretion should be left up to the user as to what is viable from both hardware resources, and what the simulation software supports.

The pathway implemented for the Alchemical Transfer Method (ATM)~\cite{pal2019perturbation,khuttan2021alchemical,wu2021alchemical,azimi2022relative} is an example of an alternative alchemical formulation for binding that does not require soft-core pair potentials and the splitting of electrostatic and non-electrostatic contributions. ATM employs an optimized softplus alchemical potential energy function~\cite{pal2019perturbation} and a soft-core binding energy function that smooths the variations of the perturbation energy $u(\vec{q}) = U_1(\vec{q}) - U_0(\vec{q})$ rather than each pair interaction.\cite{khuttan2021alchemical} The advantage of this approach is that it does not require modifications of the energy routines of the MD engine to implement soft-core pair potentials. Moreover, it has been shown to be applicable without electrostatic/LJ splitting to the transfer of molecules, equivalent to the disappearance and introduction of atoms in conventional single- and dual-topology methods.\cite{khuttan2021alchemical}

A key additional consideration in choosing the alchemical pathway is the choice of spacing of intermediate states.
The spacing depends to some extent on the choice of analysis method, though states should essentially be spaced equidistant in the relevant thermodynamic length~\cite{crooks2007measuring, sivak2012thermodynamic}.
For BAR/MBAR techniques this means that states should be spaced so that the statistical uncertainties between neighboring states be approximately equal~\cite{pham2012optimal, shenfeld2009minimizing}, where "approximately" is roughly within 30-50\% in magnitude. 
Some schemes to adaptively optimize the spacing of intermediate states based on initial exploratory simulations have been proposed~\cite{hayes2017adaptive}. For molecules changing in dense solvent, then the best path is roughly independent of molecule size and shape, so what works for one molecular transformation is likely to be relatively efficient for another~\cite{monroe2014converging}.

Additional approaches have attempted to find alternative pathways to improve efficiency or find paths of low thermodynamic length~\cite{naden2014linear,naden2015linear,pham2012optimal}. For example, the enveloping distribution sampling (EDS) approach, and its multiple-replica and accelerated variant, works to improve efficiency by creating a single artificial intermediate state which simultaneously samples all end state phase spaces~\cite{perthold2018accelerated,sidler2017efficient, christ2007enveloping}. When this can be done, it provides an extremely efficient way to calculate the relative free energy difference between multiple ligands from a single simulation. However, it can often fail whenever the simulation of this intermediate state ends up trapped in configurations characteristic of only one end state. Thus, successful use of EDS can require system-dependent tuning, making it difficult to implement in an automated and reliable way. However, when successful, it can be very efficient.

In our view, there is still some room for further exploration of how to best choose transformation pathways, especially for relative binding calculations or more complex molecules, as most existing studies focus on smaller molecules. As we have stressed, in principle, any pathway that connects the desired end states is rigorously correct, but as discussed above, different paths may differ dramatically in thermodynamic length and therefore efficiency. Additionally, some paths simply may not converge due to issues noted above such as those encountered without soft core potentials. However, the recommendations above are reasonable, reliable, and are likely not that much less efficient than potentially more optimal choices~\cite{naden2014linear,naden2015linear,pham2012optimal}, as the real problems with the efficiency of calculating free energies are lack of sampling of slow conformational modes, rather than the lack of efficiency of the transformations. 

It is however important to note that different packages also differ in how they handle implementation of alchemical transformations, making it difficult to give rules of thumb concerning specific efficient transformations which work equally well across simulation packages. Thus, we are hesitant to recommend best practices within specific software packages at this point in time, although any good transformation pathway will conform to the guidelines we have outlined above.

\subsubsection{The importance of configurational sampling}
\label{sec:configurational_sampling}
As mentioned previously, free energy differences estimated from alchemical calculations should be independent of the initial system conformation, given sufficient configurational sampling. In cases where the system's slowest degrees of freedom are coupled with the alchemical variable, transitioning between alchemical states can indirectly enhance configurational sampling. This effect is particularly pronounced when certain alchemical states, such as the decoupled state or loosely coupled states, lack the energy barriers often present at the fully coupled state (e.g. $\lambda=0$ in Fig. ~\ref{fig:configurational_sampling}\textbf{A}), thereby allowing the system to bypass otherwise prohibitive configurational free energy barriers. For example, in a protein-ligand unbinding process where the kinetic barrier is predominantly associated with the disruption of intermolecular interactions or the separation of binding partners, simulating different intermediate states effectively samples configurations with varying center-of-mass distances, thus mitigating the sampling issue in the configurational space. 

Conversely, when the slowest degrees of freedom in the configurational space are largely orthogonal to the alchemical variable, the system can be stuck in its initial metastable state. Such entrapment leads to discrepancies in free energy estimates from simulations initiated from different conformations. This scenario, as illustrated in Fig.~\ref{fig:configurational_sampling}\textbf{B}, is not uncommon especially in flexible systems. For example, it can arise when the free energy difference of interest needs to account for metastable states separated by torsional barriers, such as the solvation free energy of a ligand having different rotamer states, the methylation free energy of a nucleobase in a duplex ~\cite{hsu2023alchemical}, and the binding free energy that involves flexible side chains near the binding site~\cite{la2022alchemical}. Similar sampling challenges have also been reflected in several recent studies, which highlight the sensitivity of alchemical calculations to initial conformations, whether derived from crystallographic structures~\cite{suruzhon2021sensitivity, baumann2024impact} or docking protocols~\cite{cappel2020impact}. 

Similarly, Fig.~\ref{fig:configurational_sampling}\textbf{C} highlights the importance of configurational sampling in alchemical calculations, where a free energy basin spans both the alchemical and configurational coordinates, potentially trapping the system in both dimensions. This can occur, for instance, when electrostatic interactions are turned off while van der Waals interactions remain, rendering the alchemically transformed molecule a ``greasy ball''. Notably, in cases where alchemical biases/weights are applied to facilitate even alchemical sampling across states, such as in an expanded ensemble simulation~\cite{lyubartsev1992new}, scenario Fig.~\ref{fig:configurational_sampling}\textbf{C} may evolve toward scenario Fig.~\ref{fig:configurational_sampling}\textbf{B} as the alchemical free energy profile is flattened out, while the basin in the configurational direction persists. 

\begin{figure}
    % Figure to be updated
    \includegraphics[width=0.88\columnwidth]{figures/fig_configurational_sampling/FES_scenarios_path.pdf}
    \caption{\textbf{Different scenarios of free energy surfaces.} In scenario \textbf{A}, the free energy barrier present at $\lambda=0$ is absent at other $\lambda$ states, so the system can go around the barrier by alternating sampling between alchemical and configurational space, e.g. via the path shown as the dashed line. In contrast, in scenario \textbf{B}, the free energy barrier extending all alchemical states prevents the system from sampling both metastable states at $\lambda=0$. In scenario \textbf{C}, the free energy basin extending in both alchemical and configurational directions can trap the system.}
    \label{fig:configurational_sampling}
\end{figure} 

There are multiple strategies to alleviate such sampling challenges in an alchemical calculation. A straightforward but computationally expensive method is to run longer simulations with multiple replicas to increase conformational heterogeneity~\cite{suruzhon2021sensitivity}.
If using a large number of replicas these are often termed ensemble approaches and an example of such a sampling scheme is the TIES method~\cite{bhati2017} developed by Bhati et al., where a minimum of 5 to 10 replicas are recommended to make up the ensemble for RBFE and ABFE calculations respectively~\cite{bhati2022, bhati2025}.
Another approach, known as integration over parts~\cite{jayachandran2006parallelized}, involves performing separate alchemical calculations limited to a series of binding macrostates and  then computing the overall free energy difference using the free energy combination formula~\cite{gallicchio2011recent,hsu2023alchemical}, i.e., computing the negative log-sum-exp of the Boltzmann weights from each macrostate. In the integration over parts approach, restraining potentials can be used to restrict the sampling to specific macrostates~\cite{khuttan2023taming}. However, in practice, restraining potentials are sometimes omitted when the states are known to be separated by large free energy barriers and do not interconvert within the simulation time scale, such as cases like Fig.~\ref{fig:configurational_sampling}\textbf{B}.
A generally more effective strategy is to bias relevant configurational collective variables (CVs) during the alchemical simulation. This can be achieved by enhancing sampling within individual alchemical states and swapping conformations between alchemical states (preferably from states separated by large free energy barriers) via replica exchange protocols. More recently, several approaches have been proposed to simultaneously bias both configurational CV and alchemical variables, which can effectively address both scenarios Fig.~\ref{fig:configurational_sampling}\textbf{B} and \textbf{C}. Examples include alchemical metadynamics~\cite{hsu2023alchemical}, $\lambda$-ABF (adaptive biasing force)~\cite{lagardere2024lambda}, and optimized alchemical enhanced sampling (ACES)~\cite{lee2023aces}  and approaches that integrate well-tempered metadynamics~\cite{barducci2008well} with alchemical methods~\cite{zhou2025zooming, khuttan2024make}, to name a few.

Notably, detecting and addressing configurational sampling challenges in alchemical calculations remains a non-trivial task. In relative free energy calculations, large cycle closure errors are commonly used as indicators of insufficient sampling, although small errors do not necessarily imply that sampling is adequate~\cite{suruzhon2021sensitivity}. Measurement of the sensitivity of individual edges in the thermodynamic graph to the enforcement of cycle closure constraints can help to identify problematic alchemical transformations~\cite{giese2025transferability}. In other types of calculations, diagnosing sampling deficiencies typically requires prior knowledge of relevant metastable states, as well as collective variables that distinguish them. Such collective variables are often based on physical intuition, experimental insights, or preliminary computational analyses. However, optimal collective variables arerarely known \textit{a priori}, complicating the systematic detection of sampling issues. Although recent ad-hoc machine learning methods for optimal CV identification have shown promise~\cite{gokdemir2025machine, sidky2020machine, bonati2021deep} and could in principle be straightforwardly integrated into alchemical sampling protocols, systematic studies explicitly demonstrating such integration have yet to appear. Consequently, widely accepted best practices about automated diagnostic protocols capable of identifying and resolving configurational sampling bottlenecks have not yet been established. 

\paragraph{Conformational sampling challenges can affect both solvation and binding free energies}
While sampling challenges are often perceived to be minor for small molecules especially in hydration free energies, however, they can still be non-trivial. Even subtle degrees of freedom such as orientations of the hydroxyl group (as in neutral carboxylic acids) or intramolecular hydrogen bonding can influence the calculated free energy difference between two environments\cite{klimovich2010predicting, lim2019assessing}. Molecules with multiple rotatable bonds, internal hydrogen bonds, or conformational flexibility may exhibit environment-dependent populations that are difficult to sample adequately within the timescale of typical molecular dynamics simulations. Typically, solvation free energies are computed as absolute transformations, meaning that as the size and flexibility of the ligand increase, the sampling burden grows and convergence of the free energy estimate becomes more challenging. In some cases, enhanced sampling techniques such as replica exchange\cite{rest2} or metadynamics\cite{hsu2023alchemical, khuttan2024make} may be beneficial, even in hydration or partition coefficient calculations.

In partition coefficient calculations, the situation becomes even more complex, as two distinct environments must be adequately sampled: typically water and a nonpolar organic solvent. These systems not only differ in their dielectric properties and hydrogen bonding behavior but may also yield different dominant solute conformers. The partition free energy is sensitive to the relative population of conformers in each environment, so it is essential to ensure that sampling in each phase is independently converged. It is also important to ensure adequate overlap in the common end statesif the solute is collapsed to two different gas-phase or non-interacting states, the thermodynamic cycle may not hold\cite{fan2021sampl7}. Some studies have employed restrained or confining potentials to prevent solutes from drifting to the interface (especially when using periodic systems with both phases present), while others model each phase separately and compute the free energy difference via thermodynamic cycles\cite{turchi2019,bannan2016,petris2021}.

These challenges are magnified in binding free energy calculations, where sampling all relevant conformations within reasonable timescales becomes even more difficult.

\subsubsection{What $\lambda$-sampling schemes are available?}
\label{sec:sampling_schemes}
Though all alchemical simulations must sample from multiple $\vec{\lambda}$ states, different approaches can be used to achieve this. Fig.~\ref{fig:fig_sampling_scheme} illustrates the four most common schemes. The simplest approach involves running an independent simulation at each of the predefined $\vec{\lambda}$ values (see Fig.~\ref{fig:fig_sampling_scheme}\textbf{A}). This type of scheme is currently used for some AMBER TI calculations~\cite{song2019using} and for Sire as implemented in BioSimSpace~\cite{hedges2019biosimspace}. However, if these simulations can be run simultaneously with communication between them, a simple extension allows mixing between these replicas. In this approach, the simulation at each $\vec{\lambda}$ can undergo periodic exchanges with neighboring $\vec{\lambda}$ values. This form of replica exchange, called Hamiltonian replica exchange, is based on ideas developed from Monte Carlo simulations of spin glasses by Swendsen and Wang~\cite{swendsen1986replica}. With the Metropolis-Hastings acceptance criterion for exchanges, the generated ensemble of all replicas still samples from the Boltzmann distribution for each replica. This approach has been used in many different contexts for molecular simulations~\cite{sugita2000multidimensional,sugita1999replicaexchange, woods2003development, jiang2010free}. The basic idea of the replica exchange scheme is shown in Fig.~\ref{fig:fig_sampling_scheme}\textbf{B}. It is supported in various software packages that provide alchemical implementations, such as GROMACS~\cite{aldeghi2015accurate}, GROMOS~\cite{hritz2008hamiltonian,hritz2007optimization},
AMBER~\cite{Lee_JChemInfModel_2020_v60_p5595}, FEP+~\cite{wang2015accurate}, NAMD~\cite{jiang2019computing}, and OpenMM~\cite{rufa2020chemical,azimi2022relative}.
A specific variant of Hamiltonian replica exchange is FEP/REST2~\cite{rest2, feprest} that involves ``heating'' a small portion of the protein-ligand system to enhance the sampling within the binding pocket. It has been promoted as a great way to enhance sampling and is employed by default in Schr\"{o}dinger's FEP+ package. However, it should be noted that several studies have questioned its reliability and reported that it degrades the quality of free energy predictions as compared to those based on standard MD simulations without any enhanced sampling~\cite{wan2020fep+, bhati2022}. Therefore, a blind application of this sampling scheme is not recommended and it must be used with caution if at all. A variant of this method that overcomes some of the reported issues with FEP/REST2 is called alchemical enhanced sampling (ACES)~\cite{lee2023aces}. ACES creates localized targeted "enhanced sampling states" that are connected to the real state end-points through HREMD.  The method leverages the dual topology framework to produce a concerted counter-diffusion of alchemical states that leads to minimal rearrangement of the environment along the alchemical path~\cite{York_ACSPhysChemAu_2023_v3_p478}. The computational overhead of the method is negligible relative to more conventional alchemical free energy simulations with HREMD.

A third approach borrows ideas from simulated tempering~\cite{marinari1992simulated}. In this scheme a single replica rapidly explores all of $\vec{\lambda}$ space by working out optimal weights that allow switching between different intermediate $\vec{\lambda}$ values, as seen in Fig.~\ref{fig:fig_sampling_scheme}\textbf{C} . This approach is also referred to as self-adjusted mixture sampling~\cite{lyubartsev1992new, li2007simulated, tan2017optimally} and while promising, has so far only been supported in OpenMM Tools~\cite{andrearizzi2019choderalab} and GROMACS.  Although this approach allows multiple states to be simulated in a single simulation, the weights do not always converge to the proper equilibrium distribution, and care must be taken that the final results are converged. 

The non-equilibrium (NEQ) switching (Fig.~\ref{fig:fig_sampling_scheme}\textbf{D}) approach makes use of short out-of-equilibrium simulations~\cite{aldeghi2018accurate}. In this protocol, only end state $\vec{\lambda}$ replicas ($\vec{\lambda}$=0, $\vec{\lambda}=1$) are simulated at equilibrium; intermediate information is generated from non-equilibrium simulations that rapidly transition between end states. 
Over the course of each transition, Hamiltonian derivative with respect to $\lambda$ is recorded; subsequently the curves are integrated to yield work distributions for the forward and reverse processes. Crooks Fluctuation Theorem~\cite{crooks1999entropy} allows estimating free energy difference between the end states from the generated work distributions.~\cite{shirts2003equilibrium}

The NEQ approaches offer some advantages over the equilibrium sampling based methods. For example, the NEQ protocol allows equilibrium simulations of each end-state to be performed independently without pre-defining a ligand network: the transitions between the ligands can be generated afterwards. This eliminates the redundant equilibrium sampling if one end state is present in multiple perturbations. Equilibrium sampling based approaches would require sampling the central ligand for each edge, while NEQ would sample it once and connect to the other ligands afterwards. The NEQ protocol also provides a simple way to combine different structures in free energy calculations, e.g. simulations in states at $\lambda=0$ and $\lambda=1$ may be initialized with the independently generated ligand coordinates. 

%MRS: I think this below is a little too detailed for a general introduction of NEQ, as we should be talking about general strategies, not specific ones.  Probably we should be putting in a few references for key NEQ uses so readers could follow up, however, THat would be useful to have here.  


%MRS: was this sentence the one with the violated assumptions?  please check, I am note sure. 
%Another example would be using true apo and holo protein structures as the end states to initialize simulations for absolute binding free energy calculations. 


%Bhati \textit{et al.} recently published two studies directly comparing the equilibrium (EQ) and NEQ approaches at unprecedented scales for both RBFE and ABFE calculations using their ensemble simulation-based TIES method~\cite{wan2023eqvsneq, bhati2025}. Further, they systematically studied the effect of various parameters involved in setting up calculations for both approaches and recommended optimal protocols in each case for industrial applications. They highlighted several limitations of the NEQ approach that should be accounted for while performing such calculations to ensure reliability of predictions.

The non-equilibrium approach is available in GROMACS and Amber. A closely related method, termed non-equilibrium cycling, is available in OpenMM. Among the commercial packages, it is implemented in OpenEye's Orion{\textregistered}~\cite{sorensen2024orion} platform.
%A schematic of this approach is shown in Fig.~\ref{fig:fig_sampling_scheme}\textbf{D}. 

\begin{figure}
    \includegraphics[width=0.88\columnwidth]{figures/fig8_sampl_scheme/Figure.pdf}
    \caption{\textbf{Four most common sampling strategies.} (\textbf{A}): Multiple replicas in parallel at different lambda states. Each arrow symbolises an independent $\vec{\lambda}$ simulation. (\textbf{B}): Hamiltonian replica exchange scheme. Each arrow represents a short simulation interval before an exchange through Metropolis Hastings acceptance (dice) is attempted. A tick means an accepted exchange, a cross a rejected exchange. (\textbf{C}): Single replica scheme sampling from all $\vec{\lambda}$ states. After a short simulation time symbolised by the arrow, the lambda-state is attempted to change until all N lambda states will be sampled. (\textbf{D}): Non-equilibrium sampling scheme, where two equilibrium simulations at the end states are run as indicated by the blue and pink arrow. Non-equilibrium simulations are attempted at intervals to switch between the two end states.}
    \label{fig:fig_sampling_scheme}
\end{figure} 

%Currently, we recommend using Hamiltonian replica exchange type sampling schemes (Fig.~\ref{fig:fig_sampling_scheme} \textbf{B}). If these are not available in the code of choice, running independent simulations at different $\vec{\lambda}$ values can be acceptable, especially when configurational sampling is fast (Fig.~\ref{fig:fig_sampling_scheme} \textbf{A}). Single replica schemes and non-equilibrium schemes are not as established yet because of potential failure modes, but are very promising for use in the near future. 
%MRS: doesn't below here. 
%Further, ensemble simulations are recommended irrespective of the choice of sampling scheme to ensure reliability of results~\cite{bhati2018, bhati2019, wan2020fep+, wade2022, wan2021uq, bhati2025, wan2023eqvsneq}.


%MRS: This should be broken up into two sections - 
% The second of which is "what information should be saved - that should really be separated. 
% The first one should be perhaps, " How much simulation data should I collect" and THIS is where we should put discussions of ensembles versus long siulations.  I think the question "how long should I run?" is not the right questions, because as Agastya points out, how to break them up between MULTIPLE runs is an important discussion we should have.

\subsubsection{How long should I run my simulation for and what information should be saved?}
\label{sec:sim_length_information_kept}
Before launching alchemical free energy calculations it is wise to consider how convergence and completion will be assessed. Different conditions on when to stop alchemical free energy calculations should be determined, and this may require several iterative checks and therefore modifications to the calculation protocol.
One useful metric to use for termination is the expected or desired uncertainty of a desired free energy estimate, though care must be exercised should the uncertainty estimate prove unreliable.
In particular, if the rate of change in the free energy estimate is significant when this condition is met, the simulation may not be locally converged, and more sampling may be necessary to determine a stable free energy estimate which is no longer changing significantly over time. 
A few studies reported systematic variation of simulation lengths using ensemble simulations over an extended range to provide recommendations on appropriate values applicable for most protein-ligand systems. The authors suggest using 4 ns and 10 ns for RBFE~\cite{bhati2017, bhati2022, wan2023eqvsneq} and ABFE~\cite{bhati2025} calculations respectively. These values may be used as a general guideline in cases where the goal is to determine binding affinity for a given starting structure. However, these guidelines do not hold if one is interested in studying the kinetics and/or the starting structure available is not representative of the equilibrium structure.

However, this is not the only metric which can or should be used, as the uncertainty only captures the information about the sampled phase space, not necessarily the entirety of the phase space.  
For example, convergence of relative free energy calculations in predictive simulations where the entire phase space is not known in advance requires sampling the different kinetically stable states~\cite{mobley2012perspective}. 
This highlights the importance of choosing the correct thermodynamic path to ensure you sample the required thermodynamic states as discussed in Sec.~\ref{sec:important_path}.

The condition of minimizing the statistical uncertainty of different free energy estimators below a sufficient threshold should be one metric monitored over the simulation. This can be done through the uncertainty estimator built into certain analysis tools such as MBAR, or through more general statistical tools like bootstrap sampling. It should be noted however, that uncertainty estimates have the same limitations as other metrics of convergence, as they are only an uncertainty based on the phase space sampled so far in a simulation, and cannot account for states not sampled, and it is worth considering that they will be an underestimation of the true uncertainty~\cite{wan2020fep+, wan2021uq, vassaux2021, gapsys2020large, wade2022, bhati2017, bhati2022, bhati2025, wan2023eqvsneq, bhati2018, bhati2019, cournia2017relative, gapsys2021accurate, baumann2021, caves1998}.
A target statistical uncertainty should be chosen at the onset of the simulation to avoid excessively long simulations, or falling into the trap of running until the free energy estimate is "good enough," which is subjective and has no defined criteria. This could be a fixed value such as $0.20$ kcal/mol, or a functional quantity such as "below $0.5$ kcal/mol and $10\%$ of the free energy estimate." The user does not need to monitor this information in real-time and can choose to run simulations for fixed duration (either time or number of samples) and run analysis on the data collected thus far. If more samples are needed, the simulations can be resumed, or, started again in different initial conditions enlarging the overall simulation ensemble. 
Bhati \textit{et al.} recommended such a scheme for RBFE and ABFE calculations using TIES~\cite{bhati2022, bhati2025, wan2023eqvsneq, coveney2022corners}. They suggest a set of optimal parameters (ensemble size, simulation length, number of lambda-states, number and length of NEQ transitions, etc.) to be used initially and suggest pre-defined criteria (uncertainties below 0.5 kcal/mol and overlap between forward and reverse work values in case of NEQ calculations) to decide on the need of additional calculations (in the way suggested) until these criteria are met.

Convergence in other alchemical observables should also be monitored to determine if the defined phase space has been sufficiently sampled and enough decorrelated samples have been drawn. These additional observables include, but are not limited to, the variance in $\frac{dU}{d\vec{\lambda}}$ across all $\vec{\lambda}$ values, calculating the variance in free energy using bootstrap analysis, and comparing differences in free energies calculated using different percentages of the simulation in both the forward and reverse directions~\cite{klimovich2015guidelines} (see Fig.~\ref{fig:convergence_forward_reverse}).

\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{figures/fig10_forward_reverse/Figure.pdf}
    \caption{\textbf{Free energy (in $k_{B}T$) for two different relative binding free energy perturbations.} 
    Each plot shows the estimated free energy change using a varying fraction of total simulation time (up to 5 ns total). 
    Subplots (\textbf{A}), (\textbf{C}), and (\textbf{E}) show a three step protocol for a perturbation involving 3 perturbed atoms, while (\textbf{B}), (\textbf{D}), and (\textbf{F}) shows the same protocol for a perturbation involving 10 perturbed atoms. The first step of the protocol is the decharging then removing van der Waals interactions and then recharging. The difference in energy between the forward (blue) and reverse (red) free energy calculations at the midpoint of the simulation time gives an indication of the overall convergence of the simulation, with differences over 1 $k_{B}T$ indicating poor convergence.}
    \label{fig:convergence_forward_reverse}
\end{figure}

Each of these metrics shows some promise for diagnosing when a simulation has a convergence issue beyond simple convergence of uncertainty estimates. 
Results obtained from calculations with convergence issues should be checked for errors or run for longer before any confidence should be placed in conclusions drawn from their analysis.
For example, in relative calculations ligands that share similar binding modes and do not induce large conformational changes when in complex with protein, the need to sample exhaustively to converge estimates in free energy differences is often minimal due to the locality of sampling changes in the molecular topology and shared phase space of the core atoms.
However, even subtle induced changes in protein binding configuration will require more sampling or cause local convergence to a free energy estimate that has high error.
The confidence a user should have in a free energy estimate is significantly improved when both the uncertainty of the free energy estimate is low, and when other observables have reached a convergence.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{figures/fig_pmf/pmf.png}
    \caption{{\bf Potential of mean force with respect to $\vec{\lambda}$ for TI and MBAR}
    The estimated PMF for a bound calculation of a Tyk2 ligand pair of Wang et al.~\cite{wang2015accurate} with respect to $\vec{\lambda}$ estimated from TI and MBAR and showing agreement within errorbars. 
    }
    \label{fig:pmf}
\end{figure}

The uncertainty in the free energy, for example, can be estimated in multiple ways, e.g. through standard error propagation methods (including MBAR's estimator, which is based on the same principles as standard error propagation), through bootstrap methods, and through ensemble simulations. 
%However, as we have repeatedly pointed out, only ensemble simulations can capture the true uncertainty in MD based predictions. All other methods underestimate the true uncertainty as reported by several authors~\cite{wan2020fep+, wan2021uq, vassaux2021, gapsys2020large, wade2022, bhati2017, bhati2022, bhati2025, wan2023eqvsneq, bhati2018, bhati2019}. 
Independent of how the property is estimated, it is important to remember that results of any free energy analysis are \textit{estimations of the given property}, not the true underlying value of the property itself. 
These estimators are usually consistent estimators, meaning they will converge to the true answer in the limit of sufficient sampling, not necessarily unbiased ones though.
As such, it is a good idea to subject different estimators to the same data to see if they yield either the same estimate (within error and bias), or if they fluctuate wildly. See, for example, the potential of mean force with respect to $\vec{\lambda}$ estimated from a bound simulation of a Tyk2 ligand pair of Wang et al.~\cite{wang2015accurate} for both the MBAR and TI estimators, as seen in Fig.~\ref{fig:pmf}.
This is not a perfect method as some estimators, such as exponential averaging, will converge significantly more slowly, relative to more accurate estimators like MBAR. 
Therefore, it is a good idea to apply the estimators to different fractions of the data to see if the main estimator of free energy you have chosen is stable.

Each method requires different data from the simulation be collected. If, for instance, the free energy estimator selected is thermodynamic integration, then values of $\frac{dU}{d\vec{\lambda}}$ at uncorrelated data points must be collected. Once you have made a choice of the combination of the type of simulation you will run, which alchemical topology you will simulate, what alchemical path you will simulate along, and what your stopping conditions are, then you are ready to enumerate the information you should capture. Below is a sample of the minimal information you need for a set of common estimators (discussed in more detail in Sec.~\ref{subsec:estimators}):

\begin{itemize}
    \item Thermodynamic Integration (TI) requires $\frac{\partial u(\vec{q})}{\partial\vec{\lambda}}$.
    \item Exponential Averaging (EXP) needs \textit{either} $\Delta u_{k,k+1}(\vec{q})$ or $\Delta u_{k,k-1}(\vec{q})$, depending on the direction its being evaluated in.
    \item Bennett Acceptance Ratio (BAR) needs \textit{both} $\Delta u_{k,k+1}(\vec{q})$ and $\Delta u_{k,k-1}(\vec{q})$.
    \item Weighted Histogram Analysis Method (WHAM) and Multistate Bennett Acceptance Ratio (MBAR) both need the complete set of $\Delta u_{k,j} \, \forall \, j=\{1...K\}$. WHAM must have this same information binned with some choice of bin width small enough not to affect the results.
\end{itemize}

The potential derivative required for TI should generally be calculated during the simulation; only under very rare circumstances~\cite{naden2015linear} can it post-processed by a code that does not evaluate the derivatives. Many codes already have options for doing this.
If that option is unavailable, you can estimate it through finite difference (if sufficient information is collected), but this will introduce significant error, and is generally not a best practice. The BAR estimator may be a better, and simpler choice at that point as you will have at least the same level of information. 

The potential energy differences required for EXP, BAR, MBAR, and WHAM can be calculated either during the simulation or in post-processing. It is recommended to calculate the potential differences in code when possible to avoid extra overhead and possible errors produced by evaluating the energy of the configuration twice, and to reduce the amount of stored information. 
Although potential energy derivatives must usually be calculated in code, they can sometimes be easily computed in post-simulation analysis. 
For example, if the alchemical path you have chosen is a linear alchemical path, then $\frac{du}{d\vec{\lambda}} = u_1(\vec{q}) - u_0(\vec{q}) = u(\vec{q})$, which is the perturbation energy $u$--the potential energy difference between the initial and final states. These values are already calculated by the simulation and can be recorded easily without additional computational expense. As discussed earlier, linear paths are inefficient. However, methods such as EDS and ATM, based on optimized non-linear energy interpolation alchemical energy functions $W_\lambda(u)$ that depend on atomic coordinates only through the perturbation function,~\cite{konig2021efficient,azimi2022relative} can achieve high computational efficiency by sampling and storing only perturbation energy values. The stored values can then be analyzed in post-processing to, for example, evaluate algebraically the $\Delta u_{k,j}$ quantities needed by multistate analysis (see above). 

Free energy information should generally be saved more frequently than coordinate data, approximately at the rate that uncorrelated samples are produced.  
The on-disk size of the data for free energy estimation is often significantly smaller than full atomic coordinates, so the information can easily be collected frequently. 
However, the information should not be collected \textit{every} time step, as most free energy techniques are operated at equilibrium, and need equilibrated \textit{and decorrelated} samples for an unbiased estimate.
Samples collected every time step will likely result in most samples being discarded due to the detection of correlation in the time series by decorrelation routines in the analysis. However, if it is computationally cheap and disk space is plentiful, do save often. One may safely assume that the correlation time is greater than 100-200 fs even for relatively simple systems such as small molecules in solvent, so saving no more frequently than every 50-100 steps is recommended. 
How decorrelation impacts calculations, and how to compute it is discussed in Sec.~\ref{sec:decorrelating-samples}.

In general, uncertainties can be assumed to decrease as $1/\sqrt(N)$ where $N$ is the number of uncorrelated samples, for all standard free energy calculation methods~\cite{shirts2005comparison}. However, this carries the notable caveat that such estimates require accurate estimation of the correlation time which, if important motions are slow compared to simulation timescales, can be difficult. Still, this metric provides a good rule of thumb, and as long as conformational transitions are captured by the simulation, increasing the aggregate simulation time by a factor of $T$ will reduce the uncertainty by a factor of approximately $\sqrt{T}$.

\subsubsection{Multiple or uncertain binding modes may require considerable care}
\label{sec:multiple_binding_modes}
In a discovery setting, new ligands can have unknown or at least uncertain binding modes~\cite{kaus2015how, plountprice2000analysis,mobley2009binding,calabro2016elucidation}, complicating binding free energy estimation.

To deal with prospective ligands with unknown binding modes, discovery projects commonly assume that modifications of functional groups on a common scaffold result in a consistent binding mode across all members of a series.
This is not necessarily always the case~\cite{kaus2015how}, as reviewed elsewhere~\cite{mobley2009binding} and in some cases unexpected binding mode changes can be the origin of apparent non-additivity in structure-activity relationships~\cite{calabro2016elucidation}.
Binding modes also tend to be particularly variable in the case of fragments, which often may have multiple relevant binding modes~\cite{steinbrecher2015accurate}.


Absolute free energy calculations for dissimilar ligands can have particular challenges because the (potentially incorrect) assumption of consistent binding modes across a series of similar ligands is likely to be even less robust than in the case of relative calculations.
This means that researchers performing absolute binding free energy calculations will have to pay particular attention to generating reasonable putative binding modes.

In some cases, it is tempting to simply use docking techniques to generate initial bound structures for starting molecular dynamics simulations.
However, timescales for binding mode interconversion are usually slow compared to MD/free energy timescales, meaning that simulations started from different potential binding modes are likely to yield disparate computed binding free energies~\cite{mobley2006use, palma2012computation, mobley2012perspective, gill2018binding}. Moreover, docking techniques are good at identifying sterically reasonable potential binding modes, but still perform relatively poorly at identifying a single dominant binding mode \emph{a priori}. 


It is worth highlighting a recent SAMPL blind challenge on HIV integrase as an illustration of this. 
Many submissions, using state-of-the-art methods, had difficulty even predicting which \emph{binding site} ligands would bind in---most submissions placed more than half of the ligands into the incorrect binding site---and even given correct binding sites, the binding mode within each site was also quite difficult to predict~\cite{mobley2014blind}.
The best performing submission for predicting binding modes actually ended up being a human expert (aided by computational tools) with more than 10 years of experience on the particular target~\cite{voet2014combining}, rather than a fully automated approach.
While free energy calculations on this set had some success, many of the failures actually ended up being cases where the binding mode selected as input for free energy calculations was later found to be incorrect~\cite{gallicchio2014virtual}, highlighting the importance of these issues.

One approach which has shown some success in identifying accurate binding modes \emph{de novo} is to retain diverse potential binding modes from docking, perform short MD simulations of these to identify distinct stable binding modes, and then consider only these stable modes in subsequent calculations~\cite{gallicchio2014virtual, mobley2006use,rocklin2013blind, boyce2009predicting, mobley2007predicting}.


Routes to handle multiple potential binding modes are different depending on whether absolute or relative calculations are selected, unless a method is available to estimate the relative populations of different stable binding modes in advance (e.g. such as the BLUES approach currently in development~\cite{gill2018binding}), in which case this approach could be applied to assist both types of calculations.

\paragraph{Handling multiple potential binding modes within absolute calculations.}
Within absolute binding free energy calculations, multiple potential binding modes can be handled by two main strategies: Considering each binding mode separately (a separation of states strategy) or sampling all binding modes within a single simulation~\cite{mobley2012perspective}.
This couples to the choice of restraints selected, as some restraints will allow transitions between binding modes and even binding sites (Sec.~\ref{sec:standardstate-restraints}), and others do not.

Sampling all potential ligand binding modes within a single free energy calculation is usually impractical without some form of enhanced sampling or at least Hamiltonian replica exchange~\cite{wang2013identifying} because barriers for binding mode interconversion result in kinetics which are too slow compared to simulation timescales~\cite{mobley2006use, palma2012computation,mobley2012perspective, gill2018binding}.
Hamiltonian exchange, coupled with appropriate restraints, can allow the ligand to relatively rapidly exchange between potential binding modes when non-interacting, accelerating sampling of binding modes~\cite{wang2013identifying}. However, it is not always clear that this is desirable, since this also increases the size of the configuration space which must be sampled even if the binding mode is known.

Separation of states provides a simple though potentially expensive alternative, where each stable binding mode is considered separately with a binding free energy calculation restricted to that binding mode, and then (as long as the binding modes are non-overlapping) the resulting component binding free energies can be combined into a total~\cite{mobley2006use, mobley2012perspective}.
This approach necessitates a separate binding free energy calculation for each potential binding mode, however, so it can be computationally quite costly.
If relative populations of different stable binding modes were available from some other technique, it could make this separation of states approach considerably more efficient~\cite{mobley2012perspective, gill2018binding}.

\paragraph{Handling multiple potential binding modes within relative calculations.}
Multiple potential binding modes pose particular problems for relative free energy calculations, as having multiple starting structures for these calculations could yield substantially different calculated relative binding free energies for the same transformation due to kinetic trapping, and, without additional information (specifically, the free energy of binding mode interconversion or, equivalently, the relative populations of different binding modes) it becomes impossible to sort out which of the multiple answers is in fact the correct relative binding free energy.

To deal with this, some practitioners have actually computed relative binding free energies of different binding modes of the same ligand~\cite{palma2012computation}.
For example, a perturbation which adds a methyl to an aromatic ring of a larger ligand might yield one result if the methyl points in one direction, and a different value if it points in the other due to slow ring motions~\cite{lincoff2016comparing, sasmal2020sampling}.
One could compute the free energy of turning off the methyl group in one orientation and turning it back on in the other orientation to obtain the free energy difference between the two potential binding modes.
While this approach has precedent, it is relatively difficult to automate at present and requires considerable care.

Overall, this likely means that relative free energy calculations will be susceptible to problems resulting from uncertainty in ligand binding modes until more robust approaches are available to determine dominant binding modes, or the relative populations of different potential binding modes, in advance.

\subsection{Absolute and Relative Binding Free Energies with Multiple Chemical States}
\label{sec:multiple-chemical-states}

Consider, as an illustration, the binding equilibrium between a receptor $R$ and a ligand $A$ that exists in solution as a mixture of protonated $AH$ and ionized $A^-$ forms. It is often useful to consider the observed equilibrium binding constant between $R$ and the $A$ mixture 
\begin{equation}
  K_b(A) = C^\circ \frac{[RA]}{[R][A]}
  \label{eqn:observed-binding-constant}
\end{equation}
where $[A] = [AH] + [A^-]$ and $[RA] = [RAH] + [RA^-]$ are the total equilibrium concentrations of free $A$ and receptor-ligand complexes. The observed equilibrium constant is significant because it corresponds to binding affinity measurements that do not distinguish between the protonation states of the ligand. Inserting the definitions of $[A]$ and $[RA]$ in Eq.~(\ref{eqn:observed-binding-constant}), splitting the sum in the numerator, and multiplying and dividing each term by either $[AH]$ or $[A^-]$ we obtain
\begin{equation}
  K_b(A) = \frac{[AH]}{[A]}  K_b(AH) +  \frac{[A^-]}{[A]} K_b(A^-) =  p_0(AH) K_b(AH) +  p_0(A-) K_b(A^-)
  \label{eqn:observed-binding-constant-split}
\end{equation}
where
\begin{equation}
  K_b(AH) = C^\circ \frac{[RAH]}{[R][AH]}
  \label{eqn:observed-binding-constant-prot}
\end{equation}
is the specific equilibrium binding constant between the receptor and the protonated form of the ligand, and similarly the unprotonated form for $K_b(A^-)$. The specific $K_b$'s are the binding constants that would be obtained from ABFE calculations for those species. Eq.~(\ref{eqn:observed-binding-constant-prot}) states that the observed binding constant is an average of the specific binding constants weighted by the populations, $p_0(AH)$ and  $p_0(A^-)$ of each ligand's chemical form in solution. In this specific example, if the $pKa$ of $AH$ is known and $\alpha = [A^-]/[AH] = 10^{pH-pKa} $ is the ionization ratio of $A$ at a a given $pH$, the populations of the ionized and protonated forms are $p_0(A^-) = \alpha/(\alpha+1)$ and $p_0(AH) = 1/(\alpha+1)$, respectively.\cite{champion2024multistate,azimi2022application}

Eq.~(\ref{eqn:observed-binding-constant-split}) is a particular case of a fundamental result that extends to an arbitrary number of chemical forms of a ligand in solution. In general, the observed binding constant of a ligand present in solution in multiple forms $A_i$ (protomers, tautomers, rotamers, etc.) with populations $p_0(A_i)$ is\cite{khuttan2023taming}
\begin{equation}
  K_b(A) = \sum_i p_0(A_i) K_b(A_i)
  \label{eqn:observed-binding-constant-general}
\end{equation}
and the corresponding standard binding free energy is
\begin{equation}
 \Delta G^\circ_b(A) = -k_B T \ln K_b(A) = -k_B T \ln \sum_i p_0(A_i) e^{-\Delta G^\circ_b(A_i)/k_B T}
  \label{eqn:observed-binding-free-energy-general}
\end{equation}
where
\begin{equation}
\Delta G^\circ_b(A_i) = -k_B T \ln K_b(A_i)
\end{equation}
is the standard binding free energy of the specific form $A_i$. Eq.~(\ref{eqn:observed-binding-constant-general}) is known as the free energy combination formula, which, in the case of multiple conformational states, can be derived directly from the statistical mechanics definition Eq.~(\ref{eq:DG0-binding-constant-def}).\cite{jayachandran2006parallelized,gallicchio2011recent} It states that the contribution of a chemical or conformational state of the ligand to the observed binding free energy depends on the specific binding free energy of that state and its solution population. A state with a strong specific binding affinity may not contribute significantly to the observed binding free energy if its solution concentration is low. Conversely, a sparsely populated ligand state in solution could be responsible for most of the observed binding free energy if its binding affinity is sufficiently strong relative to the other states.\cite{azimi2022application}   

The result of Eq.~(\ref{eqn:observed-binding-constant-general}), which applies to absolute binding free energy calculations, extends to relative binding free energies or, equivalently, to ratios of observed binding constants for the same receptor of two ligands $A$ and $B$ present in solution in multiple chemical forms:
\begin{equation}
  \frac{K_b(B)}{K_b(A)} = \frac{\sum_i p_0(B_i) K_b(B_i)}{\sum_i p_0(A_i) K_b(A_i)}
  \label{eqn:observed-binding-constant-ratio}
\end{equation}
The result above can be expressed in a more computationally tractable form by separating out from the numerator and denominator the specific binding constant of a reference form of each ligand ($A_0$ and $B_0$) to obtain\cite{de2018rigorous}
\begin{equation}
 \frac{K_b(B)}{K_b(A)} = \frac{K_b(B_0)}{K_b(A_0)} \frac{
 p_0(B_0) + \sum_{i=1} p_0(B_i) K_b(B_i)/K_b(B_0)
 }{
p_0(A_0) + \sum_{i=1} p_0(A_i) K_b(A_i)/K_b(A_0)
 }
\end{equation}
which involves only quantities obtainable by relative binding free energy calculations--one for the two reference forms of the ligand to get  $K_b(B_0)/K_b(A_0)$ and those of each form of each ligand relative to the reference to get $K_b(B_i)/K_b(B_0)$ and $K_b(A_i)/K_b(A_0)$.

\subsection{General simulation setting choices that could affect free energy calculations.}
There are many parameter choices that are common to standard MD simulations. Optimal choices may depend on the simulation package and it is best to consult the manual of each package to make the right choices. One particular parameter we want to draw attention to which is often overlooked is the timestep. The choice of integrator can drastically affect the accuracy of a given calculation depending on the timestep~\cite{leimkuhler2016efficient}. Using a 1.0 fs timestep near the limit of stability without any constraints can lead to non-negligible statistical mechanical errors. However, from various previous free energy studies using 1 fs integration timesteps it is not clear that a significant error would be introduced into a free energy estimate and may warrant some further investigation.  

\subsubsection{Charge models are non-trivial}
Modeling the partial charges of the solute and solvent molecules is also highly important. In some fixed-charge models, the assigned partial charges depend on the input conformation of the molecule, meaning that poor or inconsistent conformer selection can introduce systematic errors in solvation free energy estimates \cite{jakalian2000, jambeck2003}. This is particularly true for methods such as Restrained Electrostatic Potential (RESP)\cite{bayly1993resp} or AM1 population charges with bond-charge correction (AM1-BCC)\cite{jakalian2000}, where the geometry of the molecule at the time of charge derivation can influence the electrostatic potential fit \cite{basma2001, zhang2011, dupradeau2010, osato2025}. In these cases, the conformer(s) used for assigning the partial charges should be saved for reproducibility. Ensuring consistency between the charge derivation geometry and the initial simulation structure is therefore recommended, or alternatively, using ensemble-averaged charges or polarizable models where appropriate \cite{ren2002,lemkul2016}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  Data Analysis               %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Data analysis}
\label{sec:data_analysis}
Once equilibrium data has been collected from alchemical intermediates, it must be analyzed to produce an estimate of the free energy change (and its associated statistical uncertainty) for each leg of the thermodynamic cycle.
While a number of different estimators are available that will give consistent results under optimal circumstances, some approaches are recommended over others due to their robustness and ability to provide information on poor convergence.

\subsection{Estimators for free energy differences}
\label{subsec:estimators}
Free energy differences between two different states differing in the energy function are directly related to the
ratio of probabilities of those states.
As can be noted, the partition functions in Eq.~\ref{eq:conf_probability} are simply the total accumulated probabilities for all possible configurations of the system. Virtually all of the ways to estimate this free energy are based in converting this ratio of integrals to something that can be measured in one (or several) simulations.  

\paragraph{The Zwanzig relationship (EXP)}
The simplest method for calculating free energy differences from simulations is the so-called \textit{Zwanzig
relationship}~\cite{zwanzig1954hightemperature}, also called one-sided exponential re-weighting (EXP), or simply free energy perturbation, though this final term is sometimes used to encompass all ways of calculating free energy differences.

The (reduced) free energy difference $\Delta f_{01}$ between an initial state 0 and a final state 1 defined by two different potential energy functions 
$u_0(\vec{q})$ and $u_1(\vec{q})$ over coordinate space $\vec{q}$ can be calculated as:
\begin{eqnarray}
\Delta f_{01} & = & -\ln \expect{e^{-(u_1(\vec{q}) - u_0(\vec{q}))}}_0 =  -\ln \expect{e^{-\Delta u(\vec{q})} }_0
\end{eqnarray}\label{eqn.zwanzig}
and the average is over all samples from the simulation performed with $u_0$. In the case of NVT (canonical) sampling and assuming the masses do not change, then $u$ is simply $U/k_BT$, and $f$ is $F/k_BT$, but it can be generalized to other ensembles with the proper definition of $f$ and $u$.
Described in words, we take the samples generated during our run with the potential energy function $u_0(\vec{q})$ and calculate what the difference in energy would be if we switched instantaneously to the potential energy function $u_1(\vec{q})$, and average the exponential of the negative energy difference to get the negative of the exponential of the free energy difference. The original distributions, P($u_0$) as generated at $\vec{\lambda}=0$ and P($u_1$) would look like those seen in Fig.~\ref{fig:fig_sampling_scheme}\textbf{A}-\textbf{C} on the right hand side. Reevaluating requires almost no extra code functionality to perform; one need only to save a full precision trajectory, and run an unmodified molecular simulation code using the $u_1$ in order to calculate the new energies of stored snapshots. The analysis can be written in a line of code. We note that this method is even more general, in that the instantaneous work to change the potential energy function from $u_0$ to $u_1$ can be replaced by the non-reversible work $W$ to make the same change beginning from the same equilibrium conditions at either end state~\cite{jarzynski1997nonequilibrium,jarzynski1998equilibrium,crooks2000pathensemble}, allowing for non-equilibrium free energy calculations, an alternate approach. We do not detail non-equilibrium transformations here, and refer the reader to more advanced treatments~\cite{maragakis2008bayesian,oberhofer2005biased,procacci2015unbiased,shirts2003equilibrium,ytreberg2004singleensemble, gapsys2020large}, as our focus here is on equilibrium free energy techniques.

Although the Zwanzig equation is formally correct as long as the two states considered sample the same phase space volume, which is true for standard molecular models, it has some very important numerical issues that mean that it often performs badly for standard free energy calculations, even for small molecules~\cite{shirts2005comparison,lu2003appropriate}. One can show that if the standard deviation of the difference $\Delta u(\vec{q}) = u_1(\vec{q})-u_2(\vec{q})$ over all sampled $\vec{q}$ is large, which in this case, means only several times $k_BT$, then very few samples contribute to the average, and the answer will be both biased and extremely noisy~\cite{lelievre2010free}. Essentially, the method is dominated by contributions of rare snapshots~\cite{jarzynski2006rare, wu2005phasespace, wu2005phasespacea}. 


\paragraph{The Bennett Acceptance Ratio (BAR)}
If we have the differences in the potential energy sampled from the distribution defined by $u_0$ to the state defined by $u_1$, and we also have the differences in potential energies from the distribution sampled by $u_1$ to the state defined by $u_0$, we can obtain a significantly improved estimate of the
free energy difference compared to that obtained by EXP. 
This estimate was first derived by Bennett and is hence generally called the Bennett Acceptance Ratio (BAR). It is solved by finding the reduced free energy $f_{ij}$ that satisfied the following implicit equation:
\begin{eqnarray}
 \sum_{i=1}^{n_i} \frac{1}{1 + \exp[\ln(\frac{n_i}{n_j}) + u_{ij}(\vec{q}) - f_{ij})
 ]} \nonumber \\
 =\sum_{i=1}^{n_j} \frac{1}{1 + \exp[\ln(\frac{n_i}{n_j}) - u_{ij}(\vec{q}) + f_{ij})]},
\end{eqnarray}
where $n_i$ and $n_j$ are the number of samples from each state. More recent derivations show that this formula is the maximum likelihood estimate of the free energy difference given sets of samples from the two states~\cite{shirts2003equilibrium}. 

Many studies have demonstrated both the theoretical and practical superiority of BAR over EXP in molecular
simulations~\cite{shirts2005comparison,lu2003appropriate}, and BAR converges to EXP in the limit that all samples are from a single state~\cite{bennett1976efficient,bennett1976efficient,shirts2003equilibrium}. BAR also requires significantly less overlap between the configurational space of each state to converge than EXP, though some overlap must still exist.

The Bennett acceptance ratio is only defined between two states. Usually, the endpoints of interest in a free energy calculation are sufficiently different that we will need a chain of states that gradually change the potential energy function from $u_0$ to $u_1$, as discussed in Sec.~\ref{sec:important_path}. You can carry out a BAR estimate between each pair of states $\Delta f_{1 \rightarrow N} = \Delta {f_{1\rightarrow 2}} + \Delta {f_{2\rightarrow 3}} +  \ldots + \Delta f_{N-1\rightarrow N}$.

There is one important thing to note about the uncertainty estimates when summing multiple free energy differnces together to calculate an overall estimate of a free energy difference. Although BAR itself gives a free energy estimate that is asymptotically correct and is much less biased than the uncertainty estimate for EXP, the uncertainties in $\Delta {f_{i-1\rightarrow i}}$ and $\Delta {f_{i\rightarrow i+1}}$ are not uncorrelated, because they both involve the energies $u_i(\vec{q})$. The variances of each of the free energies cannot simply be summed together into the variance of the overall free energy. Instead, some other method for propagating the uncertainty, such as bootstrapping~\cite{grossfield2018best} must be used.

\paragraph{Thermodynamic integration (TI)}
By taking the derivative of the free energy with respect to the
variable $\vec{\lambda}$, we find that:
\begin{equation}
\frac{df}{d\vec{\lambda}} = \frac{d}{d\vec{\lambda}} \left[-\ln \int \frac{\exp{-u(\vec{\lambda},\vec{q})}}{Z(\vec{\lambda})} d\vec{q}\right] = \expect{\frac{du(\vec{\lambda},\vec{q})}{d\vec{\lambda}}\
}_{\vec{\lambda}} .
\end{equation}
And then we can numerically integrate $df/d\vec{\lambda}$ over an alchemical transformation, using a range of different well-established techniques, to obtain:
\begin{equation}
\Delta f    = \int_{0}^{1} \expect{\frac{du(\vec{\lambda},\vec{q})}{d\vec{\lambda}}}_{\vec{\lambda}}  d\vec{\lambda}.    
\end{equation}
This approach to calculating the free energy is called thermodynamic integration (TI). Averaging over $\expect{\frac{du}{d\vec{\lambda}}}$ requires fewer uncorrelated samples to reach a given level of relative error
than averaging $e^{-u(\vec{q})}$, as the distribution of values is usually narrower, with a more Gaussian shape to the distribution. Rather than being limited by overlap, as in the case of BAR and MBAR (see below), we are instead limited by the bias in the numerical quadrature, which must be minimized sufficiently to be beneath the level of statistical noise.

Various numerical integration schemes are possible, but the trapezoid
rule provides a simple and robust scheme. All types of numerical integration can be written as:
\[ \Delta f \approx \sum_{k=1}^{K} w_k
\expect{\frac{du(\vec{\lambda},\vec{q})}{d\vec{\lambda}}}_{k}, \] where the weights $w_k$ correspond to a particular choice of numerical integration.
Researchers have tried a large number of different integration schemes~\cite{resat1993studies,jorge2010effect,shyu2009reducing}. However, many integration choices require specific choices of $\vec{\lambda}$ to minimize bias, which makes them unsuitable when the intermediates
have widely-varying levels of uncertainty. For example, integrating a cubic spline interpolation provided negligible benefits over a simple trapezoid rule~\cite{paliwal2011benchmark}. As fitting to higher order polynomials can have numerical instabilities for some energy functions, and because alternate functional forms might only be appropriate with some types of transformations, expertise and experience is required to perform such numerical integration modifications. For starting researchers, we therefore recommend the simple trapezoid rule scheme, as it allows for maximal flexibility in which values of $\vec{\lambda}$ are simulated. In practice, adding 2-3 more intermediate states is typically sufficient to match the performance of these more complicated numerical quadrature schemes. It is also possible to calculate the $\lambda$-derivatives at non-simulated states from simulated states in a scheme named extended TI~\cite{ruiter2016extended} which reduces the integration error.

One drawback of TI is that it requires derivatives with respect to $\vec{\lambda}$ to be calculated directly in the code. Unfortunately, many problems of interest require using pathways (such as the soft-core pathways, for removing repulsive interactions) that are not linear, as we discuss, making this more complex. Still, if the code of interest does compute $\frac{du}{d\vec{\lambda}}$, then TI is perhaps the simplest method to use, as it involves a very little post-processing effort.

\paragraph{The multistate Bennett acceptance ratio (MBAR)}
One can generalize Bennett's logic from two states to multiple states to obtain a free energy estimator that uses energy differences between configurations at all intermediate states to compute free energy differences between all states. MBAR gives a system of implicit equations for the free energies $f_i$:
\begin{equation}
f_i = - \ln \sum_{n=1}^{N} \frac{\exp(-u_i(\vec{q}_n))}{\sum_{k=1}^K N_k \exp(f_k-u_k(\vec{q}_n))},
\end{equation}
where there are $N_k$ samples from each of $K$ states, with $\sum_k N_k=N$ the total number of samples. Thus, we need to evaluate the energy function $u_i$ for all samples obtained at all states in the transformation. The equations can be solved by a number of different standard routines. We note that there are only $K-1$ independent equations, so only $K-1$ of the free energies are independent variables, and one of the $f_i$ must be specified (usually, without loss of generality, setting it to zero).

MBAR is probably the lowest variance asymptotically unbiased estimator of the free energy given the energies of the samples~\cite{tan2004likelihood}, which means that BAR is also the lowest variance estimator for the free energy difference between only 2 states, as it is mathematically exactly the same as MBAR in this case. MBAR also provides an uncertainty estimate, derived from standard error propagation methods for implicit functions, which has been shown to be highly accurate as long as there are sufficient samples at each state~\cite{paliwal2011benchmark}.

MBAR can also be thought of as the Zwanzig estimator of the free energy to state $i$ from a sampled distribution referred to as the \textit{mixture distribution}, where one throws all the samples from all simulations together in one ``pot''. Mathematically, this is defined by $p_m(\vec{q}) = N^{-1} \sum_k N_k \exp(f_k-u_k\vec{q})$, which is the average, weighted by the number of samples drawn from each distribution, of all the individual normalized probability distributions from the simulations that are performed~\cite{shirts2017reweighting}.

All of the estimators above have uncertainty estimates associated with them.  In the limit of sufficiently large data, perhaps several hundred or thousand independent points, exhaustive analyses of model data has shown that the error estimates of BAR, MBAR, and TI are all quite reliable when there is good overlap between intermediate states. For example, for a series of hydration free energy calculations of model systems of various sizes analytical estimates of the error, bootstrap estimates, and standard deviations over 100 independent simulations started at different locations along a long initial simulations all agreed within a 5---10\%.~\cite{paliwal2011benchmark} For EXP, the number of samples at which they become reliable is significantly higher, especially if overlap between intermediate states is lower. 

However, in the limit of moderate or small amounts of data (tens or hundreds of independent samples) these errors become somewhat unreliable, often off by a factor of 2 from what would get if more data was collected.~\cite{???} These estimators of uncertainty are all derived from propagation of error formulae from the estimators themselves. When the underlying data is noisy, this approximation is not very good.

Some of the authors' experience has shown that significantly more reliable estimators at lower numbers of samples are obtained by performing bootstrap sampling on data that has been uncorrelated. We do not provide a full tutorial of bootstrapping here, but the basic idea is that one takes the $N_{sample}$ data points collected and draws, with replacement, $N_{sample}$ samples.  This means some of the data points will be represented multiple times, and other data points none. This process is then repeated $N_{bootstrap}$ times, where $N$ should generally be at least 50 to up to 200 for good estimates of the standard error of the estimator.  The data is then \textit{treated} as $N_{bootstrap}$ samples from the true distribution, and statistics such as the standard error are computed from this artificial set of $N_{bootstrap}$ experiments.  In the limit of $N_{sample}$ large, it can be shown that the bootstrap estimate of the standard error converges to the true population standard error.  One way this can be seen is that bootstrap estimators of the data are independent samples of the \textit{actual} distribution of the experiment performed, i.e., a bunch of $\delta$ functions at $N_{sample}$ points, rather than being independent samples from the true, usually continuous distribution.  As more and more data is collected, our collection of $\delta$ functions becomes more and more like the true distribution. Another advantage of bootstrap sampling is that one can construct decent estimates of error bounds with arbitrary percentiles, and not just standard errors of the estimates, which assume Gaussian behavior of the underlying error, and that the error results are Gaussian as well.  The bootstrap approach, on the other hand, captures non-Gaussian behavior in the data. 

One important point is that the bootstrap samples use to estimate the standard error should be decorrelated, or else the bootstrap estimate of the standard error will be artificially small.  More discussion of subsampling and decorrelation is included in section~\ref{sec:decorrelating-samples}. Another alternative to bootstrap sampling of individual points that better captures the correlations in the data is block bootstrapping~\cite{???}.  Block bootstrapping is somewhat more complicated and less common to perform and analyze than bootstrap estimates of the error, so we refer readers to the citations for more description, but it can also provide more reliable estimates of uncertainty than the estimators above.


\paragraph{Recommendations}
\begin{itemize}
\item We recommend MBAR if all energy differences are available. It is the lowest variance unbiased free energy estimate given samples from multiple states.
\item BAR is essentially just as good as MBAR for highly optimized $\vec{\lambda}$ intermediates. Specifically, if the $\vec{\lambda}$s are chosen such that intermediate states have moderate overlap with their neighbors (i.e. between $i$ and $i+1$ and between $i$ and $i-1$), they will \textit{not} have significant overlap with their next nearest neighbors $i+2$ and $i-2$. Thus MBAR does not actually get significant information from these energy differences, so one might as well not even calculate them, and just perform BAR between nearest neighbors.~\cite{paliwal2011benchmark} 
\item TI usually gives similar values as MBAR implemented with sufficient numbers of intermediates, but quadrature errors that are hard to estimate beforehand  can occur if one does not carefully select $\lambda$ values such that the overlap between states is sufficiently high.~\cite{paliwal2011benchmark}
\item WHAM is an approximation to MBAR, and there are no compelling reasons it should be used. If bin widths are careful chosen and there are sufficient samples, it can given similar quality results to have the other methods, but it always introduces some degree of binning error, and determining when errors might occur can be challenging. 
\item Other variants, especially ones that adaptively determine the free energies can be useful in certain circumstances but beyond the scope of a Best Practices article.
\end{itemize}

\subsection{Detecting the boundary between equilibrated and production regions}
\label{sec:automatic-equilibration-detection}
Much of the infrastructure for analyzing alchemical free energy calculations relies on the concept of asymptotically unbiased estimators, which produce unbiased estimates of the free energy when fed very long simulations~\cite{shirts2005comparison}.
In reality, free energy calculations are often initiated from highly atypical initial conditions (such as a protein-ligand geometry obtained from docking and subjected to a heuristic solvent placement scheme), and simulations are of a finite length dictated by available computational resources and computing demands.
As a result, these estimators can produce significantly biased estimates if fed the entirety of simulation data generated without further processing~\cite{chodera2016simple}.
\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{figures/fig11_equib_detection/Figure.pdf}
    \caption{{\bf Automatic partitioning into equilibration and production regions.}
    (\textbf{A}) The average (black line) standard deviation (shaded region) of the reduced potential $u^*$ over many independent replicate simulations started from the same initial conditions show a significant initial transient change before relaxing to the true average potential energy (\textbf{B}). A cumulative average (red) of the entire simulation data demonstrates simulation bias not seen when initial simulation data is omitted (blue). Using an automated approach to detect equilibration of the boundary $t_0$ using statistical inefficiency $g$ (\textbf{C})  for an effective simulation interval (\textbf{D}). (\textbf{E}) The optimal equilibration boundary $t_0$ is selected to maximize the number of uncorrelated samples.
    \emph{Figure adapted from~\cite{chodera2016simple}.}
    }
    \label{fig:automatic-equilibration-detection}
\end{figure}

To minimize this effect, an initial portion of the simulation that is determined to be  \emph{equilibration}~\cite{braun2019best} should be omitted, with the idea of removing the most heavily biased initial portion of simulation data, but retaining the unbiased \emph{production} region that represents a stationary Markov chain process sampling from the desired equilibrium target distribution.
Because the simulation time required for the atypical initial sampler state to relax toward equilibrium is a property of the specific system being simulated and the specific initial conditions selected, it is simplest to collect data for the whole process and use an automated algorithm to select how much data should be discarded to equilibration in a post-processing step, rather than attempting to figure out beforehand how long equilibration will take. 

A simple approach to automatically partitioning simulation data into equilibration and production regions is described in~\cite{chodera2016simple} (illustrated in Fig.~\ref{fig:automatic-equilibration-detection}).
Suppose we have a simulation of length $T$ consisting of correlated data.
Here, the goal of the post-processing step is to select the equilibration boundary $t_0 \in [0, T]$ so as to \emph{maximize} the number of effectively uncorrelated samples remaining in the production region $N_{[t_0,T]}$, which is defined as
\begin{eqnarray}
N_{[t_0,T]} &=& \frac{T - t_0}{g_{[t_0,T]}}
\end{eqnarray}
where $g_{[t_0,T]}$ is the \emph{statistical inefficiency} of a timeseries $a_t$, described in more detail below.
This approach is implemented within the MBAR~\cite{kylebeauchamp2019choderalab} and alchemlyb~\cite{daviddotson2019alchemistry} packages, and is highly recommended for standard practice. A very similar approach involves minimizing the standard error of the production region~\cite{whiteEffectiveTruncationHeuristic1997, sprattHeuristicsStartupProblem1998, hoadAutomatingWarmupLength2010, clarkRobustAutomatedTruncation2025}.

For additional discussion of working with correlated data and autocorrelation analysis, please refer to the work on Best Practices for Quantification of Uncertainty and Sampling Quality in Molecular Simulations~\cite{grossfield2018best}.

\paragraph{Computing the timeseries for equilibration detection}
Typically, the timeseries of note $a_t$ analyzed in automated equilibration detection is the negative logarithm of the probability density ($\pi(x_t; \vec{\lambda}$)) sampled by the MCMC algorithm (up to an irrelevant additive constant).
For simple independent simulations that sample $x_t \sim \pi(x ; \vec{\lambda})$, this is given by the reduced potential
\begin{eqnarray}
a_t &\equiv& - \ln \pi(x_t; \vec{\lambda}) + c = u(x_t; \vec{\lambda}) .
\end{eqnarray}

Note that the use of the effective reduced potential is not guaranteed to detect all slow relaxation processes that may be coupled to the alchemical free energy, but the simplicity of its computation means it is generally appropriate for most cases.

\paragraph{Cautions in automating equilibration detection}
Procedures like those described above can fail to remove bias if the simulations are simply not long enough to contain a large number of samples from true equilibrium either because they are very short, or because one is simulating slow processes. In such cases, this approach often simply selects a small final portion of the simulation, which may be contained in a single substate of configurational space, which may itself lead to biased estimates. 
This situation can be detected if the equilibration boundary $t_0$ is a significant fraction of the total simulation length $T$, with a good rule of thumb being that under well-sampled situations $T \gtrsim 20 t_0$.
If identifying an equilibration time that is only a fraction of the total time is not possible, advanced analysis techniques that assume only local equilibrium within kinetically separated metastable states, rather than global equilibrium over the entire phase space, such as the TRAM estimators~\cite{mey2014xtram,wu2016multiensemble,nuske2017markov} may be more appropriate, but are beyond the scope of this paper.

\subsection{Decorrelating samples for analysis}
\label{sec:decorrelating-samples}
\paragraph{Computing the statistical inefficiency}
Replicas in ensemble simulations are initialized with velocities drawn independently from the MaxwellBoltzmann distribution and hence generate decorrelated samples by default. When only one simulation is available, the procedures described below provide a lower-bound estimate of the uncertainty.

Most estimators require an uncorrelated set of samples from the equilibrium distribution to produce (relatively) unbiased estimates of the statistical uncertainty, as most estimates of the uncertainty are derived assuming unbiased samples.
To do this, the production region of the simulation is generally \emph{subsampled} with an interval approximately equal to or greater than the \emph{statistical inefficiency} $g \ge 1$ to produce a set of uncorrelated samples that can be fed to the estimator machinery~\cite{chodera2016simple},
\begin{eqnarray}
g &\equiv& 1 + 2 \tau_\mathrm{eq} \label{eq:statistical-inefficiency-definition}
\end{eqnarray}
where $\tau_\mathrm{eq}$ is the integrated autocorrelation time, formally defined as
\begin{eqnarray}
\tau_\mathrm{eq} &\equiv& \sum_{t=1}^{T-1} \left(1 - \frac{t}{T}\right) C_t \label{eq:integrated-autocorrelation-time-definition} , 
\end{eqnarray}
with the discrete-time normalized fluctuation autocorrelation function $C_t$ defined as
\begin{eqnarray}
C_t &\equiv& \frac{\expect{a_n a_{n+t}} - \expect{a_n}^2}{\expect{a_n^2} - \expect{a_n}^2} . \label{equation:autocorrelation-definition}
\end{eqnarray}
The basic concept is that $\tau_\mathrm{eq}$ corresponds to the single-exponential decay time for the autocorrelation process that generates samples, so the statistical inefficiency $g$ measures the approximate temporal separation between two effectively uncorrelated samples (where two exponential relaxation times are presumed to be sufficient).

Robust estimation of $C_t$ for $t \sim T$ is difficult due to growth in statistical error, so common estimators of $g$ make use of several additional properties of $C_t$ to provide useful estimates (see \emph{Practical Computation of Statistical Inefficiencies} in~\cite{chodera2016simple} for a detailed discussion).

We recommend using the robust statistical inefficiency computation routines available within the MBAR~\cite{kylebeauchamp2019choderalab} and alchemlyb~\cite{daviddotson2019alchemistry} packages, though we caution that any such algorithms will underestimate the correlation time with insufficient data. Such approaches also assume that the data doesn't have any long time scale drift over the course of the simulation, which is a clear sign of lack of equilibration.  Generally, most methods will give reasonable correlation times when the simulation lasts 40--50 correlation times.


\paragraph{Subsampling data to generate uncorrelated samples}
Once the statistical inefficiency $g$ has been estimated, it is straightforward to subsample the correlated timeseries simulation data to produce effectively uncorrelated data that can be fed to the free energy estimators.
Suppose the correlated timeseries is $\{a_t\}_{t=1}^T$; we can form a new timeseries of $N_{\mathrm{eff}} \approx T / g$ effectively uncorrelated samples by selecting a subset of indices $\{ \: t = \mathrm{round}((n-1) \, g) \: | \: n \in \mathrm{range}(1,\ldots ,N) \: \}$ where $\mathrm{round(x)}$ denotes rounding to the nearest integer.

However, samples uncorrelated by this procedure are only approximately uncorrelated.  Recent careful investigation has shown that the lowest uncertainty results can be obtained by using \textit{all} of the data to obtain an estimate of the free energy itself, but using only subsampled data to calculate error estimates using the formulas or by using bootstrapping.
In fact, one can show that the standard deviation of the estimate determined by data that has been subsampled is the unbiased estimator of the free energy estimate using all the data, but is actually an underestimate of the uncertainty of estimate using just the subsampled data.
%MRS: Finlay, is there a citation for the mathematical analysis you showed in the issue tracker?  This would be a good place to it. 

We don't need to use all of the data to recover the remaining correlation.  In practice, if one subsamples the data with a
correlation interval of $g/10$, where $g$ is the correlation time, this will recover the missing correlation.  Thus, if $g=3.0$ in units of timesteps, it is best to use all of the data.  If $g=100.0$, then one loses essentially no information by subsampling with $g=10.0$ in estimating the free energies, and still saves significant time by not using all of the now-completely duplicative data.  Note that subsampling with correlation time $g$ should still be used for estimating the uncertainties, perhaps requiring two passes of the simulation analysis code. 

If independent simulations at each $\lambda$ are used, the alchemical state $\vec{\lambda}$ may have a significant impact on the correlation time, and these simulations should be subsampled independently using a separate estimate of the statistical inefficiency $g$ for each alchemical state. If coupled simulations are used (such as a Hamiltonian replica exchange simulation), the replicas should undergo equivalent random walks in alchemical space, and the replicas can be subsampled with the same $g$ to generate an equal number of uncorrelated samples at each alchemical state. Conveniently, maximizing the effective sample size for automated equilibration detection produces an appropriate estimate of $g$ over the production region for automating this process.

Our overall recommendations are therefore to determine the subsampling period $g$, either use all of the data or subsample with something like $g/10$ (i.e. more frequently than specified by $g$) to compute the free energy estimates, and then use fully subsampled data (with subsampling interval $g$) to estimate the uncertainties of the estimates.  Uncertainties calculated with the full data set will be significant underestimates if $g > 1$.

\paragraph{Cautions and considerations}
Reliable estimation of the statistical inefficiency is difficult, and estimates will not generally be as precise (in a relative error sense) as averages.
To ensure there is sufficient data available for reliable decorrelation and estimation of free energy differences, it is recommended that the effective number of uncorrelated samples $N_{\mathrm{eff}} \ge  \sim 50$ if the BAR or MBAR estimators (discussed below in sec~\ref{subsec:estimators}) are used; the number may need to be much higher with alternate estimators.


\subsection{Uncertainty estimation v2}

%% MS: This is a very loose proposal of how one might address some of the issues on uncertainty quantification.  It is only meant to help get the ball rolling, per the discussion in https://github.com/alchemistry/alchemical-best-practices/issues/150#issuecomment-3567254644. Otherwise, it can be mostly discarded. The important points in my view are:
%
% 1. clearly expressing the dependence of the density as a function (t, x_0), and what assumptions are made about its behavior; without this, I see no way of making statements about uncertainty quantification, as these all require some statistical theorem, like a Law of Large Numbers, or a Central Limit Theorem. 
% 2. a definition of an ensemble
%
% and to a lesser extent
%
% - expression for the sample variance in the case of i.i.d. or (conditionally iid) random variables,
% - expectation of the sample variance in the case of correlated samples
% - some definition of the asymptotic error
% - some discussion about the two central limit theorems being used: the one for (c)iid RVs (e.g., Lindeberg CLT) and a temporal CLT for Markov processes. In the latter case, we would expect the error to decay like 1/sqrt(# timesteps), but this does not occur. I think we should highlight this. 

Consider a molecular dynamics trajectory started at some initial configuration $z_0 = (x_0, v_0)$, where $x_0 \in \mathbb{R}^{3 N}$ denotes the initial positions of the system and $v_0 \in \mathbb{R}^{3 N}$ its initial velocities. If $z = (x_0, v_0)$ is drawn from some initial density $\rho_0 (z)$, the density time $t$ will be
\begin{equation}
  \rho_t (z' | z_0) = \int_{\mathbb{R}^{3 N} \times \mathbb{R}^{3 N}}
  \rho_0 (\mathrm{d} z) P_t (z' | z) .
\end{equation}
Here, $P_t$ denotes the transition kernel, determined by the molecular dynamics integrator. The distribution of the velocities is usually ignored, since in the presence of a thermostat they are kept distributed roughly according to a Maxwell-Boltzmann distribution, so we only consider the $x$ component. In practice, the initial distribution $\rho_0 (x) \mathrm{d} x$ is seldom more than a Dirac-$\delta$, $\delta_{\{ x_0 \}} (\mathrm{d} x)$, or a mixture thereof, e.g. $\sum_{i = 1}^n \delta_{\{ x_i \}} / n$. Any "better" initial density would require some knowledge about the system at hand. We henceforth consider only the density at time $t$ starting at, denoted $\rho_t(x | x_0)$.

It is difficult to make general statements about the behavior of $\rho_t (x | x_0)$. For systems not involving a protein, it may be possible to identify clear "plateaus'' of convergence \footnote{The relevant mathematical object here is a quasi-stationary distribution, but should we say this? Could cite Art Voter at Los Alamos, maybe even Freidlin-Wentzell for the original quasipotential.}, i.e. intervals $[T_a, T_b]$, $T_a \ll T_b$, within which $\rho_t (x | x_0)$ does not vary much for $t \in [T_a, T_b]$, and is roughly invariant to $x_0 \in B$ in some appropriate "starting domain". Consider, for instance, the estimation of free energies of hydration for small molecules [cite Shirts paper on free energies of hydration]. In this case, the free energy estimates behave in accordance with classical statistical theory, and the density $\rho_t (x | x_0)$ should not vary much along coordinates relevant to the free energy estimates.

%  MS: The above paragraph is too vague, but some kind of discussion to this effect might be necessary to make sense of why some free energy calculations, such as solvation free energy calculations or computation of free energy landscapes for small molecules, have different statistical properties than more complicated calculations, like absolute binding free energy calculations. 

One should not confuse a plateau in such coordinates with having explored the entirety of the configuration space $\Omega \subset \mathbb{R}^{3N}$; most biomolecular systems, even ones involving only a single ligand, possess a whole hierarchy of timescales, the longest of which can easily exceed achievable simulation times. Importantly, there is no claim that $\rho_t(x|x_0)$ must always converge to some unique density $\propto \exp(-\beta H(x))$, nor that the behavior of $\rho_t (x|x_0)$ is invariant to $x_0$.
% Of course, it _could_ be the case for some systems, but in general we will have a so-called quasi-stationary distribution; i.e. we will consider the distribution conditional on not having exceeded an escape time. 

% The following footnote feels out of place, but might address some comments by A. Bhati re: the Poincar recurrence times.
% \footnote{(Luckily, it is not necessary for simulations to visit every configuration $x \in \Omega$ in order to exhibit a regime of convergence for the free energy estimates. For instance, two configurations $x$ and $x'$ may be considered equivalent for free energy estimation if they differ only by the permutation of water molecules. Nature too faces the same difficulty that not all states are accessible on timescales we can observe -- it will take an astronomically long time before all the gas particles in a room happen to be on one half-side of it -- but this does not prevent us from measuring the temperature of (most) rooms.)}

For systems involving a protein-ligand complex, $\rho_t (x | x_0)$ is usually sensitive to $x_0$ and additionally may not exhibit a clear plateau on any computationally feasible time $t > 0$ for "most" $x_0$. In such a case, we can still draw independent samples from $\rho_t (\cdot | x_0)$ by simulating a trajectory up to time $t$ and taking the last frame, but this is much less valuable than knowing that $\rho_t (\cdot | x_0) \approx \rho_T (\cdot | x_0)$ for all $t \in [T_{\min}, T]$.\footnote{Should one define the mixing time of a Markov process? Cite Peres Markov Chains and Mixing Times, which is freely available?}

In this section, we explore the various possible types of error analysis which can be performed, depending on the behavior of $\rho_t$. We begin with a definition.

%% MS: I'm not tied to any particular definition of ensemble, but we should probably make a concrete one:
% - common x_0 ? 
% - v ~ MaxwellBoltzmann(Temperature) 
% - what are the individual trajectories called? "replicates" ? 
We define an \textbf{ensemble} to be a set of $R \geqslant 1$ trajectories, all started at the same configuration $x_0$, with $v_0$ drawn from the Maxwell-Boltzmann distribution at the appropriate temperature, and run for a chemical time $T$.

\subsubsection{Ensemble error estimates}
The simplest  and most robust way of obtaining error bars on free energy estimates is by simulating an ensemble $\{ X^{(1)}, \ldots, X^{(R)} \}$ of $R$ molecular dynamics trajectories started at $x_0$ and producing trajectories of free energy differences $\{ \Delta G^{(1)}, \ldots, \Delta G^{(R)} \}$. The trajectories $\Delta
G^{(i)} (\cdot)$ are identically distributed and conditionally independent given some $x_0$. For time $t > 0$, the variance of any $\Delta G^{(i)} (t)$ can be estimated with the sample variance $S^2_{(R - 1)} (t)$,
\begin{equation}
  S^2_R (t) = \frac{1}{R - 1} \sum_{i = 1}^R (\Delta G^{(i)} (t) -
  \overline{\Delta G (t)})^2, \qquad \overline{\Delta G (t)} = \frac{1}{R}
  \sum_{i = 1}^R \Delta G^{(i)} (t) .
\end{equation}
Note that, conditionally on $x_0$, we have
\begin{equation}
    \mathbb{E}_{x_0}[S_R^2(t)] = \mathrm{Var}_{x_0}(\Delta G^{(1)}(t))
\end{equation}
The above equation says that $S_R^2(t)$ is an unbiased estimator for the variance. By a law of large numbers, as $R \rightarrow \infty$, we have $S^2_R (t) \rightarrow \mathrm{Var} _{x_0}(\Delta
G^{(1)} (t)) = \sigma^2 (t ; x_0)$. 
%% Should we say what kind of LLN (weak/strong) ? Do we provide a reference (standard: Durrett or Chung)? 

The standard error
\begin{equation}
  \mathrm{SE}_R (t ; x_0) = \frac{S_R^2 (t)}{\sqrt{R}}
\end{equation}
is the gold standard for reporting the error of a set of free energies obtained from trajectories started from a common $x_0$. Note that $\mathrm{SE}_R
(t ; x_0) \rightarrow 0$ as $R \rightarrow \infty$ no matter what $S_R^2 (t)$, so long as it is finite, which is true if the $\overline{\Delta G}$ are, say, bounded. Consequently, we can estimate the variance of the estimate to essentially arbitrary precision. Note, however, that $\Delta G^{(i)}(t)$ will not in general be normally distributed, and the variance may not be a good statistic to capture the error, as the distribution may be multi-modal and heavy-tailed.
%% MS: The error estimation may further be compounded by a rare event problem, in which case simulating even R = 100 replicates may not be "enough", depending on the purposes. 
%% Should we also state the central limit theorem? 

\subsubsection{Per-replicate error estimates}

In the preceding case, we used minimal assumptions on the distribution of $\Delta G^{(i)}(t)$ to obtain estimates on $\sigma^2(t;x_0)$ by simulating conditionally independent replicates and using the sample variance. In this section, we impose much stricter assumptions on the distribution of $\Delta G^{(i)}(t)$, namely that they satisfy a (temporal) Central Limit Theorem (CLT):
$$ \sqrt{t} ( \Delta G^{(i)}(t) - \Delta G^\star) \Rightarrow N(0, \sigma^2_{\mathrm{asym}}(x_0))$$
where $\Delta G^\star$ denotes the true free energy difference, $\sigma_{\mathrm{asym}}^2(x_0)>0$ denotes the so-called "asymptotic variance", and $\Rightarrow$ denotes convergence in distribution. %% Should we define this? Might be a little too technical for the audience. Again, Durrett is one of the standard references. 
The CLT assumption implies that 
$$\sigma^2(t;x_0)=\frac{\sigma^2_{\mathrm{asym}}(x_0)}{t}.$$
In practice, it may not be the case that $\sigma^2(t;x_0)\propto t^{-1}$, nor even that $\sigma^2(t;x_0)$ is monotonically decreasing with $t>0$. In such a case, we are not in a regime where the CLT is satisfied. 

%% Here we can discuss time-blocking estimators, such as the batch-means estimator. Subsampling would also fit in nicely here. Finally, we could relate the sample variance at time $t$ to the mean of per-replicate errors at time $t$; the two should agree -- and they do for some simulations -- but in general the mean of the per-replicate errors is less than the empirical error obtained from the sample variance.

%% We should also discuss the dependence on x_0. 



\subsection{Uncertainty estimation}
\label{subsec:uncertainty}
It is important to consider the variation in your computed free energies from your equilibrium simulations, in order to obtain an estimate of uncertainty of the obtained value for the free energies of interest. The Best Practices paper by Grossfield et al.,~\cite{grossfield2018best} provides substantial detail on how to estimate uncertainties from molecular simulations and is a good starting point for this topic. 
The uncertainty of a free energy estimate is limited, however, as it is only an estimate of the configurations sampled and cannot contain any information from the phase space not sampled during a simulation. As a consequence, the variance in free energy afforded by any estimator will always be an underestimate of the true uncertainty.
In general, the quantification of different error metrics depends on both data generation and analysis methods used from the ones discussed above. The user may choose best practices based on their need for the calculations carried out. If only few free energies need to be calculated at very high accuracy, a different strategy might be employed than if large-scale estimates are needed. As such, considering overall computational cost or availability of resources with respect to accuracy desired from computations may influence the choice of sampling and analysis scheme. 
%Since sampling all of phase space is prohibitively expensive to satisfy the ergodic theorem, certain considerations are often made to still assess uncertainties in computed free energy estimates. If a system exhibits a stable strong binding pose a short number of simulation repeats, sometimes termed ensemble approaches (e.g. TIES~\cite{bhati2017}) often offer adequate free energy estimates. However, situations with more flexible binding and poses will require more strategic sampling schemes to get estimate uncertainties.  


%Statistical mechanics provides a route to calculate macroscopic thermodynamic properties of a system from \textit{ensemble averaging} over microstates. Hitherto, MD practitioners have been assuming the validity of the ergodic hypothesis that allows one to equate ensemble averaging to time averaging in the limit of time approaching infinity to predict thermodynamic properties using one-off simulations. . In more rigorous terms, ergodic theory necessitates that, if a dynamical system is to approach equilibrium, it is not sufficient for it to be ``ergodic'' but it must also be ``mixing'' (these terms refer to the different classes of dynamical systems provided by ergodic theory; please see the references for details)~\cite{coveney2016, MDbook2025}. Rate processes (a course of change within a system that occurs over time) and equilibration times are a property of the distribution function, not of individual trajectories. Consequently, neighbouring trajectories in the underlying phase space diverge exponentially which means that a single trajectory can never capture the true behaviour of a system. Rather, one must perform true ensemble averaging through running sufficiently large number of replicas, termed ``ensemble simulations''. This is manifest in the numerous published reports where authors have highlighted the non-reproducibility of results obtained from one-off simulations and that single simulations heavily underestimate the true uncertainty in predictions~\cite{wan2020fep+, wan2021uq, vassaux2021, gapsys2020large, wade2022, bhati2017, bhati2022, bhati2025, wan2023eqvsneq, bhati2018, bhati2019}. The uncertainty is calculated as the standard error of the mean for estimates obtained from each replica in the ensemble. The ensemble size is a parameter that needs to be determined empirically for the system of interest and may need to be adjusted; however, some general recommendations (for both EQ and NEQ approaches) based on systematic analyses on a large and diverse dataset of protein-ligand complexes are available in a series of papers published by the Coveney group~\cite{bhati2017, bhati2018, bhati2019, bhati2022, wan2023eqvsneq, bhati2025}. Further, ensemble simulations are also necessary in case of enhanced sampling methods~\cite{bhati2018} as well as microsecond long simulations~\cite{bhati2023}. It is the influence of these reports that journals such as \textit{JCIM} and \textit{Communications Biology} have now mandated the use of ensemble simulations in computational studies~\cite{wan2023}. 

Computing free energies using TI (Sec.n~\ref{subsec:estimators}) is straightforward and the trapezoidal rule is often recommended. The trapezoid rule easily allows unequal spacing of $\vec{\lambda}$ states, which is often required to minimize the variance in the free energy estimate, but in principle any good numerical integration method can be used if care is taken.  
Determining of regions of high curvature when estimating the integral is helpful to determine regions of phase space where more sampling and/or more $\vec{\lambda}$ states are necessary to obtain the best approximation of the integral. Plotting $\vec{\lambda}$ with respect to the gradients at each of the $\vec{\lambda}$ values, which can be done automatically with tools such as alchemlyb,  can be a helpful diagnostic. 
Additionally, computing the overall variance of TI requires the calculation of the overall variance of the integration, rather than each individual $\Delta$G$_{i,i+1}$ and assuming variances add independently. 
Therefore, $\mathrm{var}$($\Delta$f) = $\sum_{i=1}^{K}w_{k}^2 \mathrm{var}(\frac{du}{d\vec{\lambda}})_{k}$, where the $w_k$ are the integration weights (see Sec~\ref{subsec:estimators} for more discussion of $w_k$).

%The TIES method~\cite{bhati2017} employs a different scheme to obtain the overall variance of the integral. It assumes that the integrand is a Gaussian random process and hence the thermodynamic integral can be viewed as a so-called stochastic integral, which forms the basis of uncertainty propagation in this integral. The following equation is used to compute the overall variance of the integral combining variance at each $\lambda$ state. $\mathrm{var}$($\Delta$f) = $\sum_{i=1}^{K}\Delta\lambda_{k}^2 \mathrm{var}(\frac{du}{d\vec{\lambda}})_{k}$. 

Beyond thermodynamic integration, the TIES method\cite{bhati2017} uses an It\^{o} integral with Iso isomoetry for error propogation.

For alchemical changes that result in smooth, low curvature sets of $\expect{\frac{dU}{d\vec{\lambda}}}$, a relatively small number of $\vec{\lambda}$ states is necessary for sufficient accuracy and low variance in the free energy estimate. 
Depending on the difficulty of the perturbation, the bias introduced by discretization of the integral can become large due to increased curvature, and more $\vec{\lambda}$ intermediate states become necessary to reduce error.
It is recommended that researchers verify that a sufficient number of states are included such that the free energy is essentially invariant to the number of lambda intermediate states chosen. Good heuristics or measures to assess the 'difficulty' of a given perturbation is still an ongoing research topic. 

Compared with TI, the MBAR method (Sec.~\ref{subsec:estimators}) discussed above provides uncertainty estimation directly from solving a set of linear equations to compute the variances between all states. 
The number of states and amount of sampling should be optimized to minimize the uncertainty in the MBAR free energy estimate, while balancing other key considerations such as computational expense. 
A less accurate uncertainty estimate may be desirable over a reduced computational expense, increased sampling strategies such as using larger simulation ensembles will provide more accurate uncertainties but will drastically increase the computational cost. 
However, this process based on one-off simulations underestimates the true uncertainty and hence uncertainties for MBAR also should be obtained using ensemble simulations~\cite{bhati2018, wade2022}.

If possible, it is advisable to analyze the same set of simulations with different estimators, providing an opportunity for synergy. If different estimators agree the free energy estimate is more reliable than if there are differences between methods that are larger than 1 kcal/mol and would indicate poor convergence. 

Uncertainty can also be assessed for a particular perturbation by repeating calculations with slight changes in initial configurations, forcefield parameters, and different random seeds in the MD engine. 
The assessment of variability in free energy calculations due to repeating simulations has been previously reported~\cite{aldeghi2019accurate,paliwal2011benchmark,mey2016blinded,mey2018impact}, and large variance in free energies estimated from simulations with different random seeds should be flagged as issues with convergence. 

For relative binding free energy calculations, additional sensitivity analysis can be performed by changing the initial configurations of non-core regions of the perturbation topology and determining if this change in configurations results in a large differences in the computed relative free energy, indicating poor sampling of ligand configuration.
The proposed changes in configuration are increasingly relevant if no experimental evidence is available to reduce uncertainty in where the changing atoms should be positioned.

In addition to statistical uncertainty and sampling, a variety of other factors can impact results from binding free energy calculations. In addition to the choice of initial configuration, results can depend on the choice of force field for the protein/receptor, water, and small molecule(s), so rerunning calculations with different choices of force field can also be used to assess how sensitive results and conclusions are to these particular choices. Other factors, like system preparation (choice of protonation state, tautomer, counterion presence, salt concentration, etc.) can also substantially impact results~\cite{mobley2017predicting, mobley2017predictinga}, so unless modelers are confident they have these factors correct, sensitivity to these choices may also need to be examined.
Incidentally, Vassaux \textit{et al.} performed a systematic study comparing the effect of both aleatoric as well as parametric uncertainties for protein-ligand free energy calculations using NAMD~\cite{vassaux2021}. They found that, indeed, ensemble simulations are necessary to control both sources of uncertainties arising in simulations, just as is anticipated in the field of uncertainty quantification.

\subsection{Are my simulations any good?}
\label{sec:are-they-good}
There are different easily measurable indicators that can test how well converged simulations are, and if all alchemical states have been sufficiently sampled for a rigorous analysis. Furthermore, once you have established that individual perturbations are well behaved, there are some tricks to ensure the overall perturbation network gives reliable results.

\paragraph{Convergence of simulations}
Fig.~\ref{fig:freeenergytrajectories} illustrates how looking at the convergence of your data may be important. The CB8 host with guest G3 has a longer correlation time than the G6 guest in the octa acid (OA) host. In some cases, slow correlation time may not be expected and therefore not a feature known in advance. To this end, you should always look at all simulation data available and check convergence behavior for each free energy estimate.
Comparing the free energy trajectories as a function of the simulation time in the forward and reverse time direction is a useful convergence test~\cite{klimovich2015guidelines}.
As shown in Fig.~\ref{fig:freeenergytrajectories}, disagreements larger than 1~$k_{B}T$ in the final part of the forward and reverse trajectories can be useful to detect unconverged results (see also Fig.~\ref{fig:convergence_forward_reverse}).
In this case, one can extend the simulations or try an approach that requires simulations in two separate binding modes where they interconvert at very slow timescales.  
\begin{figure}
    \includegraphics[width=0.90\linewidth]{figures/fig9_convergence/Figure.pdf}
    \caption{Average binding free energy of 5 replicate Hamiltonian replica exchange calculations as a function of total simulation time (i.e. the sum of the simulation time of all replicas) for the two host-guest systems CB8-G3 and OA-G6. Shaded areas represent 95\% confidence intervals around the mean computed from the 5 replicates data. The horizontal dash-dot lines show the final binding free energy prediction of the two calculations after a total of 5230 ns for OA-G6 and 6650 ns for CB8-G3. Dashed lines are the free energy trajectories computed in the forward (blue) and reverse (red) time direction for a single replicate calculation. Longer correlation times in CB8-G3 cause the calculation to converge more slowly. The original data used to generate the plot can be found at \url{https://github.com/samplchallenges/SAMPL6/blob/master/host_guest/Analysis/SAMPLing/Data/reference_free_energies.csv}.
}
    \label{fig:freeenergytrajectories}
\end{figure}

\paragraph{Overlap matrix}
One way of assessing reliability of the calculations is checking the phase space overlap between neighboring $\vec{\lambda}$-windows~\cite{wu2005phasespace, wu2005phasespacea}. For this purpose, a so-called overlap matrix $\mathcal{O}$ can be used. $\mathcal{O}$ is a $K\times K$ matrix, with $K$ being the number of simulated states, i.e. values of $\vec{\lambda}$. Sufficient overlap is important for reweighting estimators such as BAR or MBAR, but cannot help assess reliability of estimates when using TI. 
These matrices are graphical representations of the phase space overlap, i.e. the average probability that a sample generated at state $\vec{\lambda}_{j}$ can be observed at state $\vec{\lambda_{i}}$. As this probability is computed considering the samples from all states, and not just the adjacent states, the values in each row and column add up to 1. In this analysis, the goal is to ensure every state has overlap with its neighbors in both directions, indicated by off-diagonal elements that are sufficiently larger than zero. For accurate calculations, the matrix should be at least tridiagonal.

Details on the calculation and properties of these matrices can be found elsewhere~\cite{klimovich2015guidelines}.
In an overlap matrix $\mathcal{O}$, the off-diagonal values (${O}_{i,j,i\ne j}$) are negatively correlated with the variance of the free energy difference. Accordingly, the uncertainty of the free energy difference between the states $i$ and $j$ will be smaller when ${O}_{i,j,i\ne j}$ is larger (and thus the values in the main diagonal (${O}_{i,j,i=j}$) are smaller). 
Ensemble simulations generate wider distributions of energies and hence are expected to increase the overlap between neighboring states~\cite{wade2022}.
In order to obtain a reliable estimate of the free energy all neighboring states must be connected, i.e. there must be sufficient overlap between the samples of these states, such that ${O}_{i,j,i\ne j}\ge$ threshold).
However, due to the mathematical derivation it is difficult to explicitly describe the relation of the overlap matrix and the variance by formulae. Consequently, the threshold has to be derived empirically. It has been proposed that the values of the first off-diagonals (i.e. the diagonals above and below the main diagonal) should at least be 0.03 to obtain a reliable free energy estimate~\cite{klimovich2015guidelines}. Smaller values should be considered as a warning sign (see Fig.~\ref{fig:overlap}\textbf{C}), as the variance tends to be underestimated in case of poor overlap.

\begin{figure}
\includegraphics[width=0.90\columnwidth]{figures/fig12_overlap/Figure.pdf}
\caption{\label{fig:overlap} \textbf{Overlap matrices:} Visualizing overlap matrices can help with assessing the quality of simulation data. (\textbf{A}) shows good overlap with all first off-diagonal entries well above 0.03, the suggested threshold, (\textbf{B}) is an example of mediocre overlap with good overlap at lower $\vec{\lambda}$ values and poor overlap at high $\vec{\lambda}$ values. (\textbf{C}) shows poor overlap resulting in disconnected simulations with unreliable MBAR estimates.}
\end{figure}

Fig.~\ref{fig:overlap}\textbf{A}, \textbf{B}, and \textbf{C} shows examples of good, mediocre, and poor overlap respectively. For Fig.~\ref{fig:overlap} \textbf{A}, the probability to find a sample from state $i$ in its neighboring state $j$ is about 0.2 for all states adjacent to the main diagonal, and hence the overall connectivity is good. In the case of Fig.~\ref{fig:overlap} \textbf{B}, the overlap is strongly diminishing in the lower right corner, raising concerns regarding the reliability of the free energy estimate obtained. For Fig.~\ref{fig:overlap} \textbf{C}, the state at $\vec{\lambda}$ index = 6 is connected to neither of its neighboring states. While this does not necessarily imply that the result for this perturbation is wrong, the energy estimate must at least be considered as highly unreliable.
In order to overcome the issue of poor overlap in this example, additional sampling should be performed by introducing additional states, i.e. $\vec{\lambda}$ values.

Interestingly, as the variance is inversely correlated with the number of states~\cite{klimovich2015guidelines}, it can in principle be reduced below any arbitrary threshold with enough simulation time and a large enough number of $\vec{\lambda}$ windows. However, decreasing the variance to a value close to 0 is not feasible, as this approach would significantly increase the calculation time. While variance can be decreased by increasing simulation length, if the overlap between states is known to be poor, increasing the number of $\vec{\lambda}$ values, or adjusting the spacing of those values to better cover regions of poor overlap will likely provide a larger immediate impact. Different approaches are described in Sec.~\ref{sec:simulation_protocol_choice} and more details can be found in the literature~\cite{dakka2018concurrent, hahn2019alchemical}.

The precision of NEQ calculations is determined by the overlap between the forward and reverse work distributions corresponding to out-of-equilibrium transitions between the two end-points. To estimate the overlap, Wu \& Kofke suggest using dissipated work values which can be shown to correspond to the relative entropies of the densities in the phase space. \cite{wu2005phase} Another approach to assess NEQ convergence relies on calculating the first two moments of the Fermi function in Bennett Acceptance Ratio estimator. \cite{hahn2010measuring} Since the second order estimate converges slower than the first, the overall convergence of the free energy estimate can be quantified as the normalized difference between the two moments of the Fermi function. 

In practice, analytical error estimate of the BAR estimator \cite{shirts2003equilibrium} gives an indication when the overlap is lacking: the estimated error rapidly grows with the increase in the dissipated work. \cite{shirts2005comparison} Bhati~\textit{et al.} recently studied the effect of such overlaps on the accuracy of predicted RBFEs~\cite{wan2023eqvsneq} as well as ABFEs~\cite{bhati2025} but found that overlap (or lack of it) does not capture the reliability of calculations very well. They recommended an alternative metric, ``distance'' defined as the difference between the inner extremes of the two work value distributions, which correlates quite well with the unsigned errors in free energy predictions and hence was found a better indicator of the reliability of NEQ calculations. 

\paragraph{Reversible binding simulations}
An even more stringent test of the correctness of binding free energy calculations is to compare the results to the equilibrium binding constants derived from long timescale reversible binding simulations~\cite{pan2017quantitative}. For small ligands with millimolar affinities, repeated binding to and unbinding from the protein can occur for a large number of times in a sufficiently long unbiased MD simulation (10-100 $\mu$s), and the equilibrium binding constants can be computed from the ratio of bound to unbound fractions of the simulation time. 
It is worth highlighting here that the necessity of ensemble simulations to capture the true uncertainty in predictions ensuring their reliability is equally applicable for long simulations. Bhati \textit{et al.} performed ensembles of 10 microsecond long simulations and reported large variability in several properties calculated from each replica~\cite{bhati2023}.
The agreement between the binding free energy calculations and the reversible binding simulations---given the same system preparation and the same force field parameters---will strongly support the correctness of both calculations, as the same results are arrived at by two independent methods, and any discrepancy will suggest some systematic error in one, or both, of the two methods. As part of validation testing of alchemical free energy codes a benchmark set to compare alchemical and direct computation of equilibrium binding constant should become standard in future.

\subsection{Common issues to watch out for during analysis}

It is important to carefully examine output data for common problems. Some of the most important things to check for are:
\begin{itemize}
\item \textbf{Sampling of the binding site by the ligand:} Make sure the ligand samples the binding site reasonably tightly for its expected potency and fit, and that it does not depart out of binding site in the coupled end state if it is a moderate to strong binder. 
\item \textbf{Consistency of free energy estimates across different estimators} Significant discrepancies, meaning results that further outside the mutual error estimates than would be plausible statistically, between free energies calculated with different free energy estimators such as TI, BAR, and MBAR. All of these estimators converge to the same results with sufficient sampling. Reports have shown that the use of ensemble simulations can ensure good agreement between different estimators as well as MD engines~\cite{wade2022}. Differences between them indicate poor overlap or errors in processing.
\item \textbf{Have replicas mixed well?} Poor replica mixing (for replica-exchange) or $\lambda$-space sampling for single-replica methods. If the system is not mixing between states, then the states are insufficiently close for mixing, or else there are bottlenecks in the configurational sampling that limit the accuracy.
\item \textbf{Behavior of correlation times:} Correlation time that does not vary relatively smoothly as a function of $\vec{\lambda}$. Discontinuities in correlation time with $\vec{\lambda}$ indicate that the system is sampling significantly different configurations with only small changes to the Hamiltonian changes. This usually indicates sampling problems.
\item \textbf{Dependence of the free energy on initial configuration of the system.} Ensemble average properties should not depend on the starting point.  This is a particular instance of the utility of running multiple independent simulations; if there is statistically significant differences between the independently run simulations, there is likely a lack of sampling. 
\item \textbf{Torsional sampling} Torsions with multiple low-energy minima where some of these minima are visited rarely or not at all. Which torsions have low energy minima can best be found by comparing to the simulation in the solvent. There should be clear physical reasons that simulation in the complex has different torsional distributions than the ligand in the solvent. 
\item \textbf{Free energy dependence on $\vec{\lambda}$} The free energy difference between states should vary relatively smoothly with $\vec{\lambda}$. If it varies drastically, then either there needs to be finer sampling in $\vec{\lambda}$ in this region, or there are sampling problems present in at least these simulations (if not simulations at other $\lambda$.
\item \textbf{Convergence of free energy} The free energy should clearly converge as a function of simulation time (Fig. ~\ref{fig:convergence_forward_reverse}). Convergence of the free energy as a function of time is necessary, but not sufficient.  It does not guarantee that simulations have run long enough, but lack of convergence means they certainly have not sampled the relevant configuration space.
\item If using non-equilibrium methods, \textbf{is the result independent of the speed at which the non-equilibrium change is performed}? Non-equilibrium methods are in theory independent of the switching time in the limit of good sampling unless the switching time is simply too short. 
%\item Other Diagnostics for non-equilibrium methods, robustness for switching time etc.?
\item \textbf{Visualization of data} In general, always inspect output data such as kinetic or potential energies, pressures, and volumes as a function of time, and visualize the simulation trajectories and assess if they match your expectations. Many issues can be spotted by a straightforward visualization. 
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Conclusions                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Unsettled Practices and Current Limitations}
\label{sec:unsettled}

\subsection{Unsettled practices}

Alchemical Free Energy (AFE) calculations have primarily been applied to simulate the stoichiometric, non-reversible binding of organic molecules to well-structured proteins. However, several areas of drug discovery involve other classes of binding events. While the underlying theory of alchemical free energy calculations is generally applicable, additional work may be required to develop efficient protocols suited to systems beyond the traditional small moleculeprotein complex.
For example, there is growing interest in identifying small molecules that directly bind to RNA or DNA, with recent preliminary studies showing promising results using specialized simulation protocols.\cite{Abramyan2025,Rasouli2024} In contrast, there has been limited investigation into the applicability of AFE methods to small-molecule ligands targeting intrinsically disordered proteins (IDPs,\cite{Papadourakis2024} or proteins containing intrinsically disordered regions (IDRs) that undergo disorder-to-order transitions upon ligand binding.\cite{MendozaMartinez2022}
The treatment of covalent binders has also received some attention.\cite{luo2021,zhang2019} However, robust protocols for handling datasets of irreversible covalent binders containing diverse warheads have not yet achieved widespread adoption.\cite{Yu2019} A variety of other applications are less traditional and may be possible but raise new practical issues; for example, if multiple copies of a ligand bind at once in the same site, this could pose challenges, as could handling of binding and function prediction for molecular glues and related categories of molecules. 

Relative free energy calculations carry with them additional unsettled practices relating to the use and careful treatment of dummy atoms (see ``Dummy Atoms'' in Section~\ref{sec:relative-fe-protocol}). In particular, as the work of~\cite{Fleck_2021} highlighted, valence terms for dummy atoms for dummy atoms must be treated far more carefully than previously appreciated in order for dummy atoms' contributions to the free energy to rigorously cancel. Less careful treatments may leave dummy atom terms only approximately canceling, or, worse, introducing uncharacterized errors in relative binding free energies. Indeed, such issues might have impeded previous attempts at reproducing free energy calculations across simulation engines~\cite{loeffler2018reproducibility}. 

While solutions to dummy atom challenges may in principle be known, most are not yet implemented in setup tools and free energy pipelines and have not yet been thoroughly characterized, so it seems likely that considerable science and engineering remains to be done in this space. 

More broadly, although several enhanced sampling strategies have been proposed to address configurational sampling bottlenecks in alchemical simulations, widely accepted best practices for detecting and resolving such challenges in a systematic and automated fashion remain elusive. 

\subsection{Current limitations}

% notthing here?  It would actually be really nice to summarize this. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Conclusions                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}
\label{sec:conclusion}
Alchemical free energy calculations have seen a vast increase in popularity both in academic research as well as pharmaceutical industry applications in structure based drug discovery~\cite{schindler2020largescale, sherborne2016collaborating, wagner2017computational}. Commercial products such as FEP+ and Flare, which provide a convenient user interface make the setup and use of these methods much easier~\cite{wang2015accurate, kuhn2020assessment}, but this convenience comes with less flexibility in terms of choice of simulation protocols. It is also important to understand the current limitations of the methodology to recognise when automated workflow tools can be used effectively for a given protein target and when they are likely to fail still. Prospective prediction challenges such as the Drug Design Data resource grand challenges provide a community driven platform to evaluate different free energy protocols against each other on blinded targets~\cite{gaieb2018d3r, gaieb2019d3r}. Such efforts have highlighted that selection of seemingly identical or similar potential energy function or simulation package does not guarantee production of similar free energies owing to differences in simulation protocols. 
We hope that the best practice guide provides a set of tools that allow a better understanding of how to setup, run, and reliably interpret alchemical free energy calculations. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Software                    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Selection of available software packages}

\label{sec:software}
There are many different software solutions available for the setup, running, and analysis of alchemical free energy calculations. These will vary in customizability and ways in which they are ran, e.g. graphical user interface versus command line tool or python script. The following provides a non-exhaustive list of commercial and noncommercial tools available for conducting alchemical free energy calculations. 
\begin{itemize}

\item [] \textbf{Simulation software: Commercial}
   \begin{itemize}
    \item \href{https://www.schrodinger.com/fep}{FEP+} is a tool offered by Schr\"{o}dinger Inc. under a commercial license. It has an intuitive GUI which makes it easier for non-experts to run alchemical free energy calculations and analyze the results. It runs the DESMOND MD package under the hood and hence parallelizes well on GPUs~\cite{wang2015accurate}. 
    \item \href{https://www.cresset-group.com/software/flare/}{Flare} is a commercial structure-based drug design software offered by Cresset. Similar to FEP+ it has an easily accessible graphical user interface and strives to facilitate free energy calculations for non-experts while offering advanced users full control via a Python API. It only runs on GPUs, using CUDA or OpenCL~\cite{kuhn2020assessment}. It is built on top of the open source software packages Sire and BioSimSpace (cf. below).
    \item \href{https://www.eyesopen.com/orion}{Orion}, OpenEye's cloud platform, offers relative binding free energy calculations using non-equilibrium switching (Section~\ref{sec:sampling_schemes})~\cite{sorensen2024orion}.
    \item The molecular operating environment (\href{https://www.chemcomp.com/Products.htm}{MOE}) offered by the Chemical Computing Group (CCG) has a tool for performing free energy calculations. It is built on AMBER-TI (cf. below).
    \end{itemize}
    \item[]All the above tools also provide a convenient setup and analysis suite and are really a one in all product. \newline
\item [] \textbf{Simulation software: Free/low cost academic and Commercial}
	\begin{itemize}
	\item \href{https://www.charmm.org/}{CHARMM} has a variety of tools developed over the years. The PERT module can be used to define initial and final states and define the intermediate lambda points. FREN and BAR modules can be used to analyse the data after the MD run. Lambda-dynamics-based free energy calculation can be carried out using the BLOCK module. GPU optimized implementation of CHARMM's lambda dynamics is also implemented in the new package BLaDE \cite{hayes2021blade}. A number of energy interpolation schemes have been implemented in the new GPU package apoCHARMM \cite{prasad2025apocharmm}.     
	\item \href{https://ambermd.org/}{AMBER}, including its GPU-accelerated free energy engine~\cite{Lee_JChemTheoryComput_2017_v13_p3077,Giese_JChemTheoryComput_2018_v14_p1564,Lee_JChemInfModel_2018_v58_p2043} that supports a wide range of alchemical free energy methods~\cite{Tsai_JChemTheoryComput_2023_v19_p640,lee2023aces,Zhang_JChemTheoryComput_2024_v20_p3935}, workflows~\cite{Ganguly_JChemInfModel_2022_v62_p6069} and analysis tools~\cite{Giese_JChemInfModel_2025_v65_p5273,Case_JChemInfModel_2023_v63_p6183}. 
	\item \href{http://www.gromos.net/}{GROMOS} offers an extensive and flexible molecular dynamics and simulations analysis suites with free energy calculation functionalities including customizable alchemical paths and various sampling protocols~\cite{schmid2012architecture, kunz2012new, eichenberger2011gromos}.
	\end{itemize}
\item [] \textbf{Simulation software: Open Source}
	\begin{itemize}
	\item \href{https://www.plumed.org/}{PLUMED} is a tool which enables the usage of a variety of MD engines. It is designed as a plugin for MD packages such that it analyzes the trajectory on the fly. It also offers a VMD based plugin for the computation of collective variables~\cite{bonomi2019promoting}.   	
	\item \href{https://biosimspace.org/}{BioSimSpace} is a multiscale molecular simulation framework, written to allow computational modellers to quickly prototype and develop new algorithms for molecular simulation and molecular design~\cite{hedges2019biosimspace, hedges2023suite}. 
	\item \href{https://siremol.org/}{Sire} is a multiscale, molecular simulation framework that provides several applications, including SOMD, an MD/MC code for performing FEP calculations via an interface to OpenMM~\cite{woods2024sire}. 
        \item \href{https://github.com/choderalab/openmmtools}{OpenMMTools} provides tooling for creating alchemical simulations using OpenMM. These include tools for alchemically modifying OpenMM Systems, running multistate simulations and adding alchemical restraints \cite{john_chodera_2025_17238654}.
	\item \href{http://www.gromacs.org/}{GROMACS} is a molecular simulation package with a significant number of free energy methods implementations. The LiveCOMS GROMACS tutorial includes an example free energy calculation~\cite{lemkul2018From}.
	\item \href{http://pmx.mpibpc.mpg.de/instructions.html}{PMX}, an add-on to GROMACS, offers a mutation free energy calculation module~\cite{abraham2015gromacs}.
	\item \href{https://github.com/qusers/Q6}{Q} is MD code for performing FEP calculations using a variety of force fields~\cite{aaquist2017q6}. 
    \item \href{http://www.ties-service.org}{TIES} enables the usage of NAMD and OpenMM for setting up alchemical free energy ensemble simulations \url{https://github.com/UCL-CCS/TIES_MD} \cite{bieniek2023}.
    \item \href{https://openfree.energy/}{Open Free Energy} is a platform which offers and allows the creations of alchemical simulation workflows for both absolute and relative binding free energies. Current offerings, notably includes a \href{https://github.com/choderalab/perses/tree/main/perses}{Perses-based} hybrid topology method using OpenMM \cite{alibay_2025_17258732}.
    \item \href{https://github.com/Gallicchio-Lab/AToM-OpenMM}{AToM-OpenMM} is a Python package for running simulations using the Alchemical Transfer Method in OpenMM \cite{azimi2022relative, wu2021alchemical,gallicchio2008,gallicchio2025mutants}.
    \item \href{https://github.com/Psivant/femto/tree/main}{Femto} is a Python package for running conventional MD and free energy simulations. Notably it implements tooling for Separated Topologies\cite{baumann2023broadening} and the Alchemical Transfer Method\cite{azimi2022relative,wu2021alchemical,gallicchio2008,gallicchio2025mutants}.
	\end{itemize}
\item[] \textbf{Setup tools:}
	\begin{itemize}
	\item \href{http://pmx.mpibpc.mpg.de/instructions.html}{PMX}: Setup of perturbation maps, perturbed topologies and input coordinates for GROMACS simulations at \url{https://github.com/deGrootLab/pmx}.
	\item \href{https://github.com/OpenFreeEnergy/Lomap}{Lomap/Lomap2} : Relative alchemical transformation graph planning for setting up perturbation networks~\cite{liu2013lead}.
        \item \href{https://github.com/OpenFreeEnergy/kartograf} 
    Kartograf: An geometry-based atom mapper for setting up relative free energies with a conserved core~\cite{ries2024kartograf}.
        \item \href{https://github.com/OpenFreeEnergy/Konnektor}
    Konnektor: Tooling to aid in the creation of alchemical perrturbation networks~\cite{ries2024konnektor}.
	\item \href{http://www.charmm-gui.org/}{CHARMM-GUI} is a web-based tool for setting up a variety of MD simulations. It can be used to generate CHARMM scripts for solvation and ligand-binding free energy calculations~\cite{jo2008charmmgui}.
	\item \href{https://github.com/qusers/qligfep}{QligFEP} offers robust and fast setup of FEP calculations for the software package Q~\cite{jespers2019qligfep}.
        \item 
    \href{https://github.com/cbc-univie/transformato}{transformato} is a package for setting up single topology alchemical transformations to be run using CHARMM or OpenMM \cite{karwounopoulos2022relative, karwounopoulos2023calculations, wieder2022alchemical}.
    \item \href{http://www.ties-service.org}{TIES} allows the setup of perturbation maps, hybrid topologies and structures as well as simulation-ready models for NAMD and OpenMM \url{https://github.com/UCL-CCS/TIES} \cite{bieniek2023}.
	\end{itemize}
\item []\textbf{Analysis tools:}
	\begin{itemize}

	\item Alchemlyb: Multipackage free energy analysis
	\url{https://github.com/alchemistry/alchemlyb}~\cite{daviddotson2020alchemistry}.
	\item pymbar: MBAR implementation, but have to roll your own analysis wrapper      
	\url{https://github.com/choderalab/pymbar} \cite{shirts2008statisticallya}.
	\item \href{https://github.com/OpenFreeEnergy/cinnabar}{Cinnabar}: Standardising alchemical free energy analysis. Includes tools for calculating network-wide analyses and deriving absolute free energies using a maximum-likelihood estimator \cite{richard_gowers_2025_15678719}.
        \item \href{https://gitlab.com/RutgersLBSR/fe-toolkit}{FE-Toolkit}: collection of packages for free energy analysis, including network-wide MBAR analysis~\cite{giese2025fe}.
    \item \href{http://www.ties-service.org}{TIES}: Perform statistical analysis of the output of alchemical ensemble simulations and report reliable predictions along with statistical uncertainties for a variety of free energy estimators \url{https://github.com/UCL-CCS/TIES_MD} \cite{bieniek2023}.
	\end{itemize}
\item[] Generally, commercial software will offer more complete pipelines in which standalone analysis applications are not necessarily needed; free and open source packages often require manual analysis but allow more flexibility and modification.
\end{itemize}


\section{Checklist}
\label{sec:checklist}
\begin{Checklists*}
\begin{checklist}{ Know what you want to simulate}
    \textbf{Initial questions you should ask before you set up an alchemical free energy calculation using molecular dynamics simulations}
\begin{itemize}
    \item Is my problem suitable for an alchemical calculation?
    \item Do I understand the biology, chemistry, and physics of my system (e.g., binding modes, protonation states at assay pH, or membrane environment)?
    \item Have I properly prepared my protein and ligand systems (e.g., the use of high-quality starting structures, inclusion of binding site waters and cofactors, stereochemistry considerations)?
    \item Does my system contain any structures that require custom parameters?
    \item What simulation protocol will provide the most evidence to verify my hypothesis?
    \item Are the projected computational expense and runtime realistic for my scientific goals?
    \item Will my protocol be reproducible? 
    \item Will my statistics be reliable? If not, would more replicates solve the problem? 
    \item Can I open-source my data?
\end{itemize}
\end{checklist}

\begin{checklist}{Preparing your simulations}
\textbf{Steps to getting started setting up your alchemical free energy calculation}
\begin{itemize}
    \item Make sure you know why you have picked your (combination of) force field(s)
    \item Energy minimize your system
    \item Equilibrate your system properly with your choice of thermodynamic ensemble
    \item Check the stability of your system and whether it behaves the way you believe it should
\end{itemize}
\end{checklist}

\begin{checklist}{Running absolute simulations}
        \textbf{Steps to running your absolute alchemical free energy calculations}
\begin{itemize}
 \item Check your ligands have the biologically correct binding pose(s)
        \item Make sure your \textlambda-scheduling is  appropriate
        \item Check if your ligands are discharging and decoupling correctly
        \item Set up your restraints correctly
        \item Subsample the data to estimate the variance of your free energy estimation protocol (but not to estimate the values themselves)
        \item Apply the appropriate correction terms
        \item Ensure sufficient configurational sampling for slow degrees of freedom (e.g., check for kinetic trapping in metastable states).
\end{itemize}
\end{checklist}

\begin{checklist}{Running relative simulations}
        \textbf{Steps to running your relative alchemical free energy calculations}
\begin{itemize}
   \item Check your ligands  have the same, biologically correct binding pose
        \item Make sure your $\lambda$-scheduling is set correctly
        \item Make sure your molecular transformations are realistic (1-5 heavy atoms for reliable computations)
        \item Generate a perturbation network by your method of choice; check whether you have enough cycle closures to check consistency in the results
        \item Check whether dummy atoms were assigned correctly
         \item Apply the appropriate correction terms
         \item Ensure sufficient configurational sampling for slow degrees of freedom (e.g., check for kinetic trapping in metastable states)
\end{itemize}
\end{checklist}
\end{Checklists*}

%Analyis checklist
\begin{Checklists*}
\begin{checklist}{How do I know which simulations are unreliable?}
    \textbf{Situations suggesting your alchemical free energy calculations have not run properly (assuming absence of experimental affinities)}
        \begin{itemize}
                \item Standard error (\textsigma) should not be \textgreater1 kcalmol$^{-1}$ 
    \item Simulated systems have not converged - trajectories should be manually checked for consistency; other methods such as generating RMSD plots are also recommended
    \item Simulated systems not sampling all relevant conformational states (e.g., different torsional states of a side chain in a binding pocket) that are expected to impact free energy values.
    \item Statistically significant differences in free energy estimates from simulations starting from different initial states usually indicate insufficient configurational sampling
    \newline\newline\textit{Relative:}
    \item If you observe hysteresis in perturbations and incorrect cycle closures
    \item Energy differences \textgreater$\sim$15 kcal$\cdot$mol$^{-1}$  are likely unreliable
    \newline\newline\textit{Absolute:}
    \item Energies \textless$\sim$-15 kcal$\cdot$mol$^{-1}$  are likely unreliable
    \item The ligand has not sampled most of the intended region after the decoupling step
    \item The ligand is drifting out of the intended region after the decoupling step
        \end{itemize}
\end{checklist}

\begin{checklist}{Why are they not reliable?}
    \textbf{Suggestions for finding out why your alchemical free energy calculations may not be reliable}
\begin{itemize}
    \item Check again whether dummy atoms were assigned correctly
    \item Inspect the trajectories across the $\lambda$-schedule (particularly the endpoints) for problems described in the text
    \item Inspect the overlap matrices for lack of overlap
    \item Check if all relevant conformational states are sufficiently sampled 
\end{itemize}
\end{checklist}

\begin{checklist}{Data Analysis}
    \textbf{Steps to analyzing your output data correctly}
\begin{itemize}
    \item Decide which calculated values to assess, e.g., shifted or unshifted $\Delta G$,  $\Delta \Delta G$ of computed edges, or $\Delta \Delta G$ of all edges
    \item Discard the equilibration region. Subsample the data to estimate the variance of your free energy estimation protocol (but not to estimate the values themselves)
    \item Examine the phase space overlap and the convergence of your simulation
    \item Make sure you have run enough replicates to ensure statistical reliability (\textgreater3)
    \item Compute both correlation and ranking coefficients and ranking statistics (e.g., r, \textrho, MUE and \texttau)
    \item Include error bars in all your visual analyses, and state how they were calculated.
    \item Consider bootstrapping uncertainties rather than using free energy error estimators
\end{itemize}
\end{checklist}
\end{Checklists*}
\clearpage


\section*{Author Contributions}
%%%%%%%%%%%%%%%%
% This section mustt describe the actual contributions of
% author. Since this is an electronic-only journal, there is
% no length limit when you describe the authors' contributions,
% so we recommend describing what they actually did rather than
% simply categorizing them in a small number of
% predefined roles as might be done in other journals.
%
% See the policies ``Policies on Authorship'' section of https://livecoms.github.io
% for more information on deciding on authorship and author order.
%%%%%%%%%%%%%%%%
\textbf{ASJSM}: Coordinated the document, contributed to most sections, and co-designed Figs.~\ref{fig:fig_binding_thermodynamic_cycle},~\ref{fig:fig_topology},~\ref{fig:fig_mcss},~\ref{fig:fig_types_of_networks},~\ref{fig:fig_absolute_thermodynamic_cycle},~\ref{fig:scatterplot_analysis}, and created Figs.~\ref{fig:fig_what_is_lambda},~\ref{fig:fig_what_is_alchemy},~\ref{fig:overlap},~\ref{fig:pmf} and replotted~\ref{fig:automatic-equilibration-detection} and~\ref{fig:fig_types_of_networks}.\\
\textbf{BA}: Helped write the uncertainty estimation, stopping conditions, and output analysis sections and created figure ~\ref{fig:convergence_forward_reverse}.\\
\textbf{IA} Reviewed and contributed to Sec. ~\ref{sec:prerequisites}, ~\ref{subsec:hydration}, and ~\ref{sec:multiple-chemical-states}. Updated Sec. ~\ref{sec:software}.
\textbf{APB} Contributed updates to the discussion of uncertainty quantification.\\
\textbf{SB} Wrote the sections on topologies and dummy atoms in Sec.~\ref{sec:relative-fe-protocol} and contributed to the discussion and review of many sections, in particular Sec.~\ref{sec:standardstate-restraints}.\\
\textbf{HBM} Contributed to Sec.~\ref{sec:plot_data} and Fig.~ \ref{fig:scatterplot_analysis} and helped edit the paper.\\
\textbf{JDC}: Wrote Sec.~\ref{sec:decorrelating-samples} and~\ref{sec:automatic-equilibration-detection} discussed structure and design of the whole document, suggested Figs.~\ref{fig:fig_what_is_alchemy} and~\ref{fig:fig_sampling_scheme}. \\
\textbf{FC}: Coordinated the v2.0 updates to the article (TODO: be more specific?/ mention ABFE updates?). \\
\textbf{PVC} Contributed updates to the discussion of uncertainty quantification.\\
\textbf{JWE} Contributed to ``Conserved binding site waters can play an important role in binding free energies'' and ``Handling poorly sampled water networks'' in Sec. ~\ref{subsec:binding}.\\
\textbf{EG} Wrote the updated Sec.~\ref{sec:theory} and Sec.~\ref{sec:multiple-chemical-states},  updated Sec.~\ref{sec:standardstate-restraints}, and contributed to the discussion and review of many sections.\\
\textbf{MG} Contributed to ``Changes in net charge can be challenging/problematic'' in Sec. \ref{subsec:net charge}. \\
\textbf{DFH} Contributed to Sec.~\ref{sec:software} and helped edit the paper. \\
\textbf{W-TH}: Wrote Sec.~\ref{sec:configurational_sampling}, updated Sec.~\ref{sec:prerequisites},~\ref{sec:unsettled}, and~\ref{sec:checklist}, and created Fig. ~\ref{fig:configurational_sampling}.\\
\textbf{SK}: Contributed to Sec. \ref{sec:theory} and \ref{sec:standardstate-restraints}  \\
\textbf{MK}: Contributed to Sec.~\ref{sec:data_analysis}, provided the data for figure~\ref{fig:overlap}, compiled the dataset for Sec.~\ref{sec:benchmark} and helped edit the paper.\\
\textbf{JM}: Contributed to Sec.~\ref{subsec:reproducible},~\ref{sec:prerequisites},~\ref{sec:important_path},~\ref{subsec:estimators},~\ref{subsec:uncertainty}, and~\ref{sec:conclusion}\\
\textbf{DLM}: Contributed to the outline, drafted some of the sections, gave ideas on figures, and helped edit the paper.\\
\textbf{LNN}: Helped write the simulation length, stopping conditions, and information saving section. Edited and reviewed alchemical path section.\\
\textbf{MO} Contributed to Section \ref{subsec:hydration}.\\
\textbf{CO} Contributed to ``Changes in net charge can be challenging/problematic'' in Sec. \ref{subsec:net charge}. \\
\textbf{WJP} Contributed to ``Conserved binding site waters can play an important role in binding free energies'' and ``Handling poorly sampled water networks'' in Sec. ~\ref{subsec:binding}.\\
\textbf{SP} Wrote Sec.~\ref{sec:software}. \\
\textbf{BR}: Updated Section \ref{subsec: Atom Mapping}, \ref{subsec: Dummy Atoms}, \ref{subsec: Ring breaking and forming} and supported reviewing for Topologies.\\
\textbf{AR}: Created figure~\ref{fig:freeenergytrajectories}, contributed to sections~\ref{sec:theory} and~\ref{sec:simulation_protocol_choice}, and helped edit the paper.\\
\textbf{JS}: Created Figs.~ \ref{fig:fig_what_is_alchemy},~\ref{fig:fig_binding_thermodynamic_cycle},~\ref{fig:fig_topology},~\ref{fig:fig_mcss},~\ref{fig:fig_absolute_thermodynamic_cycle},~\ref{fig:scatterplot_analysis}, and an initial draft of~\ref{fig:fig_types_of_networks}. Wrote Sec.~\ref{sec:plot_data}, the checklist Sec.~\ref{sec:checklist}, and contributed to general formatting discussions and editing.\\
\textbf{OJM} Contributed to ``Conserved binding site waters can play an important role in binding free energies'' and ``Handling poorly sampled water networks'' in Sec. ~\ref{subsec:binding}.\\
\textbf{MRS}: Helped create figure~\ref{fig:fig_what_is_lambda}, wrote Sec.~\ref{sec:important_path} describing choices for alchemical pathways and parts of~\ref{sec:data_analysis} on the analysis for free energy calculations. Reviewed and edited text throughout.\\
\textbf{GT}: Contributed to Sec.~\ref{sec:intro} and~\ref{sec:drugdiscovery}, and helped edit the paper.\\
\textbf{HX}: Contributed Sec.~\ref{subsec:accuracy}, to Sec.~\ref{sec:relative-fe-protocol}, and to Sec.~\ref{sec:are-they-good}.
% We suggest you preserve this comment:
For a more detailed description of author contributions,
see the GitHub issue tracking and changelog at \githubrepository.

\section*{Other Contributions}
%%%%%%%%%%%%%%%
% You should include all people who have filed issues that were
% accepted into the paper, or that upon discussion altered what was in the paper.
% Multiple significant contributions might mean that the contributor
% should be moved to authorship at the discretion of the a
%
% See the policies ``Policies on Authorship'' section of https://livecoms.github.io for
% more information on deciding on authorship and author order.
%%%%%%%%%%%%%%%
Julia E. Rice participated in the original discussion of the document at the Best Practices in Molecular Simulation Workshop Hosted by at NIST, Gaithersburg, MD, August 24th-25th, 2017.
Marieke Schor proofread the manuscript. 
We thank Sara Tkaczyk for creating Figure 3 (based on the earlier version by Jenke Scheen).


% We suggest you preserve this comment:
For a more detailed description of contributions from the community and others, 
see the GitHub issue tracking and changelog at \githubrepository.


\section*{Potentially Conflicting Interests}
%%%%%%%
%Declare any potentially competing interests, financial or otherwise
%%%%%%%
JM is a current member of the Scientific Advisory Board of Cresset. 
SK is employed by SandboxAQ.
MK is employed by Cresset who commercially distribute a software for performing alchemical free energy calculations. MRS is a Open Science Fellow and consultant for Silicon Therapeutics.
JDC is a current member of the Scientific Advisory Board of OpenEye Scientific Software and a consultant to Foresite Laboratories.
JWE receives research funding from AZ, Astex Pharmaceuticals, Exscientia, GSK, dstl, UCB, Diamond Light Source. Astex Pharmaceuticals part funds WGP., where he is now employed.
\section*{Funding Information}
%%%%%%%
% Authors should acknowledge funding sources here. Reference specific grants.
%%%%%%%
ASJSM and JM acknowledge funding through an EPSRC flagship software grant: EP/P022138/1
MK and JM acknowledge funding through Innovate UK by KTP partnership 011120.
AR acknowledges partial support from the Tri-Institutional Program in Computational Biology and Medicine and the Sloan Kettering Institute.
HEBM acknowledges support from a Molecular Sciences Software Institute Investment Fellowship and Relay Therapeutics.
DLM acknowledges support from the National Institutes of Health (R01GM108889, R01GM124270, and R01GM132386), and the National Science Foundation (CHE 1352608).
JDC acknowledges support from the National Institutes of Health (NIH P30 CA008748, NIH R01 GM121505, R01 GM132386), as does EG (NIH 1R15GM151708).
A complete funding history for the Chodera lab can be found at \url{http://choderalab.org/funding}.
The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.
FC acknowledges support from a UKRI Future Leaders Fellowship (Grant MR/T019654/1).
OJM, WGP, and JWE acknowledge funding from the EPSRC, Astex Pharmaceuticals, and Defence Threat Reduction Agency.
WTH acknowledges funding from Boehringer Ingelheim, which supports his postdoctoral position at the University of Oxford.
CO and MG acknowledge the financial support by the Austrian Federal Ministry for Digital and Economic Affairs, the National Foundation for Research, Technology and Development, the Christian Doppler Research Association, BASF, and Boehringer Ingelheim.
IA acknowledges funding from the Open Free Energy Fund. A list of financially contributing Open Free Energy members can be found at \url{https://openfree.energy/about/}.


\section*{Author Information}
\makeorcid
\bibliography{merged}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% APPENDICES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\appendix


\end{document}
