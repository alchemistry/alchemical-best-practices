%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% LIVECOMS ARTICLE TEMPLATE FOR BEST PRACTICES GUIDE
%%% ADAPTED FROM ELIFE ARTICLE TEMPLATE (8/10/2017)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PREAMBLE
\documentclass[9pt,bestpractices]{livecoms}
% Use the 'onehalfspacing' option for 1.5 line spacing
% Use the 'doublespacing' option for 2.0 line spacing
% Use the 'lineno' option for adding line numbers.
% The 'bestpractices' option for indicates that this is a best practices guide.
% Omit the bestpractices option to remove the marking as a LiveCoMS paper.
% Please note that these options may affect formatting.

\usepackage{lipsum} % Required to insert dummy text
\usepackage[version=4]{mhchem}
\usepackage{siunitx}
\usepackage{url}
\DeclareSIUnit\Molar{M}
\usepackage[italic]{mathastext}
\graphicspath{{figures/}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% IMPORTANT USER CONFIGURATION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[most]{tcolorbox}
\usepackage{enumitem,amssymb}
\usepackage{textgreek}
\usepackage{changepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Added to allow customisation of table of contents
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{tocloft}
\usepackage{xcolor}
\usepackage{todonotes}

% Define custom commands for colored TOC entries
\newcommand{\tocgreen}[1]{\textcolor{green}{#1}}
\newcommand{\tocorange}[1]{\textcolor{orange}{#1}}
\newcommand{\tocred}[1]{\textcolor{red}{#1}}

% Define custom commands for TOC entries with comments
\makeatletter
\newcommand{\tocsectioncomment}[1]{%
  \addtocontents{toc}{%
    {\leftskip \cftsecindent\relax
     \advance\leftskip \cftsecnumwidth\relax
     \rightskip \@tocrmarg\relax
     \textit{#1}\protect\par}}%
  \textit{#1}\par}

% Command for subsection comments in TOC
\newcommand{\tocsubsectioncomment}[1]{%
  \addtocontents{toc}{%
    {\leftskip \cftsubsecindent\relax
     \advance\leftskip \cftsubsecnumwidth\relax
     \rightskip \@tocrmarg\relax
     \textit{#1}\protect\par}}%
  \textit{#1}\par}

% Command for subsubsection comments in TOC
\newcommand{\tocsubsubsectioncomment}[1]{%
  \addtocontents{toc}{%
    {\leftskip \cftsubsecindent\relax
     \advance\leftskip \cftsubsubsecnumwidth\relax
     \rightskip \@tocrmarg\relax
     \textit{#1}\protect\par}}%
  \textit{#1}\par}

% aux. comments Stefan Boresch -> Stefan Boresch
\newcommand{\sbnote}[1]{%
  {\bfseries{}[SB: }%
  {\textcolor{blue}{#1}}{\bfseries{}]}
}

% aux. comments Emilio Gallicchio
\newcommand{\egnote}[1]{%
  {\bfseries{}[EG: }%
  {\textcolor{green}{#1}}{\bfseries{}]}
}



\newcommand{\rref}{{\bfseries[REFs]}{}}

\makeatother

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\versionnumber}{2.0} % you should update the minor version number in preprints and major version number of submissions.
\newcommand{\githubrepository}{\url{https://github.com/alchemistry/alchemical-best-practices}} %this should be the main github repository for this article
\newcommand{\expect}[1]{\left\langle{#1}\right\rangle}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE SETUP
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Best Practices for Single Alchemical Free Energy Calculations [Article v\versionnumber]}
\author[1*]{Antonia S. J. S. Mey}
\author[2]{Bryce K. Allen}
\author[3]{Hannah E. Bruce Macdonald}
\author[3*]{John D. Chodera}
\author[9]{Vytautas Gapsys}
\author[9]{David F. Hahn}
\author[1,10]{Maximilian Kuhn}
\author[1]{Julien Michel}
\author[4*]{David L. Mobley}
\author[5]{Levi N. Naden}
\author[6]{Samarjeet Prasad}
\author[2,7]{Andrea Rizzi}
\author[1]{Jenke Scheen}
\author[11]{David R. Slochower}
\author[8*]{Michael R. Shirts}
\author[9]{Gary Tresadern}
\author[2]{Huafeng Xu}

%
\affil[1]{EaStCHEM School of Chemistry, David Brewster Road, Joseph Black Building, The King's Buildings, Edinburgh, EH9 3FJ, UK}
\affil[2]{Silicon Therapeutics, Boston, MA, USA}
\affil[3]{Computational and Systems Biology Program, Sloan Kettering Institute, Memorial Sloan Kettering Cancer Center, New York NY, USA}
\affil[4]{Departments of Pharmaceutical Sciences and Chemistry, University of California, Irvine, Irvine, USA}
\affil[5]{Molecular Sciences Software Institute, Blacksburg VA, USA}
\affil[6]{National Institutes of Health, Bethesda, MD, USA}
\affil[7]{Tri-Institutional Training Program in Computational Biology and Medicine, New York, NY, USA}
\affil[8]{University of Colorado Boulder, Boulder, CO, USA}
\affil[9]{Computational Chemistry, Janssen Research \& Development, Turnhoutseweg 30, Beerse B-2340, Belgium}
\affil[10]{Cresset, Cambridgeshire, UK}
\affil[11]{Vertex Pharmaceuticals, San Diego, CA, USA}


%
\corr{antonia.mey@ed.ac.uk}{ASJSM}
\corr{john.chodera@choderalab.org}{JDC}
\corr{dmobley@mobleylab.org}{DLM}
\corr{michael.shirts@colorado.edu}{MRS}

\orcid{Antonia S. J. S. Mey}{0000-0001-7512-5252}
\orcid{Bryce Allen}{0000-0002-0804-8127}
\orcid{Hannah E. Bruce Macdonald}{0000-0002-5562-6866}
\orcid{John D. Chodera}{0000-0003-0542-119X}
\orcid{Maximilian Kuhn}{0000-0002-2811-3934}
\orcid{Julien Michel}{0000-0003-0360-1760}
\orcid{David L. Mobley}{0000-0002-1083-5533}
\orcid{Levi N. Naden}{0000-0002-3692-5027}
\orcid{Samarjeet Prasad}{0000-0001-8320-6482}
\orcid{Andrea Rizzi}{0000-0001-7693-2013}
\orcid{Jenke Scheen}{0000-0001-9781-0445}
\orcid{David R. Slochower}{0000-0003-3928-5050}
\orcid{Michael R. Shirts}{0000-0003-3249-1097}
\orcid{Gary Tresadern}{0000-0002-4801-1644}
\orcid{Huafeng Xu}{0000-0001-5447-0452}
\orcid{David F. Hahn}{0000-0003-2830-6880}
\orcid{Vytautas Gapsys}{0000-0002-6761-7780}

\blurb{This LiveCoMS document is maintained online on GitHub at \githubrepository; to provide feedback, suggestions, or help improve it, please visit the GitHub repository and participate via the issue tracker.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% PUBLICATION INFORMATION
%%% Fill out these parameters when available
%%% These are used when the "pubversion" option is invoked
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pubDOI{10.33011/livecoms.2.1.18378}
\pubvolume{2}
\pubyear{2020}
\articlenum{18378}
\datereceived{5 August 2020}
\dateaccepted{25 November 2020}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% ARTICLE START
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}

\begin{frontmatter}
\maketitle
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Abstract
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}


\todo[inline, color=green!20]{
    
The original best practices guide will be split into two documents: the first will gives best practices for running a \emph{single} calculation (and cover theory in more depth/ detail system-specific setup etc.), while the second will give best practices for running \emph{multiple} calculations (with a focus on automation). The first will become version 2.0 of the current guide, while the second will be submitted as a new manuscript.

This document outlines the contents of the first document for single calculations.
}

\todo[inline, color=green!20]{@Volunteer Update abstract to highlight the split of the document and focus on the single calculations.}

Alchemical free energy calculations are a useful tool for predicting free energy differences associated with the transfer of molecules from one environment to another.
The hallmark of these methods is the use of "bridging" potential energy functions representing \emph{alchemical} intermediate states that cannot exist as real chemical species. The data collected from these bridging alchemical thermodynamic states allows the efficient computation of transfer free energies (or differences in transfer free energies) with orders of magnitude less simulation time than simulating the transfer process directly. 
While these methods are highly flexible, care must be taken in avoiding common pitfalls to ensure that computed free energy differences can be robust and reproducible for the chosen force field, and that appropriate corrections are included to permit direct comparison with experimental data.

In this paper, we review current best practices for several popular application domains of  alchemical free energy calculations performed with equilibrium simulations, in particular relative and absolute small molecule binding free energy calculations to biomolecular targets.

% \todo[inline, color=green!20]{JDC: Should we migrate this document to \url{https://github.com/alchemistry}? ASJSM: Let's migrate with the submitted version, but leave it here for now?}
\end{abstract}
\end{frontmatter}

\newpage
% Add a comment to the top of the contents page
\addtocontents{toc}{\vskip2pt\noindent\textcolor{green}{\textbf{Green sections}: Minimal revisions required}\par\vskip2pt}
\addtocontents{toc}{\vskip2pt\noindent\textcolor{orange}{\textbf{Orange sections}: Substantial revisions required}\par\vskip2pt}
\addtocontents{toc}{\vskip2pt\noindent\textcolor{red}{\textbf{Red sections}: Needs written from scratch.}\par\vskip2pt}

\tableofcontents

\newpage

%%%%%%%%%%%%%%%%%%%%
%  Introduction    %
%%%%%%%%%%%%%%%%%%%%

\section{\tocgreen{What are alchemical free energy methods?}}
\tocsectioncomment{Steering Meeting: @Jenke Scheen to think about how figure can be made the "central axis" of the paper. Possibly update/ create new full-page figure and expand so that it shows a ``dummy workflow'' for an alchemical simluation including all general stages (e.g setup, analysis with different estimators etc.), and guides readers to appropriate sections.}
\label{sec:intro}
Alchemical free energy calculations compute free energy differences associated with transfer processes, such as the binding of a small molecule to a receptor, the transfer of a small molecule from an aqueous to apolar phase~\cite{zwanzig1954hightemperature}, or the effects of protein side chain mutations on binding affinities or thermostabilities. 
 These calculations use non-physical\footnote{Here, the non-physical nature of the transformation is referred to as "alchemical", a term coined by Tembre and McCammon in Ref.~\cite{tembre1984ligandreceptor}.} intermediate states in which the chemical identity of some portion of the system (such as a small molecule ligand or protein sidechain) is changed by modifying the potential governing the interactions with the environment for the atoms being modified, inserted, or deleted. 

Fig.~\ref{fig:fig_what_is_alchemy} illustrates common free energy changes that may be difficult to compute with unbiased molecular dynamics methods, but are more tractable with alchemical methods.
In alchemical simulations, the introduction of intermediate \textit{alchemical states} that bridge the high-probability regions of configuration space between two physical endstates of interest, permits the robust computation of free energy for large transformations.
Alchemical calculations can be used in a variety of scenarios, such as: 
\begin{itemize}
\item computing the free energy of a conformational change for a molecule with a high barrier to interconversion (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{A});
\item computing partition ($\log P$) or distribution ($\log D$) coefficients between environments (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{B})~\cite{rustenburg2016measuring, bosisio2016blinded} 
\item determining partitioning between compartments into membranes (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{C})~\cite{corey2019insights}. 
\end{itemize}

Furthermore, alchemical calculations are frequently used to estimate changes in free energies upon modifying a ligand or protein: 
\begin{itemize}
\item a protein residue can be alchemically mutated to probe the impact on binding affinity (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{D})\cite{hauser2018predicting,aldeghi2018accurate} or changes in protein thermostability~\cite{seeliger2010protein,gapsys2016insights,gapsys2016accurate,aldeghi2019accurate}; 
\item the entire ligand can be alchemically transferred from protein to solvent in an absolute binding free energy calculation (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{E})~\cite{mobley2007predicting,aldeghi2015accurate,aldeghi2017predictions}; 
\item small alchemical modifications can be made between chemically related ligands to estimate relative differences in binding free energies (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{F})~\cite{wang2015accurate,mey2016blinded,song2019using,gapsys2020large,kuhn2020assessment}.
\end{itemize}


After an alchemical calculation is performed, which generally involves multiple simulations at a variety of alchemical states, the data must be analyzed to compute an estimate of the free energy for the transformation of interest.
 Early work used simple but statistically suboptimal estimators for this: free energy perturbation (FEP) used a simple (but highly biased) estimator based on the Zwanzig relation~\cite{zwanzig1954hightemperature} or numerical quadrature via thermodynamic integration (TI), for which the theory dates back the better part of a century but with the first computational applications emerging in the 1980's and 90's~\cite{kirkwood1935statistical, jorgensen1985monte, kollman1993free, wong1986dynamics, merz1989free}. %
 More recent developments have seen new, highly efficient statistical estimators that make better use of all the data, often building on the more efficient and less biased Bennett acceptance ratio (BAR)~\cite{bennett1976efficient}, producing multistate generalizations~\cite{shirts2008statisticallya} or removing the need for global equilibrium~\cite{wu2016multiensemble, mey2014xtram, wu2014statistically}.

Subsequent work in the 2000s led to improved implementations of alchemical methods in popular biomolecular simulation packages~\cite{shirts2003extremely,shirts2005solvation,vanderspoel2005gromacs, mermelstein2018fast, wang2015accurate, hedges2019biosimspace, riniker2011calculation}. 
 This foundational work, combined with the methodological, technological, and hardware improvements of the last 5--10 years, has led to an explosion of interest and direct commercial application of these technologies~\cite{wang2015accurate, fratev2019improved, schindler2020largescale, cournia2017relative, sherborne2016collaborating, kuhn2020assessment}.


As the field of molecular simulation can now routinely access microsecond timescales with the aid of GPUs~\cite{salomon-ferrer2013routine}, and millisecond timescales appear to soon be within reach, accurate alchemical calculations on even more challenging problems will become reasonable to perform. 
In the meantime, today's users may find it difficult to get started with these complex calculations whilst also keeping up with the fast pace of change. 
This Best Practices guide provides current recommendations and tips for users of all experience. Updates and suggestions are welcomed via our GitHub repository at \url{https://github.com/alchemistry/alchemical-best-practices}.    

\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/fig1_what_is_alchemy/Figure.pdf}   
    \caption{\textbf{Illustration of common types of free energies differences that can be calculated using alchemical free energy methods.} \textbf{A}: Change in free energy due to a conformational change of the molecule across a high barrier. \textbf{B}: Partition coefficient such as $\log P$ or $\log D$ depend on a change in free energy between different phases; here, as an example the partition coefficient between methanol and water is shown. \textbf{C}: Free energy difference associated with the insertion of a molecule into a membrane. \textbf{D}: Effect of mutations of protein or host residues on free energies of binding. \textbf{E}: Relative free energy of binding of one molecule with respect to another, here toluene and benzyl alcohol, \textbf{F}: absolute free energies of binding of a small molecule to a host (e.g. protein).
    \label{fig:fig_what_is_alchemy}
    }
\end{figure}

%%%%%%%%%%%%%%%%%%%%
% Prerequesites    %
%%%%%%%%%%%%%%%%%%%%
\section{\tocorange{Prerequisites and Scope}}
\tocsectioncomment{Steering Meeting: @Volunteer to update reflecting new split between single and multiple calculations. @Michael Shirts to update best practices on multiple binding sites.}
\label{sec:pre}

This Best Practices guide focuses on providing a good starting point for new practitioners and a reference for experienced practitioners. 
 For this purpose we provide a convenient checklist (Sec.~\ref{sec:checklist}) to help ensure all calculations comply with currently-understood best practices for alchemical simulation and analysis. Where the best practices are currently not certain, we highlight areas where further research is needed to identify an unambiguous recommendation.
 This guide can also serve as a set of best practices to ensure simulation robustness and reproducibility which reviewers may wish to consider as they evaluate papers.

 We assume that novice practitioners have at least moderate experience with molecular simulation concepts and use of simulation packages. 
 Furthermore, basic familiarity with the principles of molecular mechanics, molecular dynamics simulations, statistical mechanics, and the biophysics of protein-ligand association are essential. If you feel unfamiliar with some of these concepts, good starting points can be found in these references~\cite{braun2019best, grossfield2018best, klimovich2015guidelines, shirts2012best}. 

 While reading this Best Practices guide, it is important to bear in mind \emph{this is not a review} of all free energy calculation methods at the cutting edge of current research.
Instead this guide aims to answer the following questions:
\begin{itemize}
    \item Is my problem suitable for an alchemical calculation? 
     \item How do I select an appropriate alchemical protocol? 
     \item What software tools are available to perform alchemical calculations? 
     \item How should I analyze my data and report uncertainties? 
\end{itemize}


Some other background information may be needed depending on the nature of the alchemical project. For example, often, if binding poses are not known, docking calculations can be used to generate an initial small molecule binding pose to start alchemical simulations. This will require some basic familiarity on how to perform docking to generate reasonable simulation starting points~\cite{grinter2014challenges}. 

As some of the theoretical background can seem daunting, we do, however, provide a guide to the essential theory behind alchemical free energy calculations in Sec.~\ref{sec:theory}.
In the remainder of this paper, we will cover topics that are key to the preparation (Sec.~\ref{sec:prerequisites}), choice and use of correct protocols (Sec.~\ref{sec:simulation_protocol_choice}), and finally the best practices that should be used in the analysis of alchemical calculations (Sec.~\ref{sec:data_analysis}). 
Particular focus will be given to aspects of the molecular simulations which are unique to alchemical calculations---these include the calculation of transfer free energies (hydration free energies, partition coefficients, etc.), and binding free energies (absolute and relative). We primarily focus on free energy calculations using simulations performed at \emph{equilibrium} in this Best Practices guide, as best practices for these are more developed, and non-equilibrium techniques may warrant their own guide as such practices evolve. 


While we try to address as many methods and practices as possible, the field of free energy calculations is broad, and there are many advanced topics that are left to future Best Practices documents focusing on specific issues. 
Below, we provide a non-exhaustive list of topics we have \emph{not} addressed, along with some references to provide starting points on these more advanced topics:
\begin{itemize}
\item covalent inhibition~\cite{lameira2019predicting}
\item free energies of mutation of protein side chains~\cite{gapsys2016accurate,aldeghi2018accurate}
\item nonspecific binding or multiple binding sites~\cite{gill2018binding}
\item approximate and often less accurate endpoint free energy methods such as MM-PBSA~\cite{genheden2015mm} and LIE~\cite{gutierrez-de-teran2012linear}
\item Free energy methods that extract the ligand using geometric order parameters and potential of mean force methods~\cite{heinzelmann2017attachpullrelease}
\item forcefield dependence for protein, ligand, ions, co-solvents, and co-factors. A number of different studies have looked at the influence of force fields and it is assumed the user has made an appropriate choice for the system under study~\cite{loeffler2018reproducibility, vassetti2019assessment, lopes2015current}. 
\item non-equilibrium free energy calculations~\cite{gapsys2020large}
\item Free energy calculations using QM/MM methods~\cite{beierlein2011simple,dybeck2016comparison,cave-ayland2015direct}.
\item Free energy calculations using machine learning methods~\cite{rufa2020chemical, scheen2020hybrid, cole2020machine}
\end{itemize}

For convenience we have also compiled a list of common acronyms and common symbols used throughout this paper.
\begin{tcolorbox}[title=Acronyms, colback=blue!10!white]
    {\bf CPU} --- Central Processing Unit\\
     {\bf BAR} --- Bennett Acceptance Ratio\\
     {\bf FEP} --- Free Energy Perturbation\\
     {\bf GPCR} --- G-Protein Coupled Receptor\\
     {\bf GPU} --- Graphics Processing Unit\\
     {\bf MBAR} --- Multistate Bennett Acceptance Ratio\\
     {\bf MCSS} --- Maximum Common Substructure\\
     {\bf MD} --- Molecular Dynamics\\
     {\bf RMSE} --- Root Mean Square Error\\
     {\bf MUE} --- Mean Unsigned Error\\
     {\bf SAR} --- Structure-Activity Relationships\\
     {\bf TI} --- Thermodynamic Integration
\end{tcolorbox}


\begin{tcolorbox}[title=List of Symbols, colback=green!10!white]
$L$ and $R$ --- generic names for ligand and receptor\\
$K_b^{\circ}$ --- binding  constant \\
$c^{\circ}$ --- standard state concentration \\
$U$ --- potential energy\\
$u$ --- reduced (dimensionless) potential describing a thermodynamic state \\
$G$ --- Gibbs free energy (free energy in the isothermal isobaric ensemble), Gibbs function, or free enthalpy, though the most common term Gibbs free energy is used in the text\\
$A$ --- Helmholtz free energy (free energy in the canonical ensemble) or Helmholtz function, with Helmholtz free energy used in the text.\\
$f$ --- reduced (dimensionless) free energy \\
$\Delta \hat{f}$ --- estimate from an estimator for the reduced free energy difference between two states\\
$\Gamma$ --- configurational space accessible by simulations \\
$\vec{q}$ --- vector of a single configuration, i.e. $x$, $y$, $z$ coordinates of the simulation system\\
$k_B$ --- Boltzmann constant \\
$Z$ --- partition function \\
$p$ --- pressure \\
$\mu$ --- chemical potential (grand canonical ensemble)\\
$T$ --- temperature \\
$\beta \equiv (k_B T)^{-1}$ --- inverse thermal energy \\
$\vec{\lambda}$ --- alchemical progress parameter, which may be multidimensional \\
$g$ --- statistical inefficiency\\
$\mathcal{O}$ --- overlap matrix\\
$C_t$ --- discrete-time-normalized fluctuation auto-correlation function\\
$\tau _{eq}$ --- integrated auto-correlation time\\
$t_0$ --- equilibration time
\end{tcolorbox}

%%%%%%%%%%%%%%%%%%%%
% Theory basics    %
%%%%%%%%%%%%%%%%%%%%
\section{\tocgreen{Statistical mechanics demonstrates why alchemical free energy calculations work}}
%\section{\tocorange{Statistical mechanics theory of solvation, solvent partitioning, and binding}}
\label{sec:theory}


In this section, we use a statistical mechanics theory of dilute solutions to derive free energy expressions that form the basis of alchemical computational protocols to model non-covalent molecular binding, solvation, and solvent partitioning equilibria. The emphasis here is placed on bridging theoretical foundations and intuition. Since chemical equilibria are regulated by the chemical potentials of the species involved, we will start by considering a statistical mechanics expression of the chemical potential of a solute in a solvent. We will then combine chemical potentials to develop models for each process.

\subsection{The chemical potential}

The chemical potential of a solute $u$ in an ideally diluted solution in a solvent $v$ can be written as~\cite{guggenheim1952mixtures504,gilson1997statisticalthermodynamic,gilson2007calculation}
\begin{equation}
  \mu_u = -k_B T \ln \frac{q'_u}{C_u \Lambda_u^3}
  \label{eq:chemical-potential-definition}
\end{equation}
where $k_B$ is Boltzmann's constant, $T$ is the absolute temperature, $C_u = N_u/V$ is the number concentration of the solute, $\Lambda_u = h/\sqrt{2 \pi M_u k_B T}$ is the thermal De-Broglie wavelength of the solute, where $h$ is Planck's constant and $M_u$ is the solute's total mass. The quantity $q'_u$ in Eq.~(\ref{eq:chemical-potential-definition}) is the molecular partition function of the solute at rest in the solvent
\begin{equation}
  q'_u = \frac{\Lambda_u^3}{\prod_i \lambda_i^3} 8 \pi^2 z_u
  \label{eq:intra-qpu-def}
\end{equation}
where $\beta = 1/(k_B T)$, $\lambda_i$ is the thermal De Broglie wavelength of the $i$-th atom of the solute, and $z_u$ is the intramolecular configurational partition function of the solute
\begin{equation}
  z_u = \int dx_u e^{-\beta \Psi_v(x_u)}
  \label{eq:intra-zu-def}
\end{equation}
where $x_u$ represents the collection of internal degrees of freedom of the solute (bond lengths, bond angles, and dihedral angles) with the corresponding volume element $dx_u$ assumed to include the appropriate Jacobian factors. The function $\Psi_v(x_u)$ in Eq.~\ref{eq:intra-zu-def} is the solvent-averaged potential of mean force of the solute in conformation $x_u$ in solvent $v$\cite{rouxandsimonson1999solventmodels} 
\begin{equation}
  e^{-\beta \Psi_v(x_u)} = \frac{1}{Z_{N_v}} \int d\vec{r}_v e^{-\beta U(x_u, \vec{r}_v)}
  \label{eq:solvent-pmf-def}
\end{equation}
where $\vec{r}_v$ represents the collection of Cartesian coordinates of the atoms of $N_v$ solvent molecules, $U(x_u, \vec{r}_v)$ is the potential energy of the solvent with one solute molecule in conformation $x_u$ placed in an arbitrary position in a volume $V$. When the potential energy function of the solution is separable into an intramolecular potential energy of the solute $U(x_u)$ and a solute-solvent non-bonded interaction energy, the potential of mean force can be written as the sum $\Psi_u(x_u) = U(x_u) + W_v(x_u)$ where $W_u(x_u)$ is the solvent potential of mean force, the solvation free energy of the solute fixed in configuration $x_u$.\cite{gilson2007calculation} However, the potential of mean force definition Eq.~(\ref{eq:solvent-pmf-def}) is valid in general. Finally, $Z_{N_v}$ is the configurational partition function of the pure solvent
\begin{equation}
  Z_{N_v} = \int d\vec{r}_v e^{-\beta U(\vec{r}_v)} \, .
  \label{eq:Z-pure-solvent}
\end{equation}


A few notes are in order. First, Eq.~(\ref{eq:chemical-potential-definition}) is derived using classical statistical mechanics theory.~\cite{hill1986statthermo} Classical mechanics is considered an excellent approximation for the room temperature processes studied here involving only changes in intermolecular interactions. A quantum mechanical treatment is necessary for processes not covered here, such as covalent binding, that involve breaking and forming chemical bonds. Classically, equilibrium thermodynamics properties, such as gas solubilities and binding constants, do not depend on atomic masses. Hence, while they are included in Eqs.~\ref{eq:chemical-potential-definition} and Eq.~\ref{eq:intra-qpu-def} for completeness, the thermal De Broglie wavelength terms coming from the partition functions of the momenta cancel in the resulting expressions below and we will no longer consider them.

Eq.~(\ref{eq:chemical-potential-definition}) is derived by writing the classical canonical configurational partition function $Z(N_u = 1, N_v)$ of one solute molecule in a solvent of $N_v$ molecules in a volume $V$ and multiplying and dividing it by configurational partition function of the pure solvent [Eq.~(\ref{eq:Z-pure-solvent})], and separating out the integration over the external degrees of freedom of the solute (translations and rotations) giving an $8 \pi^2 V$ term to yield $Z(N_u = 1, N_v) = Z_{N_v} 8 \pi^2 V z_u$ where $z_u$ is defined by Eqs.~(\ref{eq:intra-zu-def}) and (\ref{eq:solvent-pmf-def}). The canonical configurational partition function of $N_u$ independent solute molecules in a solvent is then obtained by considering the product of the solute terms $Z(N_u, N_v) = Z_{N_v} (8 \pi^2 V z_u)^{N_u}/N_u!$,~\cite{guggenheim1952mixtures504,simonson2016physical} where the factorial term takes care of indistinguishability. Finally, the canonical partition function $Q(N_u, N_v)$ of the solution is obtained by including the appropriate terms coming from the momenta and differentiating the resulting Helmholtz free energy $A(N_u, N_v) = -k_B T \ln Q(N_u, Nv)$ with respect to $N_u$ to obtain Eq.~(\ref{eq:chemical-potential-definition}).

The form Eq.~(\ref{eq:chemical-potential-definition}) for the solute chemical potential using the potential of mean force description is useful, as we will see, because it separates the solute's translational motion, which leads to the concentration dependence, from the intramolecular contributions. The potential of mean force description does not introduce approximations. With the exception of the use of classical statistical mechanics and the assumption of sufficient dilution so that the solute molecules can be considered independent, Eq.~(\ref{eq:chemical-potential-definition}) is rigorous. Due to rotation-vibration couplings, the separation of the solute's overall rotational motion leading to the $8 \pi^2$ term in Eq.~(\ref{eq:intra-qpu-def}) is not exact. However, it is not a strict requirement and the theory can be developed without it. The separation of rotational degrees of freedom is considered an excellent approximation at room temperature and a useful simplification, so it is adopted here.

We derived Eq.~(\ref{eq:chemical-potential-definition}) using the canonical (constant volume) partition function of the solution. Since the chemical potential can be equivalently obtained from the constant-volume differentiation of the Helmholtz free energy or the constant-pressure differentiation of the Gibbs free energy, Eq.~(\ref{eq:chemical-potential-definition}) is correct. However, the volume dependence of the chemical potential has to be considered when modeling the Gibbs free energy change for constant-pressure processes where the system's volume changes significantly.~\cite{gilson1997statisticalthermodynamic} Terms due to volume variations are generally considered small for most processes of solvation, solvent partitioning, and molecular binding at atmospheric pressure and are often ignored in alchemical calculations. Hence, we will use Eq.~(\ref{eq:chemical-potential-definition}) to derive expressions for $\Delta G$'s.

The standard chemical potential of a solute in an ideally dilute solution is obtained from Eq.~(\ref{eq:chemical-potential-definition}) by setting the concentration to the standard concentration $C^\circ$, generally $1$ mol/L equivalent to $1/1,661$ particles/\AA$^{3}$, 
\begin{equation}
  \mu_u^\circ = -k_B T \ln \frac{q'_u}{C^\circ \Lambda_u^3} \, .
  \label{eq:chemical-potential-standard}
\end{equation}
The standard state state of a dilute solution is defined as an ideally dilute solution at concentration $C^\circ$.~\cite{levine2009physicalchemistrybook6ed} Hence, Eq.~(\ref{eq:chemical-potential-standard}) is formally correct for real solutions as well.

\subsection{Solvation}\label{sec:theory-solvation}

The standard molar Gibbs free energy of the solvation of a gas species $A$ in a solvent $v$
\begin{equation}
A(\mathrm{g})  \leftrightharpoons A(v)
\end{equation}
is
\begin{equation}
  \Delta G^\circ_{\mathrm{slv}} = \mu^\circ_{A(v)}  - \mu^\circ_{A(g)} = -k_B T \ln \frac{P^\circ}{C^\circ k_B T} - k_B T \ln \frac{z_{A(v)}}{z_{A(\mathrm{g})}}
  \label{eq:DG0-solvation-def}
\end{equation}
where we used Eq.~(\ref{eq:chemical-potential-standard}) for the solution and  Eq.~(\ref{eq:chemical-potential-definition}) for the gas (assumed ideal) at the standard gas concentration $C = P^\circ/k_B T$ where $P^\circ = 1$ bar is the standard pressure, and Eq.~(\ref{eq:intra-qpu-def}) noting that all momentum terms cancel. The first term in Eq.~(\ref{eq:DG0-solvation-def}) is an ideal term $\Delta G^\circ_{\mathrm{slv,ideal}}$ that accounts for the difference of standard states for solution and gases. The second term is the excess solvation free energy $\Delta G_{\mathrm{slv, exc.}}$ that can be evaluated by numerical alchemical calculations (see below). Hence Eq.~(\ref{eq:chemical-potential-standard}) can be used to compare calculated and experimental standard free energies of solvation.

However, equilibrium experimental gas solvation data is most often available in terms of Henry's constants $k_H$. Setting $\Delta G_{\mathrm{slv}} = 0$ when the gas partial pressure and the solute's concentrations are equal to their equilibrium values $P_A$ and $C_A$, respectively, we obtain
\begin{equation}
  P_A = k_H C_A
  \label{eq:Henrys-law}
\end{equation}
where
\begin{equation}
  k_H = k_B T \frac{z_{A(\mathrm{g})}}{z_{A(v)}} \, .
  \label{eq:Henrys-constant}
\end{equation}
The relation above is used to connect alchemical calculations to Henry's constant values, often after converting them to the excess free energy scale~\cite{nicholls2008predicting,mobley2014freesolv}
\begin{equation}
\Delta G_{\mathrm{slv, exc.}} = - k_B T \ln \frac{z_{A(v)}}{z_{A(\mathrm{g})}} = k_B T \ln \frac{k_H}{k_B T} \, .
\label{eq:DG-solvation-excess}
\end{equation}
Because it involves only intramolecular partition functions, Eq.~(\ref{eq:DG-solvation-excess}) states that the excess free energy of solvation corresponds to the process of moving the solute from a fixed position and orientation in the gas to a fixed position and orientation in the solvent. This is sometimes referred to as the solvation free energy in the Ben-Naim standard state.~\cite{bennaim1984solvation}

The next step is to express the ratio of intramolecular configurational partition functions in Eq.~(\ref{eq:DG-solvation-excess}) in an ensemble average form amenable to calculation by computer simulation. First, the potential of mean force in $z_{A(v)}$ [Eq.~(\ref{eq:intra-zu-def})] is replaced with its definition from Eq.~(\ref{eq:solvent-pmf-def}) to explicitly expose the coordinates of the solvent:
\begin{equation}
  \frac{z_{A(v)}}{z_{A(\mathrm{g})}} =
  \frac{
    \int dx_A d\vec{r}_v e^{-\beta U(x_A, \vec{r}_v)}
  }{
    \int dx_A d\vec{r}_v e^{-\beta [U(\vec{r}_v) + U(x_A)] }
  }
\end{equation}
where the integral $Z_{N_v}$ for the pure solvent from Eq.~(\ref{eq:Z-pure-solvent}) has been combined in the denominator with the integral $z_{A(\mathrm{g})}$ of the solute in the gas phase to obtain the configurational partition function of an artificial system where the solute is in the solvent but it is decoupled from it (note the absence of coupling terms between the degrees of freedom of the solvent and those of the solute).

Next, we multiply and divide by the integral $\int d\zeta$ of the six external degrees of freedom of the solute (the center of mass position and the orientation angles). These degrees of freedom, together with the internal degrees of freedom $x_A$, allow the recast the integrals in terms of the Cartesian coordinates $\vec{r}_A$ of the $n_A$ solute's atoms which are typically used in computer simulations, without restraining the position and orientation of the solute. Finally, we multiply and divide the integrand in the numerator by the integrand in the denominator to obtain
\begin{equation}
  \frac{z_{A(v)}}{z_{A(\mathrm{g})}} =
  \frac{
    \int d\vec{r}_A  d\vec{r}_v  e^{-\beta \{ U(\vec{r}_A, \vec{r}_v) -  [ U(\vec{r}_v) + U(\vec{r}_A) ] \}} e^{-\beta [U(\vec{r}_v) + U(  \vec{r}_A  )] } 
  }{
    \int d\vec{r}_A d\vec{r}_v e^{-\beta [U(\vec{r}_v) + U( \vec{r}_A  )] } 
  } = \langle e^{-\beta \Delta U} \rangle_0
  \label{eq:zratio-solv-average}
\end{equation}
where $\langle \ldots \rangle_0$ is an average in the decoupled ensemble and $\Delta U =  U(\vec{r}_A , \vec{r}_v) -  [ U(\vec{r}_v) + U(\vec{r}_A ) ]$ the change in the system's potential energy for coupling the solute to the solvent. Equivalently, we can consider the reciprocal of Eq.~(\ref{eq:zratio-solv-average}) and express it in terms of an ensemble average $\langle \ldots \rangle_1$ in the coupled ensemble:
\begin{equation}
  \frac{z_{A(v)}}{z_{A(\mathrm{g})}} = \frac{1}{\langle e^{\beta \Delta U} \rangle_1}
\end{equation}
where $-\Delta U = [ U(\vec{r}_v) + U(\vec{r}_A ) ] - U(\vec{r}_A , \vec{r}_v)$ is a decoupling energy.

Combining Eqs.~(\ref{eq:DG-solvation-excess}) and (\ref{eq:zratio-solv-average}) yields\cite{widom1982potential} 
\begin{equation}
  \Delta G_{\mathrm{slv, exc.}} = - k_B T \ln \langle e^{-\beta \Delta U} \rangle_0 = k_B T \ln \langle e^{\beta \Delta U} \rangle_1
  \label{eq:zratio-solv-dgexc}
\end{equation}
The objective of alchemical solvation free energy calculations is to evaluate Eq.~(\ref{eq:zratio-solv-dgexc}), by means of \emph{coupling} or \emph{decoupling} protocols.
  
\subsection{Solvent partitioning}\label{sec:theory-partitioning}

The standard molar Gibbs free energy of transfer of a solute species $A$ from a  solvent $s$ to a solvent $v$
\begin{equation}
A(s)  \leftrightharpoons A(v)
\end{equation}
is
\begin{equation}
  \Delta G^\circ_{\mathrm{part}} = -k_B T \ln P_{sv} = \mu^\circ_{A(v)}  - \mu^\circ_{A(s)} = -k_B T \ln \frac{z_{A(v)}}{z_{A(s)}}
  \label{eq:DG0-partitioning-def}
\end{equation}
where $P_{sv} = C_{A(v)}/C_{A(s)}$ is the partition coefficient of $A$ for the two solvents.~\cite{rustenburg2016measuring} Eq.~(\ref{eq:DG0-partitioning-def}) 
immediately identifies the partition coefficient with the ratio of intramolecular configurational partition functions of $A$ in the two solvents:
\begin{equation}
  P_{sv} = \frac{z_{A(v)}}{z_{A(s)}} \, .
  \label{eq:partition-coefficient}
\end{equation}
This relation connects calculated ratios of partition functions to experimental partition coefficients. Similarly to Eq.~(\ref{eq:DG-solvation-excess}), Eq.~(\ref{eq:partition-coefficient}) corresponds to the process of transferring the solute from a fixed position and orientation in one solvent to a fixed position and orientation in the other.

The ratio of partition functions in Eq.~(\ref{eq:partition-coefficient}) can be treated in the same way as Eq.~(\ref{eq:zratio-solv-average}) to express it as the ensemble average in solvent $s$ of the change in potential energy $\Delta U$ for moving the solute to the other solvent $v$. However, in practice it has been more common to evaluate Eq.~(\ref{eq:DG0-partitioning-def}) as the difference of excess solvation free energies in the two solvents separately evaluated using Eq.~(\ref{eq:zratio-solv-dgexc}).~\cite{bosisio2016blinded} Formally, this approach is derived by multiplying and dividing Eq~(\ref{eq:partition-coefficient}) by $z_{A(\mathrm{g})}$ and expressing each terms as an ensemble average in the decoupled ensemble
\begin{equation}
  P_{sv} = \frac{z_{A(v)}}{z_{A(\mathrm{g})}}  \frac{z_{A(\mathrm{g})}}{z_{A(s)}} = \frac{\langle e^{-\beta \Delta U_{(v)}} \rangle_0}{\langle e^{-\beta \Delta U_{(s)} } \rangle_0 }
  \label{eq:partition-coefficient-coupling}
\end{equation}
where $\Delta U_{(v)}$ and $\Delta U_{(s)}$ are the solute's coupling energies to solvent $v$ and $s$, respectively. 
The implementation of Eq.~(\ref{eq:partition-coefficient-coupling}) in terms of decoupling
\begin{equation}
P_{sv} = \frac{\langle e^{\beta \Delta U_{(s)}} \rangle_1}{\langle e^{\beta \Delta U_{(v)} } \rangle_1 }
\label{eq:partition-coefficient-decoupling}
\end{equation}
is an example of a \emph{double-decoupling} alchemical computational protocol.~\cite{hermans1986freeenergy,gilson1997statisticalthermodynamic}

\subsection{Non-covalent molecular binding}
\label{sec:non-covalent-molecular-binding}

The standard Gibbs free energy of binding between a receptor $R$ and a ligand $L$ to form a complex $RL$ in a solvent $v$
\begin{equation}
  R(v) + L(v)  \leftrightharpoons RL(v)
  \label{eq:binding-reaction}
\end{equation}
is
\begin{equation}
  \Delta G^\circ_{b} = \mu^\circ_{RL(v)}  - \mu^\circ_{R(v)} - \mu^\circ_{L(v)} = -k_B T \ln Kb 
  \label{eq:DG0-binding-def}
\end{equation}
where~\cite{gilson1997statisticalthermodynamic,gilson2007calculation}
\begin{equation}
  Kb = \frac{C^\circ}{8 \pi^2} \frac{z_{RL(v)}}{z_{R(v)} z_{L(v)}}
  \label{eq:DG0-binding-constant-def}
\end{equation}
is the statistical mechanics expression for the binding constant. Eq.~(\ref{eq:DG0-binding-constant-def}) follows from the application of  Eq.~(\ref{eq:chemical-potential-standard}) for each of the three species and noting that the contributions of the momenta cancel. As discussed below, various alchemical protocols exist to evaluate the ratios of partition functions in Eq.~(\ref{eq:DG0-binding-constant-def}), providing a connection between the theory and observed binding affinities.

Eq.~(\ref{eq:intra-zu-def}) describes the intramolecular configurational partition functions $z_{R(v)}$ and $z_{L(v)}$ for the receptor $R$ and ligand $L$. The intramolecular configurational partition function $z_{RL(v)}$ of the complex is similar but the integration is limited to a chosen range of configurations in which receptor and ligand are considered ``bound''. To this end, Gilson et al.~\cite{gilson1997statisticalthermodynamic} introduced an indicator function $I(\zeta)$ equal to one when the six degrees of freedom of the complex that defines the position and orientation of the ligand relative to the receptor, collectively denoted as $\zeta$, are within the specified range of the bound state and equal to zero otherwise:
\begin{equation}
  z_{RL(v)} = \int dx_R dx_L d\zeta I(\zeta) e^{-\beta \Psi_v(x_R, x_L, \zeta)} \, .
  \label{eq:intra-zRL-def}
\end{equation}

The definition of the bound macrostate of the complex is an essential input of the theory. Unlike bond lengths, bond angles, and dihedral angles, the three degrees of freedom of the complex that correspond to the position of the ligand relative to the receptor are unbounded. Unless their extent is limited in some fashion, the bound state of the complex cannot be distinguished from the unbound state, and their free energy difference will be undefined. For example, it is reasonable to insist that the ligand be close to the receptor in configurations regarded as bound. The definition of the target macrostates is a requirement in many areas of computational chemistry and biophysics, such as when specifying the range of backbone angles to measure the relative population of $\alpha$-helical and $\beta$-strand conformations of peptides.  

Conversely, the value of the binding free energy depends on the chosen structural definition of the bound complex. The relationship between the predictions of this theory and experimental reporters (thermochemical, spectroscopic, inhibition kinetics, and others) of complex formation has been discussed.\cite{gilson1997statisticalthermodynamic,mihailescu2004theory,gallicchio2011recentadv,simonson2016physical,gallicchio2021comppeptsci} The interpretation of experimental reporters of binding is a complex issue in itself. Still, the consensus is that this theory gives nearly equivalent results when the binding is strong and specific, and the definition of the bound complex covers the major bound poses while excluding obvious unbound configurations. In some cases it is valuable to consider specific definitions of the complex by, for example, restricting the orientation of the ligand to pinpoint the relative contribution of different binding poses.

Eq.~(\ref{eq:DG0-binding-constant-def}) is the basis of a variety of alchemical computational implementations discussed in the following sections that have have been developed to study molecular binding by alchemical means.

\subsection{Simulating binding events is computationally expensive}

The appeal of alchemical approaches to study binding can be best appreciated by considering the alternative of evaluating the binding constant directly from the law of mass action definition
\begin{equation}\label{eq:law-mass-action}
 K_b = C^{\circ}\frac{[RL]}{[L][R]},
\end{equation}
where $[RL]$, $[L]$, and $[R]$ are the equilibrium concentrations of complex, ligand, and receptor, respectively, by, for example, monitoring the relative population $P(RL)/P(R+L)$ of bound and unbound configurations in molecular dynamics simulations.~\cite{jong2011determining,pan2017quantitative}

The computational protocol based on this idea can be formally derived from Eq.~(\ref{eq:DG0-binding-constant-def}) by multiplying and dividing it by
\begin{equation}
z_v = \int dx_R dx_L d\zeta e^{-\beta \Psi_v(x_R, x_L, \zeta)}
\end{equation}
that, because, unlike Eq.~(\ref{eq:intra-zRL-def}), the position of the ligand is not limited by the indicator function, corresponds to a system in which the ligand $L$ is freely moving in a box of solvent of volume $V$ containing the receptor $R$. The ratio between $z_{RL(v)}$ and $z_v$ is the ensemble average of $I(\zeta)$ or the probability $P(RL)$ that $L$ is in the binding site of the receptor $R$. To measure the probability $P(R+L)$ of the $R+L$ unbound state, we consider an indicator function $I_{\mathrm{out}}(\zeta)$ which is one when the ligand, as measured from the center of mass position for example, is far away from the receptor. The volume of the far away region is
\begin{equation}
8 \pi^2 V_{\mathrm{out}} = \int d\zeta I_{\mathrm{out}}(\zeta)
\end{equation}
where the $8 \pi^2$ term comes from the integration of the ligand's orientations not limited by $I_{\mathrm{out}}(\zeta)$. Next, multiply the ratio $z_{R(v)} z_{L(v)}/z_v$ by $\int d\zeta I_{\mathrm{out}}(\zeta)$ and divide it by $8 \pi^2 V_{\mathrm{out}}$ yielding
\begin{equation}
K_b = C^\circ V_{\mathrm{out}} \frac{P(RL)}{P(R+L)}
\end{equation}
where we have used the identity
\begin{equation}
P(R+L) = \langle I_{\mathrm{out}}(\zeta) \rangle_v = \frac{\int dx_R dx_L d\zeta I_{\mathrm{out}}(\zeta) e^{-\beta \Psi_v(x_R, x_L, \zeta)}}{\int dx_R dx_L d\zeta e^{-\beta \Psi_v(x_R, x_L, \zeta)}} \, .
\end{equation}

While simulating explicit binding events has been used to estimate binding constants~\cite{jong2011determining,pan2017quantitative} or to get insights into the binding pathways and kinetics of receptor-ligand systems~\cite{teo2016adaptive,votapka2017seekr,doerr2014onthefly,plattner2015protein,dixon2018predicting}, the computational cost of these calculations is usually dominated by the rate of dissociation, which can be on the microsecond timescale even for millimolar binders~\cite{pan2017quantitative} and reaches the microsecond to second timescale for a typical drug~\cite{basavapathruni2012conformational,hyre2006cooperative}.
Depending on system size and simulation settings, common molecular dynamics software packages can reach a few hundreds of ns/day using currently available high-end GPUs~\cite{eastman2017openmm,kutzner2019more}, making these type of calculations unappealing and irrelevant on a pharmaceutical drug discovery timescale.
Other methods compute the free energy of binding by building potential of mean force profiles along a reaction coordinate~\cite{woo2005calculation,velez-vega2013overcoming,limongelli2013funnel,heinzelmann2017attachpullrelease}, but these methods require prior knowledge of a high-probability binding pathway, which is not easily available, especially in the prospective scenarios typical of the drug development process.

Similarly, because of the long time-scale of transition events and the need to observe many events to extract probabilities, it would be very difficult to estimate solvation free energies and solvent partition coefficients by simulating explicitly the motion of solutes in and out of solutions.

\subsection{Alchemical free energy calculations yield predictions that do not require direct simulation of binding/unbinding events}

In many cases, the quantity of interest is the change in binding affinity between a compound $A$ and a related compound $B$ (e.g., by modifying one of the drug scaffold's substituents, see (Fig.~\ref{fig:fig_what_is_alchemy}\textbf{E})), which, by using Eq.~\ref{eq:binding-free-energy-from-bound-unbound-probability-ratio} and \ref{eq:bound-unbound-probability-ratio} is given by
\begin{equation}\label{eq:delta-delta-G-physical}
\begin{split}
    \Delta \Delta G_{\mathrm{bind}, AB} &= \Delta G_{\mathrm{bind}, B} - \Delta G_{\mathrm{bind}, A} \\
    &\approx -k_BT \left( \ln \frac{Z(RB)}{Z(R+B)} - \ln \frac{Z(RA)}{Z(R+A)} \right) \, .
\end{split}
\end{equation}
Note that the terms involving the standard concentration cancel out when we assume that the volume is identical for $A$ and $B$.
Predictions of $\Delta \Delta G_{\mathrm{bind}, AB}$ with non-alchemical methods generally require long simulations of both ligands, possibly through different binding pathways.
Alchemical relative free energy calculations avoid the need to simulate binding and unbinding events by making use of the fact that the free energy is a state function and exploiting the thermodynamic cycle illustrated in Fig.~\ref{fig:fig_binding_thermodynamic_cycle}.
This is apparent after rewriting Eq.~\ref{eq:delta-delta-G-physical} as
\begin{equation}\label{eq:delta-delta-G-alchemical}
\begin{split}
    \Delta \Delta G_{\mathrm{bind}, AB} &\approx -k_BT \left( \ln \frac{Z(RB)}{Z(RA)} - \ln \frac{Z(R+B)}{Z(R+A)} \right) \\
    &= -k_BT \left( \ln \frac{Z(RB)}{Z(RA)} - \ln \frac{Z(B)}{Z(A)} \right) \\
    &= \Delta G_{\mathrm{bound}} - \Delta G_{\mathrm{unbound}} \, ,
\end{split}
\end{equation}
where $\Delta G_{\mathrm{bound/unbound}}$ is the free energy of mutating $A$ to $B$ in the bound/unbound state.
Eq.~\ref{eq:delta-delta-G-alchemical} and Fig.~\ref{fig:fig_binding_thermodynamic_cycle} tell us that the difference in free energy of binding between toluene ($A$) and benzyl alcohol ($B$) can be computed by running two independent calculations estimating the free energy cost of mutating $A$ into $B$ in the binding pocket ($\Delta G_{\mathrm{bound}}$) and in solvent ($\Delta G_{\mathrm{unbound}}$), saving us the need to simulate the physical binding process of the two compounds.
In particular, the second line of Eq.~\ref{eq:delta-delta-G-alchemical} is a consequence of $\Delta G_{\mathrm{unbound}}$ being independent of the presence of the receptor in the simulation box as the definition of the unbound state assumes receptor and ligand to be at a sufficient distance for them to have no energetic interactions.
Note that, when $A$ and $B$ have a different number of atoms, the factors $ \ln \frac{Z(RB)}{Z(RA)}$ and $\ln \frac{Z(B)}{Z(A)}$ in   Eq.~\ref{eq:delta-delta-G-alchemical} appear both to have factors with units of volume in the logarithms, but these factors exactly cancel between the terms.

\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/fig2_therm_cyc/Figure.pdf}
    \caption{{\bf Thermodynamic cycle for computing the relative free energy of binding ($\Delta \Delta G$) between two related small molecules to a supramolecular host or a rigid receptor.}
    The relative binding free energy difference between two small molecules, $\Delta \Delta G_{\mathrm{bind}, A \rightarrow B} \equiv \Delta G_{\mathrm{bind}, B} - \Delta G_{\mathrm{bind}, A}$---here benzyl alcohol (top) to toluene (bottom)---can be computed as a difference between two alchemical transformations, $\Delta G_\mathrm{bound} - \Delta G_\mathrm{solvated}$, where $\Delta G_\mathrm{bound}$ represents the free energy change of transforming $A \rightarrow B$ in complex, i.e. bound to a host molecule, and $\Delta G_\mathrm{unbound}$ the free energy change of transforming $A \rightarrow B$ in solvent, typically water.}
    \label{fig:fig_binding_thermodynamic_cycle}
\end{figure}

\paragraph{How are alchemical transformations performed in practice?}

In practice, the mutation of $A$ to $B$ is carried out by introducing one or more parameters $\vec{\lambda}$ controlling the potential energy function $U(\vec{q};\vec{\lambda})$ such that the potential of compounds $A$ and $B$ is recovered at two particular values $\vec{\lambda}_A$ and $\vec{\lambda}_B$.
Briefly, this is achieved by simulating a ``chimeric'' molecule composed of enough atoms to represent both $A$ and $B$.
A subset of the energetic terms in $U(\vec{q};\vec{\lambda})$ is then modulated by $\vec{\lambda}$ so that at $\vec{\lambda}_A$, the atoms that form molecule $A$ are activated and those belonging exclusively to $B$ are non-interacting ``dummy atoms'', while the opposite occurs at $\vec{\lambda}_B$ (see Sec.~\ref{sec:relative-fe-protocol} for details).

We can rigorously account for fluctuations in other thermodynamic parameters such as changes in volume $V$ when simulating at constant pressure $p$ or changes in number of molecules $N_i$ of species $i$ at constant chemical potential $\mu_i$ (e.g., number of waters or ions) by introducing the \textit{reduced potential}~\cite{shirts2008statisticallya}
\begin{equation}\label{eq:reduced-potential}
u(\vec{q};\vec{\lambda}) \equiv \beta \left[ U(\vec{q};\vec{\lambda}) + p \, V(\vec{q}) + \sum_i \mu_i \, N_i(\vec{q}) + \cdots \right] \, .
\end{equation}
Here, the collection of thermodynamic and alchemical parameters $\{\beta, \vec{\lambda}, p, \mu, \ldots\}$ defines a \emph{thermodynamic state}.
In the context of alchemical calculations, in which the thermodynamic states vary only in their value of $\vec{\lambda}$, these are also referred to as \emph{alchemical states}.
The free energy of mutating $A$ to $B$ in any environment ($\Delta G_{\mathrm{env}}$ e.g., binding site, solvent) can then be computed as
\begin{equation}\label{eq:delta-G-env}
    \Delta G_{\mathrm{env}} = - k_BT \ln \frac{Z(\vec{\lambda}_B)}{Z(\vec{\lambda}_A)} = - k_BT \ln \frac{\int_{\Gamma_{\mathrm{env}}} \exp\left( u(\vec{q}; \vec{\lambda}_B) \right) \, d\vec{q}}{\int_{\Gamma_{\mathrm{env}}} \exp\left( u(\vec{q}; \vec{\lambda}_A) \right) \, d\vec{q}} \, ,
\end{equation}
over the configurational space of the environment ($\Gamma_{\mathrm{env}}$).
While it is generally not feasible to compute the two partition functions $Z(\vec{\lambda})$, several estimators have been devised to robustly estimate the ratio of partition functions in Eq.~\ref{eq:delta-G-env} (see Sec.~\ref{subsec:estimators}) from a set of configurations usually collected with MD simulations from the thermodynamic states defined at $\vec{\lambda}_A$ and $\vec{\lambda}_B$ and intermediates thereof.

\paragraph{Why do alchemical calculations need unphysical intermediate states?}
While it is theoretically possible to estimate the ratio of partition functions from samples collected only at states $\vec{\lambda}_A$ and $\vec{\lambda}_B$, the efficiency of the free energy estimators rapidly decreases as the phase-space overlap between the two states also decreases~\cite{wu2005phasespace, wu2005phasespacea}.
Roughly, the phase-space overlap between two thermodynamic states measures the degree to which high-probability configurations (i.e., those with very negative potential energy) in one state are also high-probability configurations in the other state (see Sec.~\ref{sec:are-they-good} and Fig.~\ref{fig:fig_what_is_lambda}).

Equilibrium free energy calculations, our focus here, solve the problem of having poor overlap between the states of interest by introducing multiple intermediate alchemical states at values $\vec{\lambda}_A = \vec{\lambda}_0, \vec{\lambda}_1, \cdots, \vec{\lambda}_K = \vec{\lambda}_B$ so that each pair of consecutive states $\vec{\lambda}_k, \vec{\lambda}_{k+1}$ share good overlap.
Each intermediate state models a ligand that is neither $A$ nor $B$ but a interpolation of the two.
Many estimators (e.g., exponential reweighting (EXP)~\cite{zwanzig1954hightemperature} and Bennett's acceptance ratio (BAR)~\cite{bennett1976efficient,shirts2003equilibrium}) can then be used to compute the free energy as
\begin{equation}
    \Delta G_{\mathrm{env}} = k_BT \sum_{k=0}^{K-1} \Delta f(\vec{\lambda}_k, \vec{\lambda}_{k+1}),
\end{equation}
from samples collected at all the alchemical states $\{\vec{\lambda}_k \}$, where $\Delta f$ is the \emph{unitless free energy difference}
\begin{equation}
    \Delta f(\vec{\lambda}_k, \vec{\lambda}_{k+1}) = f(\vec{\lambda}_{k+1}) - f(\vec{\lambda}_k) = - \ln \frac{Z(\vec{\lambda}_{k+1})}{Z(\vec{\lambda}_k)} \, .
\end{equation}
While this strategy usually results in sampling thermodynamic states whose Boltzmann distributions are very similar, thus collecting information that is to some degree redundant, some estimators, such as the Multistate Bennett acceptance ratio (MBAR)~\cite{shirts2008statisticallya}, can exploit similarities between states to improve the precision of the estimates. This is achieved by using the configurations sampled at all alchemical states $\{\vec{\lambda}_k \}$ to compute the free energy difference $\Delta f(\vec{\lambda}_i, \vec{\lambda}_{j})$ between any pair of states $i,j$ (see Sec.~\ref{subsec:estimators}).

Non-equilibrium free energy techniques provide an alternate approach to this problem, driving $\lambda$ between states, but these are not our focus here.~\cite{jarzynski1997nonequilibrium,jarzynski1998equilibrium,crooks2000pathensemble, gapsys2020large}

\paragraph{How do absolute free energy calculations differ from relative?}

While absolute and relative free energy calculations have subtle differences in their practical applications (e.g., use of restraints, handling of the standard state), the fundamental ideas and concepts of relative free energy approaches remain unaltered in other types of alchemical calculations.
Absolute binding, hydration, and partition free energies still use thermodynamic cycles that enable computing transfer free energies without actually simulating the physical transfer from one environment to another.

The main difference in these approaches lies instead in the thermodynamic cycle to which this strategy is applied.
For example, a typical thermodynamic cycle for an alchemical absolute binding free energy calculation is represented in Fig.~\ref{fig:fig_absolute_thermodynamic_cycle}.
In this case, two independent calculations compute the free energy of removing the interactions between the ligand and its environment in solvent or in the binding site respectively through a series of intermediate states in which the energy terms are only partially deactivated.




%%%%%%%%%%%%
% Step 0   %
%%%%%%%%%%%%
\section{\tocorange{What can be expected from alchemical simulations?}}
\tocsectioncomment{Steering Meeting: @Volunteer Shorten and move most material to second paper. Possibly add a walkthrough of a ``dummy calculation'' (which could be a particular realisation of a general workflow laid out in @Jenke Scheen's figure)? This could lead on to discussion of particular methods. @Toni Mey I could do this}
\label{sec:step0}
When starting an alchemical free energy project, a key first step is to decide whether free energy calculations are really the right tool. Particularly, count the cost of your
project: Can you even hope to tackle the problem with available resources and, if successful, will it
be worth it in terms of human and computational cost?

\subsection{How accurate are alchemical free energy calculations?}
\label{subsec:expectation}
We first note that the accuracy of any free energy calculation method will depend on the quality of the underlying force field.  Therefore, any description of the force field for the molecules under study must be carefully checked to be sufficiently accurate to experiment. In particular, one must make sure that if using automatically generated molecular descriptions from either one's own workflow or some other computational chemistry program, there are no obvious problems in these files either through errors in the workflow, or lack of chemical coverage in the data used to construct the molecular description. Torsional parameters, in particular can be misassigned or improperly parameterized. 

Alchemical free energy calculations involving small molecules seem to achieve, in favorable cases, root mean square (RMS) errors relative to experiment around 1-2 kcal/mol depending on force field, system, and a variety of other factors such as simulation time, sampling method, and whether the calculations employed are absolute or relative. A small selection of example datasets and case studies can be found in Sec.~\ref{sec:benchmark} at the end of this document.
However, the domain of applicability is a significant concern~\cite{sherborne2016collaborating, cournia2017relative}, especially for relative calculations, which typically require a high quality and usually experimental bound structure of a closely
related ligand as a starting point. Additional factors such as slow protein or ligand rearrangements, uncertainties in ligand binding mode, or charged ligands can make these calculations far less reliable and more of a research effort.


It is worth noting that the accuracy of free energy calculations is highly variable across different protein targets, and likely across different ligand chemotypes as well.
For instance, FEP+ with OPLS3 achieves an RMSE of 0.62 kcal/mol for a set of 21 compounds binding to JNK1 kinase, but an RMSE of 1.05 kcal/mol for a set of 34 compounds binding to P38$\alpha$ kinase~\cite{harder2016opls3}.
Furthermore, perturbations for the same chemotype in different pockets of the BACE enzyme gave varied errors~\cite{keranen2017acylguanidine}. Here the errors refer to the difference in $\Delta G$ derived from calculated $\Delta \Delta G$'s while fitting a constant offset to best reproduce the experimental binding free energies for known compounds~\cite{wang2015accurate}. Each $\Delta \Delta G$ is associated with a particular free energy calculation or transformation, which can be thought of as an edge in the graph spanning the compound series, see examples of such graphs in Fig.~\ref{fig:fig_types_of_networks}.

The fact that we can analyze both $\Delta G$ values and $\Delta \Delta G$ values raises an important question about analysis -- which calculated values should we assess? It is important to be clear on what error to report: $\Delta G$ after shifting by a constant to minimize the RMSE, unshifted $\Delta G$, $\Delta \Delta G$ of computed edges, or $\Delta \Delta G$ of all edges. (See recommendations for reporting best practices, Sec.~\ref{sec:plot_data}.) Additionally, as it is possible to perform calculations on a set of ligands using different pairwise comparisons of molecules, the performance of the method may be biased based on which pairs of comparisons are performed. Additionally, it is possible that the error associated with the relative free energy between a two ligands that was not directly computed,  but can be deduced using one or more thermodynamic paths involving other ligands will likely be more uncertain.
Given the need to understand the performance of the system with alchemical free energy calculations, we recommend that retrospective studies for a particular target and a particular chemical series be performed for each application case.

\subsection{How reproducible are alchemical free energy calculations?}
\label{subsec:reproducible}
We restrict our analysis here to repetitions of the same calculation performed with precisely the same force field, as different force fields used to describe the same molecule can lead to wide differences in free energies in some cases.  Even within this restriction,
finite computing resources necessarily limit the generated number of uncorrelated samples of potential energy surfaces, and therefore alchemical free energy calculations only give free energy estimates to within finite precision. An important consideration is how reproducible alchemical free energy calculations are in practice. In simple cases such as absolute hydration free energies of small organic molecules, or relative hydration free energy calculations between structurally similar small organic molecules, it should be possible to obtain highly precise estimates with a given software package, i.e.with a sample standard deviation under 0.01 kcal/mol~\cite{rizzi2019sampl6}.
For more complex use cases such as protein-ligand binding free energies the repeatability is often substantially worse~\cite{rizzi2019sampl6}. A good practice is to perform two or three runs of the same perturbation to assess precision with a given protocol, using different initial velocities. The sample standard deviation will give a crude estimate of the reliability of the estimates, and whether the precision is sufficient for the problem at hand. When practical, a more stringent test is to use different input coordinates for each repeat run as well as different velocities. 

Note that these types of statistical differences concern calculations carried out with a single software package, but simulation package variations can introduce additional discrepancies. Such issues of reproducibility of free energy calculations across different simulation packages have attracted attention recently~\cite{loeffler2018reproducibility,rizzi2019sampl6}. Greater variability is expected between packages due to methodological differences such as integrators, thermostats, barostats, treatment of long-range electrostatics, and potentially other factors. For absolute and relative hydration free energies of small organic molecules a variability of ca. 0.2 kcal/mol between popular simulation packages has been reported~\cite{loeffler2018reproducibility}. In the recent SAMPL6 SAMPLing challenge a larger variability of 0.3 to 1.0 kcal/mol was noted in the computed absolute binding free energies of host/guest systems even though the study sought to use identical input and simulation parameters~\cite{rizzi2019sampl6} and, in many cases, single-point energies were identical or nearly so. Further work is needed to ensure reproducibility of alchemical free energy calculations across different software implementations to guarantee that force-field development efforts lead to transferable potential energy functions. 

\subsection{Is my problem suitable for alchemical free energy calculations?}
\label{subsec:suitability}
Before even planning free energy calculations to study binding to a
particular target, it is important to assess what is known about the
system and its timescales and its suitability for free energy
calculations, as well as the \emph{purpose} of the calculations and
the amount of available computer resources. In some cases, predicting accurate binding free energies for a particular target might be
\emph{more} challenging than simply measuring them! This is
often the case when dealing with database screening problems, where
compounds might be easily and quickly available commercially for
testing and free energy calculations could consume far more resources. Free energy calculations thus typically only
appeal when (slow or costly) synthesis would be required or experiments are otherwise cost-prohibitive.

Sometimes, however, free energy calculations can provide answers that are not
readily available from experiments. For example, type II kinase
inhibitors selectively bind to different kinases in the so-called
DFG-out conformations~\cite{schindler2000structural}. The selectivity of such
inhibitors may be attributed either to their differential binding to
different kinases in the DFG-out conformations, or to different
stability of the DFG-out conformations of different kinases. 

Let
$K_C$ be the equilibrium constant between DFG-in and DFG-out
conformations of one kinase, and $K_D^\ast$ be the dissociation
constant of a type II inhibitor against this kinase, the apparent
binding constant of this inhibitor against this kinase is then
\begin{equation}
  K_D = K_D^\ast \frac{1 + K_C}{K_C}
  \label{eqn:conformational-binding}
\end{equation}

Since binding experiments cannot resolve $K_D^\ast$ and $K_C$ individually, such experiments cannot address the basis of selectivity of the type II inhibitors. Absolute binding free energy calculations, in contrast, can take advantage of the slow kinetics of DFG-in/out conversion, and estimate the conformation-specific binding constant $K_D^\ast$, thus yielding clues as to the source of selectivity.

%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Simulation prerequisites  %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
\section{\tocorange{Simulation prerequisites}}
\tocsectioncomment{There was substantial interest in expanding this section (see initial suggestions/ discussion).}
\tocsectioncomment{@Irfan Alibay/ @Volunteer to suggest additional points.}
\tocsectioncomment{@Irfan Alibay/ @Emilio Gallicchio/ @Volunteer to expand on approaches for explicitly accounting for protonation/ tautomer changes.}
\tocsectioncomment{@Hannah Bruce Macdonald/ @David Slochower/ @Vytas Gapsys/ @Volunteer to expand range of systems discussed, e.g. membrane proteins, cofactors, multimers, PPIs.}
\label{sec:prerequisites}
Alchemical free energy protocols as discussed below (Sec.~\ref{sec:simulation_protocol_choice}) are defined for a specific type of free energy calculation, i.e. a free energy of binding or a free energy of hydration. Different types of simulations require different choices for ligands, solvent, and host molecules (in the case of the estimation of free energies of binding).

\subsection{Free energies of binding}
\tocsubsectioncomment{{Steering Meeting: @Volunteer move paragraph ``Congeneric series often need alignment'' to second paper if we are assuming a single calculation?}}
\label{subsec:binding}
In principle, in the limit of sufficient configurational sampling, the free energy changes estimated from an alchemical free energy calculation should be independent of the system's initial coordinates. However, in practice, because simulations are of finite duration (typically 1-100 ns per state at present), this is only true for certain classes of alchemical free energy calculations such as relative or absolute free energies of hydration of small and relatively rigid organic molecules. Protein-ligand complexes typically exhibit slowly relaxing degrees of freedom that significantly exceed the duration of an alchemical free energy calculation, and host-guest calculations can be susceptible to these issues as well, depending on timescale and system. It is therefore generally important to carefully select input coordinates to obtain satisfactory results. 
The following questions may be relevant before diving into the simulation setup.

\begin{itemize}
    \item Do I have one or multiple good receptor structures? (e.g. a good resolution X-ray crystal of the protein target)
    \item Do I have information on one or all of the ligand binding sites? (e.g. an X-ray structure)
    \item Should I include buried waters, or other small molecules that can be found in an X-ray structure?
    \item Are my ligands part of a congeneric series? (i.e. simple R group substitutions around the same scaffold)
    \end{itemize}

\paragraph{Are there good X-ray structures available?}
As with any simulation, care should be taken in selecting available X-ray structures in the Protein DataBank~\cite{berman2003announcing}. In some cases it may be wise to choose multiple starting structures to account for variability in receptor conformations as well as the accuracy of available X-ray structures. Typically, clustering of receptor structures can be used to identify different receptor conformations near the binding site, as well as assessing relevant side chain placements from the X-ray structure, see for example~\cite{mey2016blinded}. In terms of set up and other choices, following general best practice guidelines is advisable~\cite{braun2019best}.

Many free energy calculations focus on a congeneric series of ligands, which can make these calculations suitable for relative free energy protocols (see Sec.~\ref{sec:simulation_protocol_choice}). For relative calculations, some care has to be taken selecting binding poses for these ligands. Generally, a common assumption for a congeneric series is that the binding mode is conserved. Therefore, if an X-ray structure of one of the ligands is available, this should be used to position the ligands in the putative binding site in an energetically reasonable conformation without steric or electrostatic mismatch with the receptor. Checking the X-ray structure versus the experimental electron densities is important, as the position of part of the ligand or important sidechains may be based on the interpretation of the crystallographer rather than the available electron density, especially in cases of missing density. For example, looking at a cyclohexane ring density, a chair configuration is vastly more likely than that of a boat and, if a boat configuration is present in the structure, it may be worth inspecting the density to ensure it adequately supports this choice. 

\paragraph{Are you prepared to deal with any binding mode challenges?}
Generally, binding modes within congeneric series are conserved~\cite{wacker2010conserved}, however, exceptions exist~\cite{brandt2011congeneric,nazare2005probing}, as discussed in more detail in Sec.~\ref{sec:multiple_binding_modes}. Certain functional groups may be particularly prone to this due to symmetries or near symmetries. One such issue involves a 180 degree flip in the dihedral angle of an aromatic ring, or five-membered ring leading to a different spatial position of ortho- or meta- substituents that otherwise should overlap within a series. The 180 degree flip of the ring may not occur enough during simulations (due to steric obstructions) to overcome bias due to the starting configuration. Another scenario may be equatorial and axially substituted saturated rings (e.g. cyclohexane derivatives). This situation may be addressed by explicitly modelling different binding modes of the same ligand and combining later computed free energy differences for different binding modes into a relative free energies of binding~\cite{kaus2015how}.

\paragraph{Have you considered stereoisomers and enantiomers?}
Congeneric series can contain stereoisomers or enantiomers which can bind very differently, resulting in large errors if treated incorrectly. For racemates, the relative abundance of each stereoisomer is normally not known. Therefore, the experimental activity associated with just one stereoisomer/enantiomer is more uncertain. However, the modeling typically uses just the bioactive conformation that best fits the active site. Clearly this introduces potential for larger errors compared to experiment. Nevertheless, if all compounds in the congeneric series are racemic, originating from similar synthetic procedures with an expected similar abundance of stereoisomers, then the differences may cancel and the trend in calculated and observed binding energies may be robust. Despite this, we can see that care and further testing is needed in this scenario, and the quality of the predictions may suffer. Additionally, unexpected changes in what stereoisomer binds experimentally, if they occur, could pose significant challenges for modelling efforts.

\paragraph{Conserved binding site waters can play an important role in binding free energies}
Binding site water molecules may form water mediated protein-ligand interactions which can pose challenges whenever exchange with bulk water is slow compared to simulation timescales. This can happen in buried binding sites~\cite{laage2017water}. Overlaying multiple protein X-ray structures can identify conserved water molecules or those that are associated only with certain ligands in a series and are therefore important to include in calculations. In cases where water molecules are known to play an important role in ligand binding, for example if the presence of electron density suggests they are tightly bound (indicated by a high EDIA score~\cite{nittinger2015evidence,meyder2017estimating}), software implementations that use water sampling facilitated by Grand Canonical Monte Carlo methods may be useful~\cite{michel2010prediction}. Other tools such as WaterMap~\cite{abel2008role,young2007motifs} or open source equivalents (SSTMap~\cite{haider2018solvation}, GIST~\cite{ramsey2016solvation}, and others) can be used to define the hydration states for systems with no experimental evidence of water sites~\cite{wang2011ligand}. Well-known protein systems with water mediated ligand interactions are for example: HSP90 which formed part of the D3R grand challenge 2015~\cite{mey2016blinded}, A2A~\cite{brucemacdonald2018ligand}, MUP~\cite{ross2015water}, ~\cite{deflorian2020accurate}, and others~\cite{michel2009energetics}.

In the context of relative binding free energy calculations, determining the correct hydration pattern for the two endpoints may not be sufficient for an accurate and reproducible calculation. If the locations of the bound water molecules differs at the two endpoints - e.g. if a perturbation to the ligand displaces a bound water molecule - then the network needs to be able to adapt during the perturbation. Otherwise, it is likely that the estimated relative binding free energies will be dependent on the direction in which the perturbation is performed~\cite{ross2020enhancing}.

In absolute binding free energy calculations, a ligand is fully decoupled from a binding site cavity which may otherwise be hydrated in the \textit{apo} state. In this case, the sampling of water molecules must be sufficient to hydrate the binding pocket as the ligand is decoupled (or vice versa for the reverse). When the binding site is exposed and water can move freely between the site and bulk solvent, then sampling is often not an issue. However, in the case of more buried sites or sites which form complex water networks, enhanced water sampling may be required to ensure an accurate binding affinity.

\paragraph{Membrane proteins require additional care}
Integral membrane proteins require embedding in a suitable model membrane to remain stable during simulations. Lipids are usually not included in protein force fields and, although they may be covered by generic small molecule force fields, have often been parameterized separately (e.g., AMBER's Lipid21 \cite{AMBERLipid21} and the CHARMM lipid force field \cite{CHARMMLipidFF}). Membrane systems can be simulated in multiple thermodynamic ensembles, but the semi-isotropic scheme $NP_{z}P_{xy}T$ is frequently employed, allowing the pressure in the bilayer plane ($xy$) to scale independently \cite{LipidBestPracticesCOMS}. These systems require more extensive equilibration than soluble proteins. Some workflows, such as CHARMM-GUI or Desmond membrane preparation, recommend a multi-protocol to relax membrane systems \cite{https://doi.org/10.1002/jcc.23702,DesmondManual}. 

Alchemical transformations that involve net charge changes can provide difficulties for membrane systems; phospholipids carry functional groups with nonzero formal charge and cannot be treated as a solvent with a uniform dielectric in the same way as water. Several approaches are reviewed in \cite{wu2022correction-51c}. The authors recommend the use of a co-alchemical ion, specifically making an ion of equivalent charge appear alongside the disappearing charged molecule to maintain system neutrality.

In the case of a lipid-facing binding site, there are three additional challenges. First, simulation time should be extended to ensure sufficient sampling of lipid configurational space. Lipids may either bind alongside small molecules, acting as cofactors, or be displaced from the binding site by a ligand. If lipids participate in binding through protein-lipid or ligand-lipid interactions, it is necessary to sample these intermolecular interactions through additional $\lambda$ windows, longer simulation times, or different alchemical protocols. Displacing a lipid will have its own free energy cost which may take a long time to converge if it requires diffusion and rearrangement of nearby lipids. Second, considering the free energy cost of a ligand partitioning into the membrane may provide additional insights \cite{doi:10.1021/acs.jcim.1c01147}. Third, the free energy of binding for a small molecule may be strongly coupled to the lipid species. In some cases, the identity of the lipid may be known. But in other cases, it may be difficult to discern the identity of the lipid from X-ray or cryo-EM structures due to the flexible nature of lipid head groups and benchmarking is recommended to match experimental data.

\paragraph{Protonation states depend on the pH of the experimental assay}
Care should be taken when preparing ligands and proteins to match the pH of the experimental assay, if known. As mentioned above in Sec.~\ref{subsec:exp_condition}, the pH of the assay can differ from neutral pH and will determine the protonation states of the proteins and ligands. Since the pKa of reference amino acid sidechain residues is known, but can vary in the protein environment, many different tools have emerged for predicting sidechain pKa in proteins, such as the H++ server, ProPKa, APBS, and Maestro ~\cite{anandakrishnan2012automating, sondergaard2011improved, jurrus2018improvements, 2020schrodinger}. Strongly acidic (Glu, Asp) or basic (Arg, Lys) sidechains can reliably be predicted to be ionized, but care is still needed as the local environment can modify expected ionization states, such as  the catalytic Asp dyad in proteases. Histidine is notoriously more difficult to predict as its pKa suggests it ionizes closer to the experimental pH range. For ligands, often the pKa needs to be determined, if it is not known experimentally. There are many different available tools for this purpose, but common choices may be propKa~\cite{olsson2011propka3,sondergaard2011improved}, Chemicalize (\url{https://chemicalize.com/welcome}), or Maestro~\cite{2020schrodinger}. Still, accurate pKa prediction for small molecules remains a challenging problem, even with dedicated tools~\cite{isik2018pka}. While often it can be assumed that the protonation state of a ligand and protein will remain the same as the ligand binds, some care needs to be taken with systems where the protonation state may change upon binding~\cite{onufriev2013protonation}. BACE~\cite{kim2015conformational}, for example, famously undergoes a protonation state change on ligand binding.


\paragraph{Congeneric series often need alignment}
Input coordinates for a congeneric series may be generated by docking calculations, or by ligand alignment using MCSS algorithms. The latter tends to produce alignments that are more conserved and more consistent free energy changes across a dataset, but will struggle to yield reasonable results for relative binding free energy calculations that involve a significant binding mode rearrangement. This may also lead to steric clashes with the receptor coordinates of the reference ligand if structural rearrangements are needed to accommodate different members of the congeneric series. Small steric clashes may be resolved during subsequent simulation equilibration prior to data collection, but there is a risk that the complex relaxes to an alternative metastable state. 

An additional consideration arises for single topology relative free energy calculations. In this class of alchemical free energy calculations it is necessary to generate a molecular topology that may describe the initial and final states of the perturbation (see Fig.~\ref{fig:fig_topology}). In cases where the end states have high topological similarity and high structural overlap this is relatively straightforward and typically handled by use of MCSS calculations. In situations where the end state topologies differ significantly, or where there is relatively little spatial overlap between the two end states, some user intervention may be necessary to produce a satisfactory input topology.

If the binding site location is uncertain but the structure of the receptor is well defined and plausible binding sites are identified, it may be more useful to choose an absolute free energy protocol to compute the standard free energy of binding of the ligand to a set of binding sites. This requires the user to prepare input files describing the bound conformation in different putative binding sites~\cite{evoli2016multiple}. The apparent binding free energy of the ligand may be obtained by combining the individual binding site free energies, which also indicate where the ligand is more likely to bind. In this case a docking program can generate initial structures. Different commercial and non-commercial tools are available, such as rDock~\cite{ruiz-carmona2014rdock}, Autodock Vina~\cite{trott2010autodock}, Glide~\cite{friesner2004glide}, or Flare, to name a few~\cite{kuhn2020assessment}. 

If the putative binding sites are not apparent, for instance due to significant induced-fit effects, it may be challenging to obtain meaningful free energies of binding. One may have to account for the free energy cost of forming a binding site in the target receptor which may not be feasible on alchemical simulation timescales.

\subsection{Free energies of hydration or partition coefficients}
\tocsubsectioncomment{Steering Meeting: @Volunteer to expand coverage of free energies of hydration/ partition coefficients to make coverage of applications more equal.}
\label{subsec:hydration}
Preliminary considerations necessary for using free energy methods to compute partition coefficients are generally more straight forward. For example, a 3D minimised structure of a solute can be generated with a simple tool such as openBabel and solvated to prepare the input to compute a free energy of hydration~\cite{oboyle2011open}. However, in these cases a careful choice of forcefield for the organic solvent model, as well as water model is essential. See for example~\cite{bosisio2016blinded,rustenburg2016measuring} for a good discussion of these choices. And, while sampling problems might seem to be a non-issue for small molecules, this is not always the case; e.g. even the hydroxyl orientation on neutral carboxylic acids can occasionally pose a challenge~\cite{klimovich2010predicting, lim2019assessing}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% What simulation protocol should I choose   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{\tocorange{What simulation protocol should I choose?}}
\section{\tocorange{Choice of simulation protocol and implementation of alchemical transformations}}
  \sbnote{Emilio suggested to make the title more general; this is my suggestion!}
\tocsectioncomment{Steering group: Possibly expand to include other methods group agrees on.}
\tocsectioncomment{@Stefan Boresch to restructure as per his suggestion to remove single/dual topology section and begin with a more fundamental discussion which might more naturally include all options e.g. ATM. @Stefan Boresch to mention best practices for dummy atoms? This might benefit from following @Emilio Gallicchio's changes to make the theory section more general.}
\tocsectioncomment{@Sheenam Khuttan / @Emilio Gallicchio to contribute section on ATM.}
\tocsectioncomment{@Vytas Gapsys / @Volunteer to add best practices for non-equilibrium calculations.}
\label{sec:simulation_protocol_choice}
Alchemical free energy calculations can be grouped into two main categories, ``absolute'' (see Fig.~\ref{fig:fig_absolute_thermodynamic_cycle}) and ``relative''\footnote{The distinction is a bit of a misnomer, since both compute ratios of partition functions relative to another state and in that sense are relative, while neither computes an absolute free energy.} (see Fig.~\ref{fig:fig_binding_thermodynamic_cycle}), which differ in whether they compute properties for a single molecule (absolute) or compare properties of different, usually closely related, molecules (relative).
To use binding as a concrete example, in absolute binding free energy calculations, we compute the binding free energy of a ligand to an individual receptor relative to a standard reference concentration. In contrast, in relative binding free energy calculations, we compare the binding free energy of two related ligands to determine the potency difference.

\subsection{Absolute and relative free energy calculations have important differences}
Many of the issues around simulation setup and protocol choice for alchemical calculations are common, but there are some differences between absolute and relative calculations. We will consider protocol differences before treating the common elements.

\subsubsection{Choices unique to relative free energy calculations}
\tocsubsubsectioncomment{Steering Group: @Volunteer to mainly move atom mapping section to second paper and assume that the change is small (and hence atom mapping is trivial). @Benjamin Ries to add discussion of 3D atom mapping in second paper.}
\label{sec:relative-fe-protocol}

\paragraph{Topologies} In regular biomolecular simulations one studies physical systems or, in other words, all entities in the system, e.g., protein, ligand and waters, represent real molecules. For the following, it is helpful to classify such simulation systems as having a {\em chemical} topology. In relative free energy calculations, however, one has to transform, e.g., ligand A into ligand B etc. (see \sbnote{appropriate cross-reference!}). The required alchemical transformations can be realized in several ways, each with distinct advantages and disadvantages. In the first relative free energy calculations, these transformations were achieved with the help of chimeric entities, capable of representing both ligand A or ligand B. The important point here is that there is a single set of coordinates for this chimeric ligand, but its ``topology'' is flexible and can, for the same set of coordinates, represent either end state. We will consider this class of approaches as using an {\em alchemical} topology with a single set of coordinates. The construction of these chimeric intermediates quickly gets complicated and is difficult to automate; therefore, approaches have been developed in which both end states (e.g., ligand A and B) are present simultaneously. Thus, we have dual coordinates, but chemical topologies for each of the entities. In the following, we outline these approaches in more detail, together with additional considerations how the various approaches differ in practical use. While we will point out the respective advantages and disadavantages, we stress that the user's option in practice often are limited by the choice of simulation software.

\paragraph{Single coordinate approaches --- alchemical topologies}

When operating with a single set of coordinates for the region undergoing the alchemical transformation, a key distinction between approaches concerns the atom mapping between end state molecules. %Often this is predetermined by the choice of simulation software.
As first suggested by Pearlman, these have been referred to as \emph{dual topology} versus a \emph{single topology} \cite{Pearlman_1994}. The distinction between single and dual topology can be illustrated by considering a hypothetical transformation from molecule A to molecule B, where both atoms share a common substructure but differ in their substituents; in particular, consider a transformation of benzene to benzyl alcohol shown in Fig.~\ref{fig:fig_topology}. The single and dual topology approaches as proposed by Pearlman correspond to the left and middle paths of Fig.~\ref{fig:fig_topology}.  %\sbnote{Fig.~3 needs to be updated for dual coordinate methods and corrected, some bonds for the dummy atoms have the wrong anchor atom!}
The common substructure between the two molecules is the benzene ring, though in practice the substructure may be selected to be larger depending on the mapping chosen, as we discuss below.

In single topology calculations, the overall transformation is set up to involve as few additional atoms as possible, so benzene would be typically changed into benzyl alcohol by first changing one of the hydrogens into a carbon. The site of this transformation will also be the future home of two additional hydrogen atoms bound to the new carbon, so these must initially be present as non-interacting atoms called ``dummy atoms'' (labelled Du in Fig.~\ref{fig:fig_topology}), which retain their bonded interactions but do not interact with the rest of the system.  Bond parameters as well as partial charges between the changing atoms are adjusted accordingly between the initial and final state; see below for further details. In a single topology calculation, atoms may change their type, ensuring minimal dummy atoms are created. This is illustrated in the left arm of Fig.~\ref{fig:fig_topology}. At intermediate states, atoms behave as 'mixed' (M), either interpolating between two physical atoms, e.g., in the example, the hydrogen becomes a carbon, or between dummy and physical atoms.

\begin{figure}
    \includegraphics[width=0.95\columnwidth]{figures/fig3_topol/Figure.pdf}
    \caption{\textbf{Strategies for alchemical calculations: single coordinate single and dual topology vs.\ dual coordinate dual topology.} \textbf{Left}: A single coordinate single topology converts from one type of atom to another. Dummy atoms (Du) are used when there is no corresponding maximum common substructure match between the two molecules for certain atoms, using a soft-core interaction to improve overlap between the dummy atoms and the "real" atoms. At intermediate states, 'mixed' atoms (M) are present, either interpolating between physical atoms, e.g., a hydrogen to a carbon, or between physical and dummy atoms.  \textbf{Middle}: The single coordinate dual topology does not convert one species to another, but only converts between Du atoms and an interacting species, typically using soft-core potentials for this. Here, 'mixed' intermediate atoms (M) always interpolate between physical and dummy atoms. Thus, 'mixed' atoms are used in both single coordinate approaches (single and dual topology), but the way the transformation occurs and the end states differ.
      %Following the arrow along the left and right illustrate the differences.
\textbf{Right}: In the dual coordinate dual topology approach both end states are present as separate molecules simultaneously.  Initially, benzyl alcohol is not interacting with the environment, at intermediate states the environment sees a mixture of the interactions of the two solutes, and, finally, benzene is not interacting with the environment. The two solutes are kept on top of each other by suitable restraints, indicated by the black ``spring'', and  the two molecules never see each other.  Figure adapted from the one used in V1 of this manuscript; adapted and extended by Sara Tkaczyk.
      % \url{http://www.alchemistry.org/wiki/Constructing_a_Pathway_of_Intermediate_States}
    }
    \label{fig:fig_topology}
\end{figure} 

In contrast, in a dual topology alchemical free energy calculation, \emph{no atoms are allowed to change type}~\cite{boresch1999role, shirts2012best}. This means that the benzene to benzyl alcohol transformation involves starting with benzene plus the non-interacting dummy atoms making up the hydroxymethyl group, then passing through an intermediate state where some atoms are partially interacting---particularly, those atoms which are becoming dummy atoms or ceasing to be dummy atoms~\cite{mobley2014blind}. The transformation finally culminates in a state where benzyl alcohol is present along with the additional dummy atom which was previously a corresponding hydrogen of the benzene. Fig.~\ref{fig:fig_topology}'s right branch depicts how such a dual topology works. Note that the two groups that are switched on or off never see each other. The 'mixed' intermediate atoms (M) are used as well, but they strictly interpolate between physical and dummy atoms, or vice versa.


%\sbnote{This probably needs to be rewritten\ldots}
As far as we are aware, the distinction between (single coordinate) single and dual topology approaches has been made primarily for two main reasons. First, this choice affects the alchemical pathway followed, and thus may affect convergence properties---though we are not yet aware of a study of the relative efficiency and merits of these two approaches. Additionally, historically, some simulation packages implemented only one approach and not the other, meaning that the distinction was functional. For an in-depth analyis of differences resulting from the use of a  single vs.\ a dual topology approach (single coordinate in both cases) see Ref.~\cite{Boresch_2002}.

\paragraph{Dual coordinate approaches --- dual chemical topologies}

The chimeric constructs needed in single and dual topology approaches in the sense of Pearlmans definition just described quickly become non-trivial to set up and require care to avoid artifacts (see below). %\sbnote{See below; where do we place the dummy atom discussion?}.
Some of these difficulties might be avoided by having the initial and final state present as separate molecules with separate coordinate sets. To the best of our knowledge, such an approach was first described by Axelsen and Li \cite{Axelsen_1998}. Both initial and final state are present simultaneously; the two copies never see each other and interactions with the environment are turned on/off as a function of $\lambda$. Harmonic restraints between corresponding atoms in the initial and final state copy prevent the two molecules (sets of atoms from drifting apart). %Unfortunately, Axelsen and Li referred to their ansatz also as dual-topology, though in practice it is quite different from Pearlmans meaning of the term.
A recent implementation of this idea is Restraintmaker \cite{Ries_2022}, a tool to automatically assign the distance restraints needed to keep the two molecules / regions (one for each of the physical endstates) on top of each other. The idea is illustrated in the right branch of Fig.~\ref{fig:fig_topology}.  Somewhat unfortunately, Axelsen and Li, as well as Ries et al refer to their approach as dual topology. Ries et al suggested to use the term hybrid topology for (single coordinate) dual topology in the sense of Pearlman. We will attempt a disambiguation of the various nomenclatures below.

Another variant of a dual coordinate approach is implemented in NAMD \cite{jiang2019computing}. Whereas Ries et al.\  use distance restraints to keep two molecules on top of each other, corresponding atoms in NAMD are held on top of each other by constraints; in practice, this means that these coordinates are forced to be identical. AMBER's free energy implementation recently switched to a similar approach \cite{Lee_2023}.
%The authors refer to this approach as hybrid single-dual topology. While it technically uses two separate sets of coordinates, the constraint that corresponding atoms have identical coordinates makes it effectively a single coordinate method; hence, I consider NAMDs approach to be a variant of Pearlmans (single coordinate) dual topology. 

Dual coordinate approaches with chemical topologies encompass a third group of methods, where essentially two absolute free energy calculations are carried out in opposite directions at the same time.
The so-called ``separated topologies'' (SepTop) method \cite{rocklin2013separated,Baumann_2023} and the ``alchemical transfer method'' (ATM) \cite{Azimi_2022} belong into this category. In SepTop, the two copies are held on top of each other via restraints with respect to the protein/receptor they bind to (as opposed to Restraintmaker, where the molecules are restrained to each other. %In ATM, a restraint is used to keep the bound ligand 1 and the free ligand 2 always some minimum distance apart; during exchange moves, suitable rigid-body rotations/translations are applied to move the free ligand into a position/orientation as similar as possible to the one of the bound ligand.
In ATM, restraints are used to keep the bound and free ligands at some distance apart and in the same orientation, so that during the translation move the free ligand is placed into a position and orientation as similar as possible to that of the bound ligand. Both copies are present simultaneously, but they do not occupy the same space. Recently, a variant of $\lambda$-dynamics that uses chemical topologies (separate coordinates for each state) has been proposed \cite{Liesen_2024}.
  
%Other methodologies also use both end states simultaneously; examples are the Separated Topologies (SepTop) approach [Baumann2023] and the ATM method [Azimi2022]. In the former, the two copies are held on top of each other via restraints with respect to the protein/receptor they bind to. Ries et al. refer to such an approach as separated dual topology, whereas they label their approach as linked dual topology. In ATM, a restraint is used to keep the bound ligand 1 and the free ligand 2 always some minimum distance apart; during exchange moves, suitable rigid-body rotations/translations are applied to move the free ligand into a position/orientation as similar as possible to the one of the bound ligand. Both copies are present simultaneously, but they do not occupy the same space.

%One final approach, so far in its infancy, has been called ``separated topologies'' and essentially consist of two absolute free energy calculations in opposite directions at the same time, turning one molecule's interactions with the environment off, while turning the other molecule's interaction on~\cite{jiang2019computing, rocklin2013separated}.

\paragraph{Summary, comparison of single and dual coordinate methods, orthogonal classifications:}

%Some additional terms have also been employed to talk about these different intermediate pathways . Particularly, some studies refer to a ``hybrid'' topology approach to free energy calculations~\cite{gapsys2015pmx, gapsys2016accurate, gapsys2020large}, though this term may not yet have achieved widespread use. In this case, "hybrid" seems to indicate that the set up of these free energy calculations involves a hybrid of the two molecules, and much of what is done in these studies uses a single topology approach~\cite{gapsys2020large}.

Unfortunately, during the past years the use of the terms single and dual topology has proliferated, often with quite different meaning from the original intentions. The above presentation makes clear that the primary difference between approaches is the use of separate coordinates for each end state (chemical topology) or the use of an alchemical chimera with a single set of coordinates (alchemical topology). We therefore suggest the following classification
\begin{itemize}
\item Single coordinate (SC) --- Alchemical topology
  \begin{itemize}
  \item Single topology (SCST)
    \item Dual topology (SCDT)
  \end{itemize}
  \item Dual coordinate --- Chemical topology (DC)
  \end{itemize}
For completeness, we list some additional terminology that has been used: Some studies refer to a ``hybrid'' topology approach to free energy calculations~\cite{gapsys2015pmx, gapsys2016accurate, gapsys2020large}, though in our view these calculations should be classified as single coordinate single topology \sbnote{Check whether this is correct!}. %this term may not yet have achieved widespread use. In this case, "hybrid" seems to indicate that the set up of these free energy calculations involves a hybrid of the two molecules, and much of what is done in these studies uses a single topology approach~\cite{gapsys2020large}.
Ries et al.\ suggested terminology \cite{Ries_2022} in which single topology corresponds to SCST, hybrid topology to SCDT, and dual topology to DC.

The practical implementation of the approaches to carry out alchemial transformations above leads to additional, often non-trivial differences within each methodology. In the description of DC approaches we already pointed out that the two sets of coordinates can be held on top of each other by constraints \cite{jiang2019computing,Lee_2023} or restraints. In the latter case, the restraints may couple the two set of coordinates directly \cite{Axelsen_1998,Ries_2022}, or the restraints may be defined relative to a common reference frame \cite{rocklin2013separated,Baumann_2023}. Finally, in ATM the two copies of the coordinates are held separate \cite{Azimi_2022}.

Concerning SC approaches, Pearlmans usage of the term single topology not only meant a chimeric construct as depicted in Fig.~\ref{fig:fig_topology}, but specifically implied that the coupling parameter $\lambda$ was applied to the force field parameters. E.g., a bond stretching energy term changing from C-H to C-C has the functional form $U_{bond}(\lambda)=K(\lambda)(r-r_0(\lambda))^2$. For $\lambda=0$, $K(\lambda)$ and $r_0(\lambda)$ correspond to the values appropriate for a C-H bond, and for $\lambda=1$ to those for a C-C bond. The other energy terms are treated analogously. The single topology paradigm as just summarized was the default mode of alchemical transformations in AMBER and GROMOS at that time.  More recently, this implementation of single topology has been referred to as parameter interpolation or mixing \cite{Giese_2018}. 

The $\lambda$-dependent interpolation can also be accomplished by mixing the energies and forces of the initial ($\lambda=0$) and final state ($\lambda=1$), e.g., linearly according to $U(\lambda)=(1-\lambda) U_0+\lambda\,U_1$. Other -dependencies can be used, and soft-cores \rref may be used for Lennard-Jones and electrostatic interactions to avoid endpoint problems. Giese et al. \cite{Giese_2018} refer to this approach as energy mixing (interpolation).%; it requires two separate calls to the energy/force routines, but since only a fraction of interactions is affected by the alchemical changes, various optimizations are possible to keep the computational overhead manageable.
An early example of energy mixing for SCST is the PERT free energy module of CHARMM (written by Bernie Brooks around 1990 and briefly described in Ref.~\cite{brooks_2009}.

Any SCDT approach requires two energy/force calculations and, thus, uses energy mixing. Therefore, approaches that implement energy mixing together with an alchemical topology (a single set of coordinates) often support both SCST and SCDT. E.g., CHARMM's PERT module just mentioned could be used to set up either of the SC approaches sketched in Fig.~\ref{fig:fig_topology}. Finally, all DC approaches require two energy/force evaluations.

Any energy mixing approach, whether in a SC or DC context, requires two energy/force evaluations. While various optimizations keep the computational overhead significantly below a factor of two,  parameter mixing, if applicable, is the compuationally most efficient approach. However, it is closely tied to SCST and the more complicated the alchemical transformation, the more challenging a strict SCST approach becomes. Also, the mixing of partial charges and the calculation of $\partial U/\partial\lambda$ for the reciprocal space particle-mesh Ewald (PME) summation is tricky. Giese et al.\ described how to do this \cite{Giese_2018}, but most energy mixing implementations calculate the PME term twice and mix the resulting energy and forces.

\sbnote{I think this should get its own paragraph/subsection; to be expanded!} Software packages vary in their use of single or dual topology approaches; for example, AMBER TI uses a dual topology approach, while BioSimSpace uses a single topology approach. Please make sure to check what approach is used with your software package of choice, or whether it supports your choice of approach (GROMACS and GROMOS, for example, support both). 
To our knowledge, efficiency differences have not been thoroughly explored, though conventional wisdom suggests that fewer dummy atoms are better, as introducing or removing atomic sites is usually more difficult, requiring more intermediate steps ~\cite{liu2013lead, mobley2012perspective}.

\paragraph{Atom mapping}
Following the choice of system representation and sampling strategy, it might be required to generate a atom mapping. This is the case especially for system representations using a single coordinate set (Type 1. \& 2), however a dual coordinate set approach could use an atom mapping as well, depending on the sampling method, this will be explained in the next steps.
Once a single coordinate set approach is selected is selected, a crucial next step is to identify the common atoms which will not be perturbed between the two molecules (respectivly end-states).
Rigorously, this process typically comprises a MCSS search of the molecules involved to identify the common substructure.
Specifically, with a single coordinate set approach in mind, atom types are allowed to change, so a permissive MCSS search can be done. This however requires either careful implementation of atom mass changes, bond length etc. or accepting the introduction of potential systematic error, that is in many cases negliable due to the cancelation of errors. \cite{ries2024Kartograf}

\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/fig4_mcs/Figure.pdf}
    \caption{\textbf{Illustration of maximum common substructure matches} MCSS is shown in green for when (\textbf{A}) a restrictive MCSS match is used and in (\textbf{B}) ring breaking is allowed, meaning there is no MCSS match between the two compounds.}
    \label{fig:fig_mcss}
\end{figure} 

In general there are mutliple ways on how a MCSS can be calculated. One of the most prominent approaches is to estimate the MCSS with a 2D subgraph isomorphism solver(SIS) using the 2D topological stuructre information of molecules\cite{raymond2002maximum}.
A large number of software tools can compute SIS MCSS matches using different cheminformatics packages. Some rely on RDKit~\cite{rdkit2019Dec}, such as pmx~\cite{gapsys2015pmx}, LOMAP~\cite{liu2013lead}, FESetup~\cite{loeffler2015fesetup}, ProtoCaller~\cite{suruzhon2020protocaller}, SMArt~\cite{petrov2021perturbation}, and partially BioSimSpace~\cite{hedges2019biosimspace}, while others such as fkckombu~\cite{kawabata20143d} are standalone tools. Schr\"{o}dinger's FEP+ planning tool was originally based on a version of LOMAP, and it also uses MCSS matching as well as 3D considerations to plan the network of single topology calculations between molecules~\cite{wang2015accurate}. 

SIS based methods, showed to struggle with 3D properties of the molecules, that need to be mapped, like for example stereochemistry. Therefore some packages developed a post-mapping step, where they filtered for atom distances, and therefore added 3D information into the mapping.
Still SIS MCSS searches can be relatively time consuming as the algorithmic complexity is classified as NP-complete, so if the goal is to assess a library of ligands to identify promising pairs for relative calculations, it can be helpful to use faster approaches such as shape similarity to perform an initial similarity assessment and then use MCSS only to identify final mappings for relative calculations~\cite{raymond2002maximum,klabunde2012mars,jones2009elucidating, Duesbury2018Comparison}. The SIS MCSS approach, though relatively standard, takes into account only topological similarity. It is possible that changes in binding mode could actually require a different choice of mapping, so in some cases mappings may need to be planned differently depending on 3D positioning of atoms in space. 

Here an alternative way to estimate the MCSS is to calculate a bipartite graph matching based on the 3D positions of two molecules. These approaches tend to be very fast (can have algorithmic complexity of $O(n)=N^3$) and geometric accurate in their mapping (e.g. stereochemistry or binding mode differing).
The geometric approaches additionally allow mappings of differing binding modes of the same molecule, or can be even used for significant larger molecules like proteins, due to the speed increase.
A disadvantage of these approaches is the strong dependency on the coordinate sets being well aligned. Another aspect is taking the topology changes of the molecules not into account, which can be done if necessary in a next step with a filtering approach, like checking for changes in ring hybridization or ring breaking (this problem is discusse below)|.
Tools that can be used to estimate the MCSS this way are contained for example in pmx \cite{gapsys2015pmx} or Kartograf \cite{ries2024kartograf}.

In any case Visual inspection prior to simulation is recommended to ensure that the mapping criteria correspond to the expected binding mode. If the mapping protocol returns simulations that correspond to different binding modes of a ligand within a perturbation map, this can cause large hysteresis.

A next step for atom mappings, would be to support multistate methods (e.g. RE-EDS~\cite{sidler2016replica}, A-EDS~\cite{perthold2020toward} or Ladybugs~\cite{robo2022achieving}) with efficient mapping algorithms. There are protoype starting point for solving this problem, but to our knowledge, there is only few published work on this aspect. \cite{petrov2021Perturbation}

Single coordinate set relative calculations and calculations based on substructure searches only work if in fact the ligands share a common substructure, e.g. are part of a congeneric series, see Fig.~\ref{fig:fig_mcss}.
If no common substructure is shared, then dual coordinate sets methods like linked-dual or separated topology free energy calculations are needed. One would co-localize a pair of compounds in a binding site, exclude their interactions with one another, and compute the relative binding free energy by turning one molecule on from being dummy atoms while turning the other off.
For such approaches it is crucial to find a good set of restraints, that keep the ligands colocalized over the time of the simulation . This problem is similar to the required restraints in ABFE Calculations (see \ref{ABFErest}). Few descriptions of possible approaches in RBFE calculations can be found for such approaches like the one suggested by \textit{Baumann et al.}~\cite{baumann2023broadening} based on boresch style restraints~\cite{boresch2003absolute}, with an elaborate automatic atom selection approach, for the seperated topology approach, or Restraintmaker~\cite{ries2022restraintmaker} for the linked-dualtopology approaches, which finds a small set of atoms to be linked via distance restraints, with a small distance to each other. 
However the implementation and testing of an fully automatized dual-topology pipeline for RBFE dual topology approaches is still to our knowledge a remaining research problem and was only tested with small datasets. \cite{jespers2019qligfep, Rieder2022Lev}

\paragraph{Dummy atoms}

In practically all relative free energy simulations, regardless of the approach, SCST, SCDT, or DCDT, dummy atoms (non-interacting placeholder atoms) are required. We stress this point, as sometimes dummy atoms are viewed as something specific to SCST. In SC approaches, dummy atoms may even be required if the number of atoms between initial and final state of the system is identical, consider, e.g., tautomeric forms of a molecule.

The need for and role of dummy atoms is clearly visible in Fig.~\ref{fig:fig_topology}: One or more dummy atoms are attached to the physical molecule. A crucial requirement is that these atoms, typically connected through bonded energy terms (bond stretching, angle bending, dihedral angles) do not affect equilibrium and dynamical properties of the physical system. However, since a physical molecule + dummy atoms attached to it can or must be viewed as a modified physical molecule, the partition function of the molecules with and without dummy atoms will NOT be identical. In other words, a single free energy difference between two molecules A and B will be different from that of A(+D) and B(+D), where the (+D) indicates the presence of one or more dummy atoms needed so that the alchemical transformation can be carried out. When a dual coordinate approach is used, the noninteracting part of the respective other endstate is tied to the physical one, and will contribute to the partition function. By construction, relative free energy simulatins involve two analogous alchemical transformations, e.g., A(+D) -> B(+D) in gas phase and aqueous solution (RSFEs), or in the bound and unbound state (RBFEs). If dummy atoms are interacting with the physical system in such a way that $\mathsf{Z = Z(R) \times Z(R\text{-}D) \times Z(D)}$, where Z is the total partition function, Z(R) the partition function of the physical system, Z(D) the partition function contribution resulting from interactions between only the dummy atoms, and Z(R-D) the contribution resulting from the bonded connections between the physical atoms and dummy atoms, then their contributions (Z(D) and Z(R-D)) factor from the total partition function. As dummy atoms do not interact with the environment, their contribution, therefore, is identical in the two alchemical transformations required in the two legs of the relative transformation and will cancel exactly from the double free energy difference of interest.

While some early work on the correct treatment of dummy atoms, i.e., how to treat them so that their contribution to the partition function factors, has been available for years \cite{Boresch_2002,Shobana_2000,Wang_2012}, most workers seem to mostly turn off nonbonded interactions for dummy atoms, but leaving all bonded interactions intact \sbnote{To all: While I am quite sure that this is what most of us have been doing most of the time, I wonder whether this has been epxlicitly described anywhere?}. Since current force fields use multiple angle and torsion terms for each atom, there are often a large number of bonded energy terms connecting dummy atoms to the physical molecule. However, as already described in the early studies and repeated in a more recent study focusing on the correct treatment of dummy atoms \cite{Fleck_2021}, the desired factorization can only be guaranteed if any dummy atom connected to the physical molecule is held by exactly three (non-redundant) degrees of freedom. Naive application of the three-degree-of-freedom per dummy atom rule (for dummy atoms having at least one joint bonded term with the physical molecule), however, can result in simulations where the dummy part adopts unphysical configurations/conformations; Fleck et al. referred to this as flapping. Thus, depending on the details of the physical molecule -- dummy atom(s) junction, the three degree of freedoms need to be selected with care, or a carefully chosen additional redundant degree of freedom may be needed. In the latter case, the factorization of the partition function is not exact, but the overall error can still be made arbitrarily small. For the full details, we refer the reader to Ref.~\cite{Fleck_2021}. 

One situation involving dummy atoms that needs to be avoided is the creation of a cyclic structure involving dummy atoms, i.e., whenever the (group of) dummy atom(s) is attached to two different parts of the physical molecule. In this case, the factorization of the partition function is never possible \cite{Shobana_2000}. It follows that ring opening or closing is extremely challenging to carry out using SCST approaches \cite{liu2015ring}; these difficulties have in part motivated the development and adoption of dual coordinate approaches. For more on ring opening/closing, see also below. Nevertheless, DC approaches are susceptible to exactly this type of problem: to keep the noninteracting molecule on top of the interacting one, typically multiple bonded restraints (e.g. harmonic bonds) are used \cite{Axelsen_1998,Ries_2022}. These effectively, are equivalent to the formation of cyclic structures with potential erroneous contributions to the double free energy difference of interest. The type of restraints used in SepTop \cite{rocklin2013separated,Baumann_2023} and ATM \cite{Azimi_2022} aoid this problem.

The influence from an incorrect treatment of dummy atoms (e.g., leaving all bonded terms intact) is difficult to estimate, though it may be small in many cases \cite{Fleck_2021}. Nevertheless, some guidelines should be followed:
\begin{itemize}
  \item Obviously, a system with and without dummy atoms should have the same energetic minimum. Note that in larger groups of dummy atoms, redundant bonded terms involving only dummy atoms will be essential to avoid flapping, and the energy of the optimized geometry may be different from that of the physical system without dummy atoms. Thus, a \underline{necessary} condition is as follows: Optimize the geometry of the physical system (no dummy atoms); the final energy is the reference value. Optimize the geometry of the same molecule in the presence of dummy atoms; the final energy may well be different from the reference energy. Now delete the dummy atoms and recompute the energy \underline{without} further minimization. The energy after the deletion of the dummy atoms must be identical to the reference energy. 
\item The above is only a \underline{necessary} criterion, and the dummy atoms may still influence the dynamical behavior of the physical molecule. Furthermore, overzealous removal of redundant energy terms may result in flapping of the dummy atoms. If one suspects the latter, then a short simulation in the gas phase should reveal flapping. Unfortunately, while straightforward in principle, both checks described are hard to automate, which is essential in large RFEs campaigns. 
\item The correct treatment of dummy atoms can be validated by closing a suitable thermodynamic cycle.  E.g., Fleck et al.\ calculated ASFEs for each of their endstates, as well as the RSFE between them \cite{Fleck_2021}. In all cases when dummy atoms were treated according to best practices, the cycle closure error was well within the statistical uncertainty, which was well below 0.1 kcal/mol. A related, earlier study by Loeffler et al. also reported ASFEs and RSFEs. If one attempts to close the cycle based on the numbers reported there, cycle closure error was nonnegligible in some cases \cite{loeffler2018reproducibility}. 
\item While solvation free energies can nowadays be computed quite fast, their systematic calculation would nevertheless be too costly. The role of solvent can be replaced by some external restraint, distorting the average geometry of the physical molecule. If one computes the free energy cost of applying the restraint with and without dummy atoms, the two numbers must agree within statistical significance. While much faster than full solvation free energy calculations, applying a restraint in the gas phase requires careful thermalization of the simulation system, and automation is difficult.
  \end{itemize}
%Further work automating the correct setup and treatment of dummy atoms is necessary.


\paragraph{Ring breaking and forming.} Relative free energy calculations for ring breaking and forming are particularly challenging/problematic (see Fig.~\ref{fig:fig_mcss}\textbf{B}), in part because relative calculations rely on the free energy contributions of dummy atoms canceling between different legs of the thermodynamic cycle, which may not be true whenever dummy atoms are involved in rings~\cite{liu2015ring}.
Some approaches have attempted to address this using a single coordinate sets and with soft bond approaches ~\cite{clark2019relative,wang2017accurate} or dual coordinate set approach \cite{jespers2019qligfep, ries2022relative} but a general solution is not yet in mainstream use. Still, FEP+ implements one solution\cite{wang2017accurate}.

\paragraph{Constraints and relative free energy calculations}
One issue which requires particular care is the use of constraints.
Commonly, bonds involving hydrogen are constrained to a fixed length using algorithms such as SHAKE or LINCS, allowing the use of longer timesteps~\cite{krautler2001fast}.
However, in single topology relative free energy calculations, the atoms involved might be mutated to other atom types---for example, in a mutation of methane to methanol, one hydrogen might become an oxygen atom. The bonds with such atoms might not have any constraints, or if all bond are constrained, would have constraints of different lengths. 
Some molecular dynamics engines are not set up to recognize this change, or at least not to correctly include contributions to the free energy from changing constraints/constraint length, so results for a transformation can be erroneous.
At present the most general solution to this problem is simply to avoid the use of constraints (and thus use a smaller timestep if necessary, usually of around 1 fs) in any relative free energy calculation involving a transformation of a constrained bond. Individual software programs and settings can handle such issues. For example, bonds can be transformed in both GROMACS and GROMOS, because contributions of LINCS (GROMACS) and SHAKE (GROMOS) constrained bonds are added to the $\frac{dH}{d\lambda}$ term~\cite{pearlman1993determining, straatsma1992holonomic, pearlman1991overlooked, gunsteren1989computer}. However, the constraints are not taken into account when calculating energy differences to other intermediate states as the effect is entropic, not energetic. User manuals should carefully checked for how these effects are included if a constrained bond changes in length. We do note that if one performs calculations of the changing constraint in both solution and in the binding site, then the errors often cancel substantially, but the cancellation is not guaranteed.

\subsubsection{Absolute free energy calculations must handle the standard state and use binding site restraints}
\label{sec:standardstate-restraints}

\tocsubsubsectioncomment{@Emilio Gallicchio to comment on possible issues with theoretical discussion and possibly update in the context of revised theory section. See PR from @Finlay Clark to improve discussion of restraint schemes and automated restraint selection. @Stefan Boresch may like to weigh in on analytical corrections/ general discussion. @Andrea Rizzi to reivew?}


\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/fig5_thermo_cyc_abs/Figure.png}
    \caption{\textbf{Thermodynamic cycle for an absolute binding free energy calculation with auxiliary restraints} The fully interacting ligand in water (\textbf{A}), has its charges turned off to pass to (\textbf{B}) followed by turning off van der Waals terms, resulting in a non-interacting ligand in water (\textbf{C}). The receptor-ligand complex (\textbf{D}) is defined by binding site restraints (dotted oval). Auxiliary restraints are often introduced (\textbf{E}) to improve convergence while the charges and van der Waals interactions are turned off (\textbf{F} and \textbf{G}). The free energy cost of releasing the auxiliary restraints (\textbf{G} to \textbf{H}) and transferring the non-interacting ligand from the standard state volume to the binding site (\textbf{C} to \textbf{H}) must be accounted for. The standard binding free energy is computed from this cycle as $\Delta G^{\circ}_{\mathrm{bind}} = (\Delta G^{\mathrm{elec}}_{\mathrm{solv}}+ \Delta G^{\mathrm{VdW}}_{\mathrm{solv}}) + \Delta G^{\circ}_{\mathrm{ideal}} -(\Delta G_{\mathrm{aux.restr.}}+\Delta G^{\mathrm{elec}}_{\mathrm{bound}}+ \Delta G^{\mathrm{VdW}}_{\mathrm{bound}}+\Delta G_{\mathrm{release}})$. Many variations of the route between the free (\textbf{A}) and bound (\textbf{D}) states can be used -- for example, state \textbf{H} is commonly skipped and the free energy cost of moving from \textbf{C} to \textbf{G} is calculated directly.}
    \label{fig:fig_absolute_thermodynamic_cycle}
\end{figure}


An absolute binding free energy calculation yields the standard free energy of formation of the molecular complex from the separated receptor and ligand species. Hence, as discussed in \ref{sec:non-covalent-molecular-binding}, it must depend on the standard state concentration $C^\circ$ (here $1 \, {\rm M} = 1 \, {\rm molecule}/1660$~\r{A}$^3$) and on the definition of the complex, that is on the specific binding pose for which the binding free energy is requested. Omitting the standard state concentration would yield an undefined result that would vary with the choice of concentration units. A similar vague estimate would result from omitting the binding pose definition that, for example, could equally describe binding to a specific site of the receptor or unspecific binding throughout the receptor surface depending on the extent of conformational sampling (see Sec.~\ref{sec:weak-binders}).

In the statistical mechanics formulation of Gilson et al.~\cite{gilson1997statisticalthermodynamic}, described in Section \ref{sec:non-covalent-molecular-binding}, the standard state concentration appears explicitly in Eq.~(\ref{eq:DG0-binding-constant-def}) and the binding pose is defined by the indicator function $I(\zeta)$ that characterizes the partition function of the complex; Eq.~(\ref{eq:intra-zRL-def}).  The role of the standard state and binding site definitions are particularly evident when expressing Eq.~(\ref{eq:DG0-binding-constant-def}) in terms of an ensemble average. To do so, we express the integrals in the numerator and denominator of Eq.~(\ref{eq:DG0-binding-constant-def}) over the same set of degrees of freedom. Note that the intramolecular configurational partition function of the complex, $z_{RL(v)}$, includes six more degrees of freedom--the position and orientation of the ligand relative to the receptor collectively described by the variable $\zeta$--than the product of the intramolecular partition functions, $z_{R(v)} z_{L(v)}$, of the separated receptor and ligand. To correct this discrepancy, we multiply and divide the right-hand side of Eq.~(\ref{eq:DG0-binding-constant-def})  by the quantity
\begin{equation} \label{eq:Vsite-def}
    V_{\rm site} \Omega = \int d\zeta I(\zeta) \, ,
\end{equation}
%\Omega is in my opinion a better symbol of the orientational extent than \xi_L. Lowercase greek letters are usually used
%for dynamical variables rather than integrated quantities
which measures the extent of the binding pose macrostate, where $V_{\rm site}$ corresponds to the spatial extent and $\Omega$ the orientational extent. The right-hand side of Eq.~(\ref{eq:Vsite-def}) combined with the integrals $z_{R(v)}$ and $z_{L(v)}$ yields a partition function similar to Eq.~(\ref{eq:intra-zRL-def}) but corresponding to a complex in which ligand and receptor are uncoupled~\cite{gallicchio2011recent} as if they were at infinite distance apart. The result is
\begin{equation}\label{eq:DG0-binding-constant-def-average}
K_b = C^\circ V_{\rm site} \frac{\Omega}{8 \pi^2} \langle e^{-\beta \Delta \Psi}  \rangle_0 
\end{equation}
where, similarly to Eq.~(\ref{eq:zratio-solv-average}),
\begin{equation}\label{eq:pert-energy-def}
\Delta \Psi(x_R, x_L, \zeta) =  \Psi_v(x_R, x_L, \zeta) - \left[  \Psi_v(x_R) + \Psi(x_L) \right]
\end{equation}
is the solvent-averaged binding energy of the complex when receptor and ligands are in intramolecular configurations $x_R$ and $x_L$, the ligand is in position and orientation $\zeta$ relative to the receptor (the uncoupled potential energy does not depend on  the position and orientation of the ligand relative to the receptor), and $\langle \ldots \rangle_0$ represents an ensemble average in the uncoupled ensemble. Finally, note that $\Omega = 8 \pi^2$ when the binding pose indicator function does not depend on the orientation of the ligand and Eq.~(\ref{eq:DG0-binding-constant-def-average}) simplifies to
\begin{equation}\label{eq:DG0-binding-constant-def-average-noOmega}
K_b = C^\circ V_{\rm site} \langle e^{-\beta \Delta \Psi}  \rangle_0 
\end{equation}
which, expressed in free energy units, yields
\begin{eqnarray}\label{eq:DG0-def-Vsite}
  \Delta G^\circ_b &=&  - k_B T \ln K_b = - k_B T \ln C^\circ V_{\rm site} - k_B T \ln \langle e^{-\beta \Delta \Psi}  \rangle_0 \nonumber \\
{\rm \ }  &=& \Delta G^\circ_{b,{\rm ideal}} + \Delta G_{b,{\rm exc.}}
\end{eqnarray}

The term $\Delta G^\circ_{b,{\rm ideal}} = - k_B T \ln C^\circ V_{\rm site}$ in Eq.~(\ref{eq:DG0-def-Vsite}) is interpreted as the \emph{ideal} component of the standard binding free energy, that is the binding free energy that would be measured in the absence of ligand-receptor interactions ($\Delta \Psi = 0$) and when the ligand's concentration is $C^\circ$. The ideal term is responsible for the dependence of the standard binding free energy on the standard state concentration. The arguably inappropriate term ``standard state correction'' is sometimes used in the literature to refer to $\Delta G^\circ_{b,{\rm ideal}}$. As seen above, the ideal term is a fundamental aspect of the statistical mechanics theory of molecular binding rather than a mere correction to an inexact formulation. 

Conversely, the term $\Delta G_{b,{\rm exc.}} = - k_B T \ln \langle e^{-\beta \Delta \Psi}  \rangle_0 $ is the \emph{excess} component of the standard free energy of binding, which is the term that depends on intermolecular interactions and the specific chemical composition of the system. The excess component is the target of the alchemical molecular simulations discussed here, in contrast to the ideal term that is generally evaluated analytically~\cite{boresch2003absolute}.

\paragraph{Handling the standard state in free energy calculations.}
As discussed in Sections \ref{sec:theory-solvation} and \ref{sec:theory-partitioning}, the handling of the standard state in solvation and solvent partitioning free energy calculations is typically straightforward. Eq.~(\ref{eq:DG0-solvation-def}) identifies the ideal and excess components of the standard solvation free energy in terms of the standard gas pressure $P^\circ$, standard solution concentration $C^\circ$, and ensemble averages typically evaluated by alchemical free energy simulations. These relations provide simple recipes to relate computational estimates to experimental values obtained under different conditions. Moreover, typical experimental reporters (Henry's constants and partitioning coefficients) directly probe the excess term calculated by molecular simulations, which is independent of the standard state.

As discussed above, the situation for binding is more complex and requires special care. The first important aspect is that binding free energy calculations must be performed with binding site restraints that implement the binding site indicator function $I(\zeta)$ by forcing the ligand to occupy the binding site even when it is decoupled from the receptor. Doing otherwise would fail to specify the bound macrostate of the complex and return undefined binding free energy estimates. However, in practice, calculations lacking binding site restraints often return reliable binding free energy estimates due to the kinetic trapping of the ligand in the binding site region during the relatively short molecular dynamics sampling typical of alchemical binding free energy simulations. Nevertheless, longer calculations could display persistent drift of the estimate as new regions of conformational space are sampled. A more serious consequence of neglecting binding site restraints is the possibility of the ligand leaving the binding site when it is not coupled to the receptor. Such occurrence indicates a serious violation of the theory. Alchemical binding free energy simulations where the ligand leaves the binding site are not set up correctly and can return grossly inaccurate binding free energy estimates.

Because it is a discontinuous function of the position and orientation of the ligand relative to the receptor, molecular dynamics implementations often approximate the indicator function by means of flat-bottom restraints~\cite{chen2007can, wu2021alchemical} (see below). Harmonic restraints are not as suitable in this respect because they favor a specific microstate at the bottom of the harmonic potential rather than specifying a region of conformational space.

Note that $\Delta G^\circ_{b,{\rm ideal}}$ is independent of the chemical nature of the binding partners, and it is the same for all complexes sharing similar binding site definitions. The latter is the reason that the ideal term cancels out when taking the difference of absolute binding free energies when estimating relative binding free energies (RBFEs). However, while it does not appear explicitly in the definition, $\Delta G_{b,{\rm exc.}}$ depends implicitly on the definition of the binding site through the ensemble average in the uncoupled ensemble, which includes only ``bound'' configurations according to the definition of the indicator function $I(\zeta)$. Varying the binding site definition affects both the ideal and excess binding free energy terms such that their sum (the standard binding free energy) is often only weakly dependent on the binding site definition~\cite{gilson1997statisticalthermodynamic,gallicchio2011recent}. Conversely, great care should be exercised when comparing calculated excess binding free energy values corresponding to different binding site definitions. Similarly, the outcome of a binding free energy calculation conducted without a binding site definition, i.e.\ without binding site restraints, is, in principle, undefined. The latter is also true for relative binding free energies because while the ideal term cancels out, the difference in excess binding free energies depends on the binding pose definition. 

\paragraph{Several choices of restraints are possible in binding free energy calculations.}
A variety of restraint types are commonly used in alchemical binding free energy calculations. Before going into their characteristics, we must acknowledge an important and often unrecognized distinction between the binding site restraints corresponding to the indicator function $I(\zeta)$ necessary for the implementation of the theory and optional auxiliary restraints and biasing potentials sometimes used to speed up the convergence of free energy calculations. Binding site restraints are an integral part of the molecular complex definition and are typically maintained throughout the alchemical process. In particular, they must be present unchanged at the unbound and bound states. In contrast, unless thermodynamic reweighting is applied in post-processing, auxiliary restraints cannot be present at the endstates to avoid affecting their free energies. Hence, typically the free energy cost of turning them on is computed at the uncoupled state, and the free energy gain of releasing them is calculated near the bound state. In the alchemical binding free energy literature, often harmonic restraint potentials imposed in an initial stage and removed in a final stage are described as implementing binding sites restraints. However, because they utilize harmonic potentials that cannot correctly describe the binding pose macrostate (see above) and because they are turned on and then off, these are instead auxiliary restraints introduced to enhance convergence without affecting, in principle, binding free energy estimates.

Binding site restraints implement the $I(\zeta)$ indicator function. They, therefore, can depend at most on the six rigid-body external coordinates of the ligand governing the position and orientation of the ligand relative to the receptor. Any other choice would affect the intramolecular conformational distribution of the ligand or the receptor and would  bias the binding free energy estimate. The external degrees of freedom introduced by Boresch et al.~\cite{boresch2003absolute,leitgeb2005alchemical} are a popular choice. The Boresch coordinates, as well as other similar approaches, involve selecting anchor atoms of the receptor and the ligand. In principle, the choice of anchor atoms is arbitrary, provided adequate simulation time is available, and as long as it leads to similar binding pose definitions. However, practical considerations may be important. For example, some choices of Boresch-style anchor atoms can be numerically unstable. Additionally, anchor atoms should likely be placed in a part of the molecule that defines the binding orientation well rather than in a floppy, solvent-exposed tail. Several automated methods have been proposed to select anchor points for Boresch restraints, which typically involve analysing a simulation of the fully-interacting receptor-ligand complex~\cite{alibay2022evaluating, alibay2021mdrestraintsgenerator, baumann2023broadening, chen2023enhancing, hedges2023suite, wu2025optimizing}.

As discussed above, binding site restraints are commonly implemented using quadratic flat-bottom restraints, which impose a restoring harmonic  force similar to harmonic potentials but only if the ligand leaves a specific region~\cite{chen2007can}. Often, binding site restraints do not limit the rotational degrees of freedom of the ligand, and the corresponding standard state term is zero; see Eq.~(\ref{eq:DG0-def-Vsite}). However, it might be challenging to fully explore the bound macrostate at all alchemical states when it is only limited by receptor-ligand positional restraints. As further discussed below, auxiliary restraints are particularly helpful in the latter circumstance to limit the extent of conformational sampling necessary to achieve rapid convergence of binding free energy estimates.

Most current binding free energy workflows do not use binding site restraints present at all stages of the simulation and implicitly assume that $V_{\rm site}$ in Eq.~(\ref{eq:Vsite-def}) is the volume of the simulation box $V$. In the absence of binding site restraints, only the protein-ligand interactions prevent the ligand from slipping out from the binding site and wandering throughout the simulation box within the simulation time frame. However, observations of ligands leaving the binding site become more likely as simulation times increase, especially when analyzing weak binders and non-binders (see below). Moreover, there is no obstacle for the ligand to diffuse away from the binding site at the decoupled state when protein-ligand interactions are turned off.

In practice, because they often implement auxiliary restraints, binding free energy prediction workflows that omit binding site restraints rarely yield grossly erroneous predictions. Auxiliary restraints are introduced gradually as protein-ligand interactions are turned off or are introduced at the bound state when the ligand is naturally trapped in the binding site. Either way, the free energy of imposing them can be tracked while preventing the ligand from leaving the binding site at the decoupled state. Provided that the interacting ligand samples only bound configurations, i.e., it behaves as if binding site restraints were present, the current practice of not using them is likely to incur only minor or insignificant errors. 

The Boresch harmonic restraints~\cite{boresch2003absolute,baumann2023broadening} are a popular choice as auxiliary restraints because they are based on interatomic distances, bond angles, and dihedral angles degrees of freedom already implemented in molecular mechanics codes that do not interfere with intramolecular conformational distributions. Moreover, the free energy of releasing Boresch restraints within the simulation box volume $V$ is easily computed analytically~\cite{boresch2003absolute, boresch2024analytical}.

By reducing the conformational space to be sampled, auxiliary restraints are often crucial for obtaining converged binding free energy estimates, even when binding site restraints are employed.
Auxiliary restraints take a variety of forms, such as distance restraints between the ligand and the protein~\cite{mobley2006use,clark2023comparison} as well as flat-bottom restraints. The choice of degrees of freedom and restraining potentials for auxiliary restraints is not as restrictive as for those for binding site restraints, provided that the free energy terms of restraining collective variables that couple protein and ligand degrees of freedom are adequately accounted for to avoid serious systematic errors~\cite{clark2023comparison}.
For example, the overall ligand RMSD has been used~\cite{woo2005calculation} for this purpose. Auxiliary restraints are designed to reduce the amount of conformational sampling at intermediate $\vec{\lambda}$ values. However, more computational effort is required to compute the free energy when the restraints are turned on and off. Additionally, such restraints can limit the exploration of alternative binding modes. This restriction may be undesirable when using Hamiltonian $\lambda$ exchange or expanded ensemble techniques where allowing the ligand to exchange binding modes when it is non-interacting could provide sampling benefits~\cite{wang2013identifying}.
More specifically, flat-bottom restraints allow a ligand to explore multiple binding sites, and harmonic restraints allow the exploration of multiple binding modes within a site, while Boresch restraints only allow a single binding mode within a single site.
See additional discussion of the possibility of multiple binding modes in Sec.~\ref{sec:multiple_binding_modes} below.

Recently, degrees of freedom for binding site and auxiliary potentials based on larger sets of atomic positions of the receptor and ligand have been put forward.
Fu et al. suggested restraining the six relative rigid-body degrees of freedom derived by finding the rotation of the ligand, which minimises the RMSD to a reference structure of the receptor-ligand complex (after accounting for rotation and translation of the receptor)~\cite{fu2017new}. Salari et al. proposed restraining the ``distance-from-bound-configuration'' (DBC) variable, which is the RMSD of ligand coordinates in the frame of reference of the binding site~\cite{salari2018streamlined, ebrahimi2022symmetry}. DBC may allow the binding pose to be closely preserved as the ligand intermolecular interactions are removed, but has the disadvantage of coupling the internal and relative external degrees of freedom of the receptor and ligand, making them unsuitable for describing the binding site macrostate and the corresponding standard state terms. However, these restraints are practical as auxiliary restraints when additional steps are used to introduce and release them. Moreover, because they are based on flat-bottom potentials encompassing the desired binding poses, the free energy of releasing them in the bound state can be safely neglected in most cases. The restraint schemes discussed here are implemented in open-source workflows~\cite{fu2021bfee2, fu2022accurate, santiago-mcrae2023computing, clark2023comparison, hedges2023suite}.

\subsection{Absolute and relative calculations deal with some of the same issues} 

\paragraph{Handling weak binders}\label{sec:weak-binders}
According to the non-covalent statistical mechanics theory of bimolecular binding (Sec.~\ref{sec:theory}), only the conformations in which the receptor and ligand form a bound complex are sampled. Determining an appropriate definition of the bound macrostate can be challenging for weakly bound ligands. For tightly bound ligands, virtually all reasonable definitions of the bound state will lead to equivalent free energies since the partition function will be dominated by a relatively limited ensemble of low-energy poses. However, this simplification breaks down for weak binders.  In fact, there might not be a perfect correspondence between the structural definition of the complex on which current alchemical models are based~\cite{gilson1997statisticalthermodynamic} (Sec.~\ref{sec:theory}) and experimental reporters~\cite{mihailescu2004theory}. For example, isothermal titration calorimetry (ITC) or surface plasmon resonance (SPR) measurements effectively define a binding state that encompasses all ligand conformations complexed with the protein, regardless of where they bind the protein. In contrast, fluorescence polarization competition assays measure binding to only a single location, where the ligand of interest displaces a competing binder. Therefore, care must be taken to ensure that a reasonable definition of the binding site is used~\cite{wang2013identifying}.

Apart from the difficulty of selecting an appropriate definition of the binding site region that relates to the experimental technique, the alchemical theory and the computational procedures are the same whether strong, weak, or non-binders are considered. The alchemical binding free energy calculation will report the binding free energy for the selected binding pose specified, for example, by the region allowed by flat-bottom binding site restraints. Changing the definition of the binding pose will yield a binding free energy for the new pose, which will generally differ from the first. 

Especially when simulating non-binders that are not tightly associated with the receptor, it is likely to observe the ligand exploring the boundaries of the allowed binding site region. In such occurrences, which can also occur when the allowed binding site region is too restrictive, and the ligand is attempting to access a lower free energy pose or when the ligand is initially docked in a high energy pose, it can be expected that the choice of the binding site restraints will have a significant effect on the binding free energy estimate. However, in practice, alchemical binding free energy models are typically employed to identify binders and optimize the affinity of strong binders. Hence, it is often not critical to quantitatively pinpoint the binding free energies of weak and non-binders, as well as their dependence on the binding site definition.

\subsubsection{Changes in net charge can be challenging/problematic.}
\tocsubsubsectioncomment{@Chris Oostenbrink/ Vytas Gapsys to update.}
If the net charge of the system changes as the alchemical variable changes during the calculation, this can pose major challenges.
Specifically, finite-size effects can introduce significant charge-dependent artifacts into computed binding free energies, in part because typical schemes for long-range electrostatics, including particle mesh Ewald (PME) and reaction field, do not handle free energy contributions from such changes as they would be handled in a hypothetical macroscopic bulk solution. The outcome depends either on the size of the cutoff for reaction field methods or on the size of the simulation box when using lattice sum methods due to periodic boundary conditions~\cite{lin2014overview, ohlknecht2020correcting, rocklin2013calculating}.

Lattice summation methods (e.g. PME) effectively neutralize the simulation box by applying an implicit homogeneously distributed background counter charge~\cite{figueirido1995finite,hummer1996free}. The background charge can be interpreted as a converged distribution of counterions and may be a reasonable choice for computing hydration free energies of monovalent ions (finite size effect corrections can be applied in these cases)~\cite{hummer1996free}. In inhomogeneous systems with different dielectrics, e.g. solvated protein or lipid bilayer in a water box, assuming uniform background countercharge distribution is unphysical, as the higher countercharge density should be located in the regions of higher dielectric~\cite{hub2014pme}. This, in turn, causes significant artifacts in sampled population densities of charged molecules, i.e. errors in calculated free energy differences.

There are two main classes of approaches to address artefacts introduced by changes in net charge during alchemical free energy calculations: (1) avoiding changing the net charge altogether and (2) post-processing approaches to correct for artefacts using continuum electrostatics.
Many relative free energy planning tools have been set up to avoid changing the net charge of the systems considered, including LOMAP~\cite{liu2013lead} and Schr\"{o}dinger's FEP+~\cite{wang2015accurate}. In absolute free energy calculations, it is often difficult to avoid a change in the net charge. One way to avoid charge changes is to ensure that, as a charged ligand is removed, a charged counterion of opposite sign is also removed, or one of the same sign is inserted. This is sometimes referred to as a co-alchemical ion approach to deal with the required charge change. This approach is easily supported in most free energy calculating programs, as it merely involves an additional simultaneous modification.
There are special flavours of the co-alchemical ion approach such as proposed by Gapsys et al.~\cite{gapsys2015calculation}, which uses a double-system/single-box setup. Here, the two branches of a thermodynamic cycle as used in relative free energy calculations are placed in one simulation box, effectively circumventing a change in the overall net charge during a perturbation. Note that the co-alchemical approaches only avoid finite-size effects with lattice-sum methods such as PME.

Charge-change correction schemes have been explored and offer potentially viable solutions for the problem~\cite{mey2018impact}, where artifacts introduced by finite-size effects are corrected a posteriori from Poisson-Boltzmann calculations ~\cite{chen2018accurate, ohlknecht2020correcting, rocklin2013calculating,Reif2014chargecorrection}. However, application of such corrections is typically inconvenient and computationally demanding. High grid resolutions for the Poisson-Boltzmann calculations are required to avoid numerical artifacts, and it may be necessary to average over multiple representative configurations to obtain reliable results. Furthermore, they rely on continuum electrostatic models, which cannot fully capture phenomena arising from discrete solvent effects. These effects can be quantified in the orientational-disorder limit such that analytical correction terms for this effect exist for solvent models with a single van der Waals interaction site. Readers interested in these conceptual and technical limitations are referred to detailed analyses by Hnenberger and co-workers~\cite{kastenholz2006solvfe, rocklin2013calculating}.
Alternatively, Reif and Oostenbrink demonstrated in a proof-of-concept study that on-the-fly corrections to the physical forces can be effectively used to eliminate finite-size and approximate electrostatic artifacts~\cite{Reif2015onthefly}.

Petrov et al.~\cite{Petrov2024guidelines} investigated the box-size dependencies of alchemical free energy calculations using PME together with the co-alchemical ion approach. They concluded that in neutral simulation boxes with a minimal distance to the box wall larger than 1 nm, finite-size artifacts could be made negligible. The following recommendations should be followed to minimize finite-size artifacts, when using lattice-sum electrostatics: (a) setup of free energy calculations such that there is no net charge change whenever possible, (b) ensuring an overall neutral simulation box, (c) use of a sufficiently large distance between the solute and the box wall, at least 1 nm, and (d) use of salt if possible to screen finite-size periodicity artifacts~\cite{chen2018accurate}. In cases where these recommendations are not practical for specific applications, such as small simulation boxes or when reaction field methods are preferred, charge-change corrections may be applied to reduce artifacts. Though both post-processing corrections and the co-alchemical ion approach come at a cost of increased uncertainties. The Poisson-Boltzmann calculations are approximate due to finite-grid sizes and are applied only to a subset of the ensemble. Co-alchemical ion approaches introduce additional degrees of freedom and increase sampling requirements.

\subsubsection{Handling poorly sampled water networks}
The location of any water molecules within the binding site of interest must be determined prior to carrying out a free energy calculation. Experimental structures, such as those determined by X-ray crystallography and cryo-EM, are often sufficient for this, provided the resolution is good enough. However, we recommend using grand canonical sampling methods\cite{melling2023enhanced, samways2020grand} as a means of verifying the experimental water placement and determining any potential differences owing to the classical forcefield used. Many other water placement methods are available, all varying in their methodology, computational cost and accuracy. Details of these methods can be found in the publication from Samways et al.\cite{samways2021water}.

In relative binding free energy calculations, if the hydration patterns differ between the two ligand endpoints then careful consideration will need to be given to the adaptation of the water network during the free energy calculation. We recommend performing the free energy calculation in the conventional way, i.e. with no enhanced water sampling, to determine whether the water network can adapt to the ligand perturbation itself. This is likely to happen if the hydration site is not particularly occluded from bulk solvent and water molecules can move freely from bulk into the binding site. Similarly, performing calculations in both directions (i.e. using both endpoints as the starting structure) can aid understanding the effect of the water network on the estimated binding affinities. Replica exchange moves in lambda space, instigated from correctly equilibrated water distributions at the end points, may be sufficient to sample water distributions appropriately across a ligand perturbation.

If a conventional sampling method, such as molecular dynamics or Monte Carlo, is unable to rearrange the water network with sufficient efficacy to accommodate the perturbation, then an enhanced sampling method will be required to achieve accurate and converged results. One such approach is to include an absolute free energy calculation of the water molecule into the thermodynamic cycle\cite{ross2020enhancing, hamelberg2004standard, barillari2007classification, yu2008free, ge2022abfewat} such that the free energies of both the ligand transformation, and the decoupling of any displaced water molecules, are calculated separately and combined to achieve the total free energy change for the process. This method can be difficult to use in practice as the water molecule needs to be carefully restrained while being decoupled, and care needs to be taken to ensure water does not diffuse back into the hydration site as the water is decoupled.

Monte Carlo approaches such as the hybrid MC/MD approach proposed by Bergazin et al.\cite{bergazin2021enhancing, ben-shalom2021fast, ge2022enhancing} allow waters to move between bulk solvent and the binding site with greater frequency by proposing MC moves that translate the water molecules within a spherical region that encompasses both bulk solvent and the binding site. This avoids the difficulty of performing a decoupling calculation on the bound waters but can be time-consuming and risks computational time being wasted on move proposals that are not of interest.

Grand canonical (GC) methods propose the addition and removal of water molecules to and from a binding site in accordance with a defined chemical potential. Several implementations of GC moves being coupled to RBFE calculations exist, such as in Schrodinger's FEP+ package, introduced by Ross et al.\cite{ross2020enhancing} with moves proposed both within the binding site (to ensure the correct hydration pattern) and also within bulk solvent (to enhance the sampling of the bulk density). A cavity-bias technique was used for the binding site moves. Grand canonical alchemical perturbation (GCAP)\cite{brucemacdonald2018ligand} is also available in ProtoMS\cite{woods2018protoms}, whereby 2-dimensional titrations are performed in both lambda and chemical potential space. However, given ProtoMS only allows MC sampling to be performed, the configurational sampling of the protein is restricted.

More recently, an OpenMM-based implementation allows for GC moves to be carried out during both equilibrium and nonequilibrium (NES) RBFE calculations\cite{melling2025developing}. These moves are performed in the form of grand canonical nonequilibrium candidate Monte Carlo (GCNCMC) moves\cite{melling2023enhanced} and are run during the equilibration phase at each lambda window in the case of equilibrium FEP calculations, or during the nonequilibrium switch in the NES calculations.

Although often water sampling is less of an issue in ABFE calculations, handling changes to water networks in buried pockets during ligand coupling/decoupling can be addressed in a similar fashion to RBFEs with grand canonical methods.

% in ABFE calculations is less established, although in principle, the same rules apply. When conventional sampling of water is insufficient such that water does not efficiently bind during ligand decoupling, performing extra ABFE calculations for the removal or addition of water molecules to the thermodynamic cycle is one way of ensuring the contribution of these solvent effects is captured. Performing grand canonical water moves along side a more traditional ABFE calculation of a ligand will ensure that any changes to binding pocket hydration states are sampled \textit{in situ}.

Employing the techniques described above with care should allow the water network to adapt during the perturbation of the ligand, ensuring more accurate and converged affinity estimations that are independent of the starting configuration and direction in which the calculation is performed.

\subsubsection{The importance of the alchemical pathway
\label{sec:important_path}}
\begin{figure}
    \includegraphics[width=0.95\linewidth]{figures/fig7_what_is_lam/Figure.pdf}
    \caption{Alchemical intermediates are created by making the potential energy depend on an additional variable $\vec{\lambda}$ that interpolates between the chemical endpoints. In (\textbf{A}), at $\vec{\lambda}=0$ the molecule is a fully interacting phenol and at $\vec{\lambda}=1$,  a fully interacting benzene. (\textbf{B}) shows an illustration of the probability distribution of the potential energies as the switching function takes values of $\vec{\lambda}=0$ to $\vec{\lambda}=1$. Intermediates states are required for a sufficient overlap in potential energies to estimate a free energy difference between $\vec{\lambda}=0$ and $\vec{\lambda}=1$.
    Soft-core potentials provide one of the most efficient families of intermediate pathways, with a $\vec{\lambda}$ dependence. In (\textbf{C}) the potential energy surface is coloured according to $\vec{\lambda}$ with blue being $\vec{\lambda}=0$ and $\vec{\lambda}=1$ orange. In (\textbf{D}) the potential is coloured according to the potential energy. Note how as $\vec{\lambda}$ approaches 0, the energy smoothly approaches zero at all $r$, a necessary requirement for efficient and stable calculations.  }
    \label{fig:fig_what_is_lambda}
\end{figure}

Both absolute and relative calculations must choose an alchemical pathway connecting initial and final states. In principle, because of the path independence of the free energy, any arbitrary pathway will give the correct free energy change, but the choice of pathway will greatly affect the efficiency of the calculations. Some choices are particularly crucial---for example, transformations involving insertions or deletions of atoms should employ a soft-core potential path for Lennard-Jones or other interactions with repulsive interactions that go to infinite energy at small radius~\cite{beutler1994avoiding, beutler1994molecular,gapsys2012new}.

The key consideration for choosing alchemical pathways is that the intermediate states that a given pathway produces should sample configurational ensembles that change as slowly as possible as $\vec{\lambda}$ changes, while still managing to go from the initial state to the final state as $\vec{\lambda}$ goes from 0 to 1.

Another way of stating this is that intermediate states should sample molecular configurations that are as similar as possible to their neighboring states. The more similar the configurations are between intermediate states, the lower the statistical uncertainty is in the estimate of free energy between intervals. This can be proven directly from the BAR and MBAR formulas~\cite{bennett1976efficient,klimovich2015guidelines}, though the exact same principles apply for TI. For a 'good' path to work and give a sequence of states with maximally similar configurations, sufficient similarity in potential energies is required. Fig.~\ref{fig:fig_what_is_lambda}\textbf{A} and \textbf{B} illustrate this. Fig.~\ref{fig:fig_what_is_lambda}\textbf{A} shows in a pictorial way a soft-core potential can be applied across different $\vec{\lambda}$s. Fig.~\ref{fig:fig_what_is_lambda}\textbf{B} illustrates the potential energy distributions at the different $\vec{\lambda}$ intermediates, with sufficient overlap between neighboring $\vec{\lambda}$ states to ensure that reweighting estimators such as MBAR can be used for analysis (see Sec.~\ref{subsec:estimators}). The actual transformation is best handled with soft-core potentials of the form shown in Fig.~\ref{fig:fig_what_is_lambda} \textbf{C} and \textbf{B}, with more details given below. 

So what are the options to adjust the potentials between the two end states based on $\vec{\lambda}$? The simplest possible alchemical pathway is a \textit{linear} pathway:
\begin{equation}
U(\vec{q},\vec{\lambda}) = (1-\vec{\lambda}) U_0(\vec{q}) + \vec{\lambda}U_1(\vec{q}) \end{equation},

so-called because the dependence on $\vec{\lambda}$ is linear. This clearly satisfies the basic requirement that it gives the initial endpoint potential energy $U_0(\vec{q})$ when $\vec{\lambda}=0$ and final endpoint energy $U_1(\vec{q})$ when $\vec{\lambda}=1$. 

For many energy terms this is a very good approach, \textit{as long as a repulsive core remains on}. For example, it can be shown that if van der Waals repulsions are left on, then the linear approach is very nearly the optimal path possible for changing, removing, or inserting the electrostatic energy terms, with the alchemical path being within about 10--20\% of the minimum possible uncertainty~\cite{naden2015linear} for a fixed amount of simulation time, as well as being nearly optimally efficient for van der Waals attractive terms with repulsion terms turned on~\cite{naden2014linear}. Although we are not aware of any quantitative tests for dipolar or higher multipole terms, theoretically it should behave equally well for those systems.

However, this approach ends up being terrible for removing or adding repulsive potentials that go to infinity quickly at or near the origin. One way to look at this is to examine how low $\vec{\lambda}$ values must go to reduce the energy at $0.5\sigma$ (the atomic size parameter) down to 1 $k_BT$, where thermal fluctuations make it possible for other atomic sites to penetrate routinely that deep. Assume we are trying to go from a particle being present, and desire to make it disappear alchemically. If the repulsive terms are of the form $\epsilon(\frac{\sigma}{r})^{12}$, and if $\epsilon$ is 1 $k_BT$ at the temperature of interest, and we start with the particle present, we may solve for $(1-\vec{\lambda})(1 k_B T)\left(\frac{\sigma}{0.5\sigma}\right)^{12} = 1 k_B T$. This yields $\vec{\lambda} = 1-2^{-12} \sim 0.999976$. At this point,  we have gone virtually all the way to the end of the transformation, but there is still an impenetrable post in the middle of our simulation! This is not very much like the desired final state of no interactions between the particle and its environment. We can play around with a few ways of modifying this, like simulating many more intermediate states near $\vec{\lambda}=1$. However, various analyses have shown that this is not a very good strategy~\cite{pham2011identifying, beutler1994avoiding, zacharias1994separationshifted, blondel2004ensemble, gapsys2012new}.

What we need instead is a function that smoothly gets rid of this infinity. A large number of schemes have been tried~\cite{beutler1994avoiding, zacharias1994separationshifted, blondel2004ensemble, pham2011identifying, pham2012optimal, naden2014linear, donnini2005incorporating}, but the most common strategy that appears to be the best practice is to use a "soft-core" potential, of the form:

\begin{equation}
    U(\vec{r_{ij}},\vec{\lambda}) = 4\epsilon_{ij} \vec{\lambda} \left(\frac{1}{(\alpha(1-\vec{\lambda}) + (r_{ij}/\sigma_{ij})^6)^2} -  \frac{1}{\alpha(1-\vec{\lambda}) + (r_{ij}/\sigma_{ij})^6}\right)
    \label{eq:softcore},
\end{equation}

where $r_{ij}$ is the distance between two particles $i$ and $j$, $\epsilon_{ij}$ and $\sigma_{ij}$ are the Lennard-Jones parameters corresponding to the interaction between particles $i$ and $j$, and $\alpha$ is a constant. In particular, $\alpha=0.5$ is statistically optimal for the specific functional form shown above. This functional form has exactly the property we are looking for: it recovers the Lennard-Jones potential when $\vec{\lambda}=1$, and the at other endpoint ($\vec{\lambda}=0$), it is exactly zero for all $r_{ij}$ everywhere, and as $\vec{\lambda}$ goes to zero, the $\alpha(1-\vec{\lambda})$ term lowers the infinite energy in the core. There are several different variants of the same functional form~\cite{zacharias1994separationshifted, beutler1994avoiding,pham2011identifying}, but the one given in eq.~\ref{eq:softcore} is easy to understand and implement and fairly numerically stable. This functional form is shown in \textbf{C} and \textbf{D} of Fig.~\ref{fig:fig_what_is_lambda}.

It has been shown that more complicated forms are not significantly more efficient than eq.~\ref{eq:softcore}~\cite{pham2012optimal}. We therefore recommend using the soft-core potential given in eq.~\ref{eq:softcore}, unless there is a compelling reason otherwise. Using a similar equation to eq.~\ref{eq:softcore} may be acceptable in most circumstances if that is what is supported in your chosen software. However, if you are inserting or removing entire atomic sites, we heavily recommend against using the linear approach; it will be very difficult to get correct or converged results. 

So far in this section, we have discussed optimal ways of disappearing or appearing Lennard-Jones interaction sites and turning on and off electrostatics terms. What about performing both transformations at the same time? We cannot turn off the electrostatics linearly at the same time we turn off the Lennard-Jones terms, as it would leave infinitely large attractive and repulsive electrostatic terms "bare" at small $\vec{\lambda}$, resulting in the simulation crashing. It \textit{is} possible to apply the same soft-core approach to the Coulomb interaction as to the van der Waals interaction, and this is indeed done in a number of implementations. In this case, it is important that the Coulomb interaction is softened as rapidly or more rapidly than the Lennard-Jones interaction to avoid charge penetration issues into the repulsive core, which  can be tricky to ensure for multiple types of perturbations simultaneously~\cite{steinbrecher2011softcore}. 

A safe but potentially more computationally expensive approach is to perform the transformations in sequence; first, turning off all electrostatics for atoms that must be removed, inserting and removing Lennard-Jones sites (both the insertion and removal can be done simultaneously), and then turning electrostatics for the introduced particles on. Again, if there are no removals or additions to atomic sites, then it is reasonable to change the interactions in the first and third steps  linearly. 

Other issues, such as whether absolute calculations should retain or remove intramolecular non-bonded interactions
through either annihilation~\cite{hermans1997inclusion, mann2000modeling, boresch2003absolute, wang2006absolute, mobley2006use} or decoupling~\cite{fujitani2005direct, mobley2006use}, must be considered. Reasonable efficiency can be often obtained with either choice even if some are somewhat better or worse than others, and there is no consensus on which is better in most given situations. Our recommendation is to leave the intramolecular interactions on during the transformation for simplicity if there are no other known issues with this approach. The key feature of the simulation to watch out for is whether the total potential energy, and therefore the intermediate ensembles sampled, changes smoothly from beginning to end. Problems of discontinuous changes of the potential energy can be diagnosed by noticing lack of configuration space overlap between different simulations (see Sec.~\ref{sec:are-they-good}).

Relative calculations introduce additional choices, such as the order in which to modify nonbonded interactions.
A common process in single topology relative calculations is, as noted above, to first remove electrostatic interactions of any atoms which will be deleted, then modify other non-bonded interactions, then restore electrostatic interactions of any atoms which are being inserted. Although this is a simpler path to understand cognitively and can take advantage of the soft-core potential from Eq.~\ref{eq:softcore}, this can lead to more intermediate steps and thus be more computationally expensive.
Other schemes, such as simultaneously changing electrostatic and Lennard-Jones interactions with electrostatic soft-core potentials~\cite{steinbrecher2007nonlinear}, as already discussed above, may be implemented with fewer intermediate states but could require fine-tuning of electrostatic and Lennard-Jones soft-core parameters to avoid numerical instabilities. 
At the time of writing, there has not been conclusive evidence to suggest the separate or simultaneous approach is in general better than the other, all factors considered, so discretion should be left up to the user as to what is viable from both hardware resources, and what the simulation software supports.

A key additional consideration in choosing the alchemical pathway is the choice of spacing of intermediate states.
The spacing depends to some extent on the choice of analysis method, though states should essentially be spaced equidistant in the relevant thermodynamic length~\cite{crooks2007measuring, sivak2012thermodynamic}.
For BAR/MBAR techniques this means that states should be spaced so that the statistical uncertainties between neighboring states be approximately equal~\cite{pham2012optimal, shenfeld2009minimizing}, where "approximately" is roughly within 30-50\% in magnitude. 
Some schemes to adaptively optimize the spacing of intermediate states based on initial exploratory simulations have been proposed~\cite{hayes2017adaptive}. For molecules changing in dense solvent, then the best path is roughly independent of molecule size and shape, so what works for one molecular transformation is likely to be relatively efficient for another~\cite{monroe2014converging}.


Some approaches have attempted to find alternative pathways to improve efficiency or find paths of low thermodynamic length~\cite{naden2014linear,naden2015linear,pham2012optimal}. For example, the enveloping distribution sampling (EDS) approach, and its multiple-replica and accelerated variant, works to improve efficiency by creating a single artificial intermediate state which simultaneously samples all end state phase spaces~\cite{perthold2018accelerated,sidler2017efficient, christ2007enveloping}. When this can be done, it provides an extremely efficient way to calculate the relative free energy difference between multiple ligands from a single simulation. However, it can often fail whenever the simulation of this intermediate state ends up trapped in configurations characteristic of only one end state. Thus, successful use of EDS can require system-dependent tuning, making it difficult to implement in an automated and reliable way. However, when successful, it can be very efficient.

In our view, there is still some room for further exploration of how to best choose transformation pathways, especially for relative binding calculations or more complex molecules, as most existing studies focus on smaller molecules. As we have stressed, in principle, any pathway that connects the desired end states is rigorously correct, but as discussed above, different paths may differ dramatically in thermodynamic length and therefore efficiency. Additionally, some paths simply may not converge due to issues noted above such as those encountered without soft core potentials. However, the recommendations above are reasonable, reliable, and are likely not that much less efficient than potentially more optimal choices~\cite{naden2014linear,naden2015linear,pham2012optimal}, as the real problems with the efficiency of calculating free energies are lack of sampling of slow conformational modes, rather than the lack of efficiency of the transformations. 

It is however important to note that different packages also differ in how they handle implementation of alchemical transformations, making it difficult to give rules of thumb concerning specific efficient transformations which work equally well across simulation packages. Thus, we are hesitant to recommend best practices within specific software packages at this point in time, although any good transformation pathway will conform to the guidelines we have outlined above.

\subsubsection{The importance of configurational sampling}
\label{sec:configurational_sampling}
As mentioned previously, free energy differences estimated from alchemical calculations should be independent of the initial system conformation, given sufficient configurational sampling. In cases where the system's slowest degrees of freedom are coupled with the alchemical variable, transitioning between alchemical states can indirectly enhance configurational sampling. This effect is particularly pronounced when certain alchemical states lack the energy barriers present at the fully coupled state (e.g. $\lambda=0$ in Fig. ~\ref{fig:configurational_sampling}\textbf{A}), thereby allowing the system to bypass otherwise prohibitive configurational free energy barriers. For example, in a protein-ligand unbinding process where the kinetic barrier is predominantly associated with the disruption of intermolecular interactions or the separation of binding partners, simulating different intermediate states effectively samples configurations with varying center-of-mass distances, thus mitigating the sampling issue in the configurational space. 

Conversely, when the slowest degrees of freedom in the configurational space are largely orthogonal to the alchemical variable, the system can be stuck in its initial metastable state. Such entrapment leads to discrepancies in free energy estimates from simulations initiated from different conformations. This scenario, as illustrated in Fig.~\ref{fig:configurational_sampling}\textbf{B}, is not uncommon especially in flexible systems. For example, it can arise when the free energy difference of interest needs to account for metastable states separated by torsional barriers, such as the solvation free energy of a ligand having different rotamer states, the methylation free energy of a nucleobase in a duplex ~\cite{hsu2023alchemical}, and the binding free energy that involves flexible side chains near the binding site~\cite{la2022alchemical}. Similar sampling challenges have also been reflected in several recent studies, which highlights the sensitivity of alchemical calculations to initial conformations, whether derived from crystallographic structures~\cite{suruzhon2021sensitivity, baumann2024impact} or docking protocols~\cite{cappel2020impact}. 

Similarly, Fig.~\ref{fig:configurational_sampling}\textbf{C} highlights the importance of configurational sampling in alchemical calculations, where a free energy basin spans both the alchemical and configurational coordinates, potentially trapping the system in both dimensions. This can occur, for instance, when electrostatic interactions are turned off while van der Waals interactions remain, rendering the alchemically transformed molecule a ``greasy ball''. Notably, in cases where alchemical biases/weights are applied to facilitate even alchemical sampling across states, such as in an expanded ensemble simulation~\cite{lyubartsev1992new}, scenario Fig.~\ref{fig:configurational_sampling}\textbf{C} may evolve toward scenario Fig.~\ref{fig:configurational_sampling}\textbf{B} as the alchemical free energy profile is flattened out, while the basin in the configurational direction persists. 

There are multiple strategies to alleviate such sampling challenges in an alchemical calculation. A straightforward but computationally expensive method is to run longer simulations with multiple replicates to increase conformational heterogeneity~\cite{suruzhon2021sensitivity}. Another approach involves performing separate alchemical calculations from different metastable states, then computing the overall free energy difference as the negative log-sum-exp of the Boltzmann weights from each metastable state~\cite{hsu2023alchemical}. However, this method is only applicable to cases like Fig.~\ref{fig:configurational_sampling}\textbf{B}, where the system remains trapped in its initial metastable state throughout the calculation. A generally more effective strategy is to bias relevant configurational collective variables (CVs) during the alchemical simulation. This can be achieved by enhancing sampling within individual alchemical states and swapping conformations between alchemical states (preferably from different metastable states) via replica exchange protocols. More recently, several approaches have been proposed to simultaneously bias both configurational CV and alchemical variables, which can effectively address both scenarios Fig.~\ref{fig:configurational_sampling}\textbf{B} and \textbf{C}. Examples include alchemical metadynamics~\cite{hsu2023alchemical}, $\lambda$-ABF (adaptive biasing force)~\cite{lagardere2024lambda} and its combination~\cite{zhou2025zooming} with well-tempered metadynamics~\cite{barducci2008well}, to name a few.  

Notably, detecting and addressing configurational sampling challenges in alchemical calculations remains a non-trivial task. In relative free energy calculations, large cycle closure errors are commonly used as indicators of insufficient sampling, although small errors do not necessarily imply that sampling is adequate~\cite{suruzhon2021sensitivity}. In other types of calculations, diagnosing sampling deficiencies typically requires prior knowledge of relevant metastable states, as well as collective variables that distinguish them. Such collective variables are often based on physical intuition, experimental insights, or preliminary computational analyses. However, optimal collective variables arerarely known \textit{a priori}, complicating the systematic detection of sampling issues. Although recent ad-hoc machine learning methods for optimal CV identification have shown promise~\cite{gokdemir2025machine, sidky2020machine, bonati2021deep} and could in principle be straightforwardly integrated into alchemical sampling protocols, systematic studies explicitly demonstrating such integration have yet to appear. Consequently, widely accepted best practices about automated diagnostic protocols capable of identifying and resolving configurational sampling bottlenecks have not yet been established. 

\begin{figure}
    % Figure to be updated
    \includegraphics[width=0.88\columnwidth]{paper/figures/fig_configurational_sampling/FES_scenarios_path.pdf}
    \caption{\textbf{Different scenarios of free energy surfaces.} In scenario \textbf{A}, the free energy barrier present at $\lambda=0$ is absent at other $\lambda$ states, so the system can go around the barrier by alternating sampling between alchemical and configurational space, e.g. via the path shown as the dashed line. In contrast, in scenario \textbf{B}, the free energy barrier extending all alchemical states prevents the system from sampling both metastable states at $\lambda=0$. In scenario \textbf{C}, the free energy basin extending in both alchemical and configurational directions can trap the system.}
    \label{fig:configurational_sampling}
\end{figure} 


\subsubsection{Which sampling scheme will work best for my problem?}
\label{sec:sampling_schemes}
Though all alchemical simulations must sample from multiple $\vec{\lambda}$ states, different approaches can be used to achieve this. Fig.~\ref{fig:fig_sampling_scheme} illustrates the four most common schemes. The simplest approach involves running an independent simulation at each of the predefined $\vec{\lambda}$ values (see Fig.~\ref{fig:fig_sampling_scheme}\textbf{A}). This type of scheme is currently used for AMBER TI calculations~\cite{song2019using} and for Sire as implemented in BioSimSpace~\cite{hedges2019biosimspace}. However, if these simulations can be run simultaneously with communication between them, a simple extension allows mixing between these replicas. In this approach, the simulation at each $\vec{\lambda}$ can undergo periodic exchanges with neighboring $\vec{\lambda}$ values. This form of replica exchange, called Hamiltonian replica exchange, is based on ideas developed from Monte Carlo simulations of spin glasses by Swendsen and Wang~\cite{swendsen1986replica}. With the Metropolis-Hastings acceptance criterion for exchanges, the generated ensemble of all replicas still samples from the Boltzmann distribution for each replica. This approach has been used in many different contexts for molecular simulations~\cite{sugita2000multidimensional,sugita1999replicaexchange, woods2003development, jiang2010free}. The basic idea of the replica exchange scheme is shown in Fig.~\ref{fig:fig_sampling_scheme}\textbf{B}. It is supported in various software packages that provide alchemical implementations, such as GROMACS~\cite{aldeghi2015accurate}, GROMOS~\cite{hritz2008hamiltonian,hritz2007optimization}, FEP+~\cite{wang2015accurate}, and NAMD~\cite{jiang2019computing}. 

A third approach borrows ideas from simulated tempering~\cite{marinari1992simulated}. In this scheme a single replica rapidly explores all of $\vec{\lambda}$ space by working out optimal weights that allow switching between different intermediate $\vec{\lambda}$ values, as seen in Fig.~\ref{fig:fig_sampling_scheme}\textbf{C} . This approach is also referred to as self-adjusted mixture sampling~\cite{lyubartsev1992new, li2007simulated, tan2017optimally} and while promising, has so far only been supported in OpenMM Tools~\cite{andrearizzi2019choderalab} and GROMACS.  Although this approach allows multiple states to be simulated in a single simulation, the weights do not always converge to the proper equilibrium distribution, and care must be taken that the final results are converged. 

The non-equilibrium switching (Fig.~\ref{fig:fig_sampling_scheme}\textbf{D}) approach makes use of short out-of-equilibrium simulations~\cite{aldeghi2018accurate}. In this protocol, only end state $\vec{\lambda}$ replicas ($\vec{\lambda}$=0, $\vec{\lambda}=1$) are simulated at equilibrium; intermediate information is generated from non-equilibrium simulations that rapidly transition between end states. 
Over the course of each transition, Hamiltonian derivative with respect to $\lambda$ is recorded; subsequently the curves are integrated to yield work distributions for the forward and reverse processes. Crooks Fluctuation Theorem~\cite{crooks1999entropy} allows estimating free energy difference between the end states from the generated work distributions.~\cite{shirts2003equilibrium}

The non-equilibrium (NEQ) approaches offer some advantages over the equilibrium sampling based methods. For example, the NEQ protocol allows equilibrium simulations of each end-state to be performed independently without pre-defining ligand network: the transitions between the ligands can be generated afterwards. This eliminates the redundant equilibrium sampling, e.g. in a starmap network, FEP based approaches would require sampling the central ligand for each edge, while NEQ would sample it once and connect to the other ligands afterwards. The NEQ protocol also provides flexibility in combining different structures in free energy calculations, e.g. simulations in states at $\lambda=0$ and $\lambda=1$ may be initialized with the independently generated ligand coordinates. Another example would be using true apo and holo protein structures as the end states to initialize simulations for absolute binding free energy calculations. 

The non-equilibrium approach is available in GROMACS and Amber. A closely related method, termed non-equilibrium cycling, is available in OpenMM. Among the commercial packages, it is implemented in OpenEye's Orion{\textregistered}~\cite{sorensen2024orion} platform.
%A schematic of this approach is shown in Fig.~\ref{fig:fig_sampling_scheme}\textbf{D}. 

\begin{figure}
    \includegraphics[width=0.88\columnwidth]{figures/fig8_sampl_scheme/Figure.pdf}
    \caption{\textbf{Four most common sampling strategies.} (\textbf{A}): Multiple replicas in parallel at different lambda states. Each arrow symbolises an independent $\vec{\lambda}$ simulation. (\textbf{B}): Hamiltonian replica exchange scheme. Each arrow represents a short simulation interval before an exchange through Metropolis Hastings acceptance (dice) is attempted. A tick means an accepted exchange, a cross a rejected exchange. (\textbf{C}): Single replica scheme sampling from all $\vec{\lambda}$ states. After a short simulation time symbolised by the arrow, the lambda-state is attempted to change until all N lambda states will be sampled. (\textbf{D}): Non-equilibrium sampling scheme, where two equilibrium simulations at the end states are run as indicated by the blue and pink arrow. Non-equilibrium simulations are attempted at intervals to switch between the two end states.}
    \label{fig:fig_sampling_scheme}
\end{figure} 

Currently, we recommend using Hamiltonian replica exchange type sampling schemes (Fig.~\ref{fig:fig_sampling_scheme} \textbf{B}). If these are not available in the code of choice, running independent simulations at different $\vec{\lambda}$ values can be acceptable, especially when configurational sampling is fast (Fig.~\ref{fig:fig_sampling_scheme} \textbf{A}). Single replica schemes and non-equilibrium schemes are not as established yet because of potential failure modes, but are very promising for use in the near future. 


\subsubsection{How long should I run my simulation for and what information should be saved?}
\label{sec:sim_length_information_kept}
Before launching alchemical free energy calculations it is wise to consider how convergence and completion will be assessed. Different conditions on when to stop alchemical free energy calculations should be determined, and this may require several iterative checks and therefore modifications to the calculation protocol.
One useful metric to use for termination is the expected or desired uncertainty of a desired free energy estimate, though care must be exercised should the uncertainty estimate prove unreliable.
In particular, if the rate of change in the free energy estimate is significant when this condition is met, the simulation may not be locally converged, and more sampling may be necessary to determine a stable free energy estimate which is no longer changing significantly over time. 


However, this is not the only metric which can or should be used, as the uncertainty only captures the information about the sampled phase space, not necessarily the entirety of the phase space.  
For example, convergence of relative free energy calculations in predictive simulations where the entire phase space is not known in advance, requires sampling the different kinetically stable states~\cite{mobley2012perspective}. 
This highlights the importance of choosing the correct thermodynamic path to ensure you sample the required thermodynamic states as discussed in Sec.~\ref{sec:important_path}.

The condition of minimizing the statistical uncertainty of different free energy estimators below a sufficient threshold should be one metric monitored over the simulation. This can be done through the uncertainty estimator built into certain analysis tools such as MBAR, or through more general statistical tools like bootstrap sampling. It should be noted however, that uncertainty estimates have the same limitations as other metrics of convergence, as they are only an uncertainty based on the phase space sampled so far in a simulation, and cannot account for states not sampled, and it is worth considering that they will be an underestimation of the true uncertainty.
A target statistical uncertainty should be chosen at the onset of the simulation to avoid excessively long simulations, or falling into the trap of running until the free energy estimate is "good enough," which is subjective and has no defined criteria. This could be a fixed value such as $0.20$ kcal/mol, or a functional quantity such as "below $0.5$ kcal/mol and $10\%$ of the free energy estimate." The user does not need to monitor this information in real-time and can choose to run simulations for fixed duration (either time or number of samples) and run analysis on the data collected thus far. If more samples are needed, the simulations can be resumed, or, started again in different initial conditions. 

Convergence in other alchemical observables should also be monitored to determine if the defined phase space has been sufficiently sampled and enough decorrelated samples have been drawn. These additional observables include, but are not limited to, the variance in $\frac{dU}{d\vec{\lambda}}$ across all $\vec{\lambda}$ values, calculating the variance in free energy using bootstrap analysis, and comparing differences in free energies calculated using different percentages of the simulation in both the forward and reverse directions~\cite{klimovich2015guidelines} (see Fig.~\ref{fig:convergence_forward_reverse}).

\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{figures/fig10_forward_reverse/Figure.pdf}
    \caption{\textbf{Free energy (in $k_{B}T$) for two different relative binding free energy perturbations.} 
    Each plot shows the estimated free energy change using a varying fraction of total simulation time (up to 5 ns total). 
    Subplots (\textbf{A}), (\textbf{C}), and (\textbf{E}) show a three step protocol for a perturbation involving 3 perturbed atoms, while (\textbf{B}), (\textbf{D}), and (\textbf{F}) shows the same protocol for a perturbation involving 10 perturbed atoms. The first step of the protocol is the decharging then removing van der Waals interactions and then recharging. The difference in energy between the forward (blue) and reverse (red) free energy calculations at the midpoint of the simulation time gives an indication of the overall convergence of the simulation, with differences over 1 $k_{B}T$ indicating poor convergence.}
    \label{fig:convergence_forward_reverse}
\end{figure}

Each of these metrics shows some promise for diagnosing when a simulation has a convergence issue beyond simple convergence of uncertainty estimates. 
Results obtained from calculations with convergence issues should be checked for errors or run for longer before any confidence should be placed in conclusions drawn from their analysis.
For example, in relative calculations ligands that share similar binding modes and do not induce large conformational changes when in complex with protein, the need to sample exhaustively to converge estimates in free energy differences is often minimal due to the locality of sampling changes in the molecular topology and shared phase space of the core atoms.
However, even subtle induced changes in protein binding configuration will require more sampling or cause local convergence to a free energy estimate that has high error.
The confidence a user should have in a free energy estimate is significantly improved when both the uncertainty of the free energy estimate is low, and when other observables have reached a convergence.

\begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{figures/fig_pmf/pmf.png}
    \caption{{\bf Potential of mean force with respect to $\vec{\lambda}$ for TI and MBAR}
    The estimated PMF for a bound calculation of a Tyk2 ligand pair of Wang et al.~\cite{wang2015accurate} with respect to $\vec{\lambda}$ estimated from TI and MBAR and showing agreement within errorbars. 
    }
    \label{fig:pmf}
\end{figure}

The uncertainty in the free energy, for example, can be estimated in multiple ways, e.g. through standard error propagation methods (including MBAR's estimator, which is based on the same principles as standard error propagation), through bootstrap methods, and through multiple independent runs. 
Independent of how the property is estimated, it is important to remember that results of any free energy analysis are \textit{estimations of the given property}, not the true underlying value of the property itself. 
These estimators are usually consistent estimators, meaning they will converge to the true answer in the limit of sufficient sampling, not necessarily unbiased ones though.
As such, it is a good idea to subject different estimators to the same data to see if they yield either the same estimate (within error and bias), or if they fluctuate wildly. See, for example, the potential of mean force with respect to $\vec{\lambda}$ estimated from a bound simulation of a Tyk2 ligand pair of Wang et al.~\cite{wang2015accurate} for both the MBAR and TI estimators, as seen in Fig.~\ref{fig:pmf}.
This is not a perfect method as some estimators, such as exponential averaging, will converge significantly more slowly, relative to more accurate estimators like MBAR. 
Therefore, it is a good idea to apply the estimators to different fractions of the data to see if the main estimator of free energy you have chosen is stable.

Each method requires different data from the simulation be collected. If, for instance, the free energy estimator selected is thermodynamic integration, then values of $\frac{dU}{d\vec{\lambda}}$ at uncorrelated data points must be collected. Once you have made a choice of the combination of the type of simulation you will run, which alchemical topology you will simulate, what alchemical path you will simulate along, and what your stopping conditions are, then you are ready to enumerate the information you should capture. Below is a sample of the minimal information you need for a set of common estimators (discussed in more detail in Sec.~\ref{subsec:estimators}):

\begin{itemize}
    \item Thermodynamic Integration (TI) requires $\frac{\partial u(\vec{q})}{\partial\vec{\lambda}}$.
    \item Exponential Averaging (EXP) needs \textit{either} $\Delta u_{k,k+1}(\vec{q})$ or $\Delta u_{k,k-1}(\vec{q})$, depending on the direction its being evaluated in.
    \item Bennett Acceptance Ratio (BAR) needs \textit{both} $\Delta u_{k,k+1}(\vec{q})$ and $\Delta u_{k,k-1}(\vec{q})$.
    \item Weighted Histogram Analysis Method (WHAM) and Multistate Bennett Acceptance Ratio (MBAR) both need the complete set of $\Delta u_{k,j} \, \forall \, j=\{1...K\}$. WHAM must have this same information binned with some choice of bin width small enough not to affect the results.
\end{itemize}

The potential derivative required for TI should generally be calculated during the simulation; only under very rare circumstances~\cite{naden2015linear} can it post-processed by a code that does not evaluate the derivatives. Many codes already have options for doing this.
If that option is unavailable, you can estimate it through finite difference (if sufficient information is collected), but this will introduce significant error, and is generally not a best practice. The BAR estimator may be a better, and simpler choice at that point as you will have at least the same level of information. 

The potential energy differences required for EXP, BAR, MBAR, and WHAM can be calculated either during the simulation or in post-processing. It is recommended to calculate the potential differences in code when possible to avoid extra overhead and possible errors produced by evaluating the energy of the configuration twice, and to reduce the amount of stored information. 
Although potential energy derivatives must usually be calculated in code there is one condition under which they can be easily computed in post-simulation analysis. 
If the alchemical path you have chosen is a linear alchemical path, then $\frac{du}{d\vec{\lambda}} = u_0(\vec{q}) - u_1(\vec{q})$, which is the difference between the initial and final states, which are already calculated by the simulation and can be recorded easily without additional computational expense. 
However, because of the problems with linear paths already discussed in this paper, this simplification is rarely that useful.


Free energy information should generally be saved more frequently than coordinate data, approximately at the rate that uncorrelated samples are produced.  
The on-disk size of the data for free energy estimation is often significantly smaller than full atomic coordinates, so the information can easily be collected frequently. 
However, the information should not be collected \textit{every} time step, as most free energy techniques are operated at equilibrium, and need equilibrated \textit{and decorrelated} samples for an unbiased estimate.
Samples collected every time step will likely result in most samples being discarded due to the detection of correlation in the time series by decorrelation routines in the analysis. However, if it is computationally cheap and disk space is plentiful, do save often. One may safely assume that the correlation time is greater than 100-200 fs even for relatively simple systems such as small molecules in solvent, so saving no more frequently than every 50-100 steps is recommended. 
How decorrelation impacts calculations, and how to compute it is discussed in Sec.~\ref{sec:decorrelating-samples}.

In general, uncertainties can be assumed to decrease as $1/\sqrt(N)$ where $N$ is the number of uncorrelated samples, for all standard free energy calculation methods~\cite{shirts2005comparison}. However, this carries the notable caveat that such estimates require accurate estimation of the correlation time which, if important motions are slow compared to simulation timescales, can be difficult. Still, this metric provides a good rule of thumb, and as long as conformational transitions are captured by the simulation, increasing the aggregate simulation time by a factor of $T$ will reduce the uncertainty by a factor of approximately $\sqrt{T}$.

\subsubsection{Multiple or uncertain binding modes may require considerable care}
\tocsubsubsectioncomment{@Michael Shirts to update discussion of treatment of multiple binding poses.}
\label{sec:multiple_binding_modes}
In a discovery setting, new ligands can have unknown or at least uncertain binding modes~\cite{kaus2015how, plountprice2000analysis,mobley2009binding,calabro2016elucidation}, complicating binding free energy estimation.

To deal with prospective ligands with unknown binding modes, discovery projects commonly assume that modifications of functional groups on a common scaffold result in a consistent binding mode across all members of a series.
This is not necessarily always the case~\cite{kaus2015how}, as reviewed elsewhere~\cite{mobley2009binding} and in some cases unexpected binding mode changes can be the origin of apparent non-additivity in structure-activity relationships~\cite{calabro2016elucidation}.
Binding modes also tend to be particularly variable in the case of fragments, which often may have multiple relevant binding modes~\cite{steinbrecher2015accurate}.


Absolute free energy calculations for dissimilar ligands can have particular challenges because the (potentially incorrect) assumption of consistent binding modes across a series of similar ligands is likely to be even less robust than in the case of relative calculations.
This means that researchers performing absolute binding free energy calculations will have to pay particular attention to generating reasonable putative binding modes.

In some cases, it is tempting to simply use docking techniques to generate initial bound structures for starting molecular dynamics simulations.
However, timescales for binding mode interconversion are usually slow compared to MD/free energy timescales, meaning that simulations started from different potential binding modes are likely to yield disparate computed binding free energies~\cite{mobley2006use, palma2012computation, mobley2012perspective, gill2018binding}. Moreover, docking techniques are good at identifying sterically reasonable potential binding modes, but still perform relatively poorly at identifying a single dominant binding mode \emph{a priori}. 


It is worth highlighting a recent SAMPL blind challenge on HIV integrase as an illustration of this. 
Many submissions, using state-of-the-art methods, had difficulty even predicting which \emph{binding site} ligands would bind in---most submissions placed more than half of the ligands into the incorrect binding site---and even given correct binding sites, the binding mode within each site was also quite difficult to predict~\cite{mobley2014blind}.
The best performing submission for predicting binding modes actually ended up being a human expert (aided by computational tools) with more than 10 years of experience on the particular target~\cite{voet2014combining}, rather than a fully automated approach.
While free energy calculations on this set had some success, many of the failures actually ended up being cases where the binding mode selected as input for free energy calculations was later found to be incorrect~\cite{gallicchio2014virtual}, highlighting the importance of these issues.

One approach which has shown some success in identifying accurate binding modes \emph{de novo} is to retain diverse potential binding modes from docking, perform short MD simulations of these to identify distinct stable binding modes, and then consider only these stable modes in subsequent calculations~\cite{gallicchio2014virtual, mobley2006use,rocklin2013blind, boyce2009predicting, mobley2007predicting}.


Routes to handle multiple potential binding modes are different depending on whether absolute or relative calculations are selected, unless a method is available to estimate the relative populations of different stable binding modes in advance (e.g. such as the BLUES approach currently in development~\cite{gill2018binding}), in which case this approach could be applied to assist both types of calculations.

\paragraph{Handling multiple potential binding modes within absolute calculations.}
Within absolute binding free energy calculations, multiple potential binding modes can be handled by two main strategies: Considering each binding mode separately (a separation of states strategy) or sampling all binding modes within a single simulation~\cite{mobley2012perspective}.
This couples to the choice of restraints selected, as some restraints will allow transitions between binding modes and even binding sites (Sec.~\ref{sec:standardstate-restraints}), and others do not.

Sampling all potential ligand binding modes within a single free energy calculation is usually impractical without some form of enhanced sampling or at least Hamiltonian replica exchange~\cite{wang2013identifying} because barriers for binding mode interconversion result in kinetics which are too slow compared to simulation timescales~\cite{mobley2006use, palma2012computation,mobley2012perspective, gill2018binding}.
Hamiltonian exchange, coupled with appropriate restraints, can allow the ligand to relatively rapidly exchange between potential binding modes when non-interacting, accelerating sampling of binding modes~\cite{wang2013identifying}. However, it is not always clear that this is desirable, since this also increases the size of the configuration space which must be sampled even if the binding mode is known.

Separation of states provides a simple though potentially expensive alternative, where each stable binding mode is considered separately with a binding free energy calculation restricted to that binding mode, and then (as long as the binding modes are non-overlapping) the resulting component binding free energies can be combined into a total~\cite{mobley2006use, mobley2012perspective}.
This approach necessitates a separate binding free energy calculation for each potential binding mode, however, so it can be computationally quite costly.
If relative populations of different stable binding modes were available from some other technique, it could make this separation of states approach considerably more efficient~\cite{mobley2012perspective, gill2018binding}.

\paragraph{Handling multiple potential binding modes within relative calculations.}
Multiple potential binding modes pose particular problems for relative free energy calculations, as having multiple starting structures for these calculations could yield substantially different calculated relative binding free energies for the same transformation due to kinetic trapping, and, without additional information (specifically, the free energy of binding mode interconversion or, equivalently, the relative populations of different binding modes) it becomes impossible to sort out which of the multiple answers is in fact the correct relative binding free energy.

To deal with this, some practitioners have actually computed relative binding free energies of different binding modes of the same ligand~\cite{palma2012computation}.
For example, a perturbation which adds a methyl to an aromatic ring of a larger ligand might yield one result if the methyl points in one direction, and a different value if it points in the other due to slow ring motions~\cite{lincoff2016comparing, sasmal2020sampling}.
One could compute the free energy of turning off the methyl group in one orientation and turning it back on in the other orientation to obtain the free energy difference between the two potential binding modes.
While this approach has precedent, it is relatively difficult to automate at present and requires considerable care.

Overall, this likely means that relative free energy calculations will be susceptible to problems resulting from uncertainty in ligand binding modes until more robust approaches are available to determine dominant binding modes, or the relative populations of different potential binding modes, in advance.

\subsection{Absolute and Relative Binding Free Energies with Multiple Chemical States}

Consider, as an illustration, the binding equilibrium between a receptor $R$ and a ligand $A$ that exists in solution as a mixture of protonated $AH$ and ionized $A^-$ forms. It is often useful to consider the observed equilibrium binding constant between $R$ and the $A$ mixture 
\begin{equation}
  K_b(A) = C^\circ \frac{[RA]}{[R][A]}
  \label{eqn:observed-binding-constant}
\end{equation}
where $[A] = [AH] + [A^-]$ and $[RA] = [RAH] + [RA^-]$ are the total equilibrium concentrations of free $A$ and receptor-ligand complexes. The observed equilibrium constant is significant because it corresponds to binding affinity measurements that do not distinguish between the protonation states of the ligand. Inserting the definitions of $[A]$ and $[RA]$ in Eq.~(\ref{eqn:observed-binding-constant}), splitting the sum in the numerator, and multiplying and dividing each term by either $[AH]$ or $[A^-]$ we obtain
\begin{equation}
  K_b(A) = \frac{[AH]}{[A]}  K_b(AH) +  \frac{[A^-]}{[A]} K_b(A^-) =  p_0(AH) K_b(AH) +  p_0(A-) K_b(A^-)
  \label{eqn:observed-binding-constant-split}
\end{equation}
where
\begin{equation}
  K_b(AH) = C^\circ \frac{[RAH]}{[R][AH]}
  \label{eqn:observed-binding-constant-prot}
\end{equation}
is the specific equilibrium binding constant between the receptor and the protonated form of the ligand, and similarly for $K_b(A^-)$. The specific $K_b$'s are the binding constants that would be obtained from ABFE calculations for those species. Eq.~(\ref{eqn:observed-binding-constant-prot}) states that the observed binding constant is an average of the specific binding constants weighted by the populations, $p_0(AH)$ and  $p_0(A^-)$ of each ligand's chemical form in solution. In this specific example, if the $pKa$ of $AH$ is known and $\alpha = [A^-]/[AH] = 10^{pH-pKa} $ is the ionization ratio of $A$ at a a given $pH$, the populations of the ionized and protonated forms are $p_0(A^-) = \alpha/(\alpha+1)$ and $p_0(AH) = 1/(\alpha+1)$, respectively.\cite{champion2024multistate,azimi2022application}

Eq.~(\ref{eqn:observed-binding-constant-split}) is a particular case of a fundamental result that extends to an arbitrary number of chemical forms of a ligand in solution. In general, the observed binding constant of a ligand present in solution in multiple forms $A_i$ (protomers, tautomers, rotamers, etc.) with populations $p_0(A_i)$ is\cite{khuttan2023taming}
\begin{equation}
  K_b(A) = \sum_i p_0(A_i) K_b(A_i)
  \label{eqn:observed-binding-constant-general}
\end{equation}
and the corresponding standard binding free energy is
\begin{equation}
 \Delta G^\circ_b(A) = -k_B T \ln K_b(A) = -k_B T \ln \sum_i p_0(A_i) e^{-\Delta G^\circ_b(A_i)/k_B T}
  \label{eqn:observed-binding-free-energy-general}
\end{equation}
where
\begin{equation}
\Delta G^\circ_b(A_i) = -k_B T \ln K_b(A_i)
\end{equation}
is the standard binding free energy of the specific form $A_i$. Eq.~(\ref{eqn:observed-binding-constant-general}) is known as the free energy combination formula, which, in the case of multiple conformational states, can be derived directly from the statistical mechanics definition Eq.~(\ref{eq:DG0-binding-constant-def}).\cite{jayachandran2006parallelized,gallicchio2011recent} It states that the contribution of a chemical or conformational state of the ligand to the observed binding free energy depends on the specific binding free energy of that state and its solution population. A state with a strong specific binding affinity may not contribute significantly to the observed binding free energy if its solution concentration is low. Conversely, a sparsely populated ligand state in solution could be responsible for most of the observed binding free energy if its binding affinity is sufficiently strong relative to the other states.\cite{azimi2022application}   

The result of Eq.~(\ref{eqn:observed-binding-constant-general}), which applies to absolute binding free energy calculations, extends to relative binding free energies or, equivalently, to ratios of observed binding constants for the same receptor of two ligands $A$ and $B$ present in solution in multiple chemical forms:
\begin{equation}
  \frac{K_b(B)}{K_b(A)} = \frac{\sum_i p_0(B_i) K_b(B_i)}{\sum_i p_0(A_i) K_b(A_i)}
  \label{eqn:observed-binding-constant-ratio}
\end{equation}
The result above can be expressed in a more computationally tractable form by separating out from the numerator and denominator the specific binding constant of a reference form of each ligand ($A_0$ and $B_0$) to obtain\cite{de2018rigorous}
\begin{equation}
 \frac{K_b(B)}{K_b(A)} = \frac{K_b(B_0)}{K_b(A_0)} \frac{
 p_0(B_0) + \sum_{i=1} p_0(B_i) K_b(B_i)/K_b(B_0)
 }{
p_0(A_0) + \sum_{i=1} p_0(A_i) K_b(A_i)/K_b(A_0)
 }
\end{equation}
which involves only quantities obtainable by relative binding free energy calculations--one for the two reference forms of the ligand to get  $K_b(B_0)/K_b(A_0)$ and those of each form of each ligand relative to the reference to get $K_b(B_i)/K_b(B_0)$ and $K_b(A_i)/K_b(A_0)$.

\subsection{General simulation setting choices that could affect free energy calculations.}
\tocsubsectioncomment{@Volunteer: Add short discussion of recommended integrators? BAOAB?}
There are many parameter choices that are common to standard MD simulations. Optimal choices may depend on the simulation package and it is best to consult the manual of each package to make the right choices. One particular parameter we want to draw attention to which is often overlooked is the timestep. The choice of integrator can drastically affect the accuracy of a given calculation depending on the timestep~\cite{leimkuhler2016efficient}. Using a 1.0 fs timestep near the limit of stability without any constraints can lead to non-negligible statistical mechanical errors. However, from various previous free energy studies using 1 fs integration timesteps it is not clear that a significant error would be introduced into a free energy estimate and may warrant some further investigation.  

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  Data Analysis               %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\tocorange{Data analysis}}
\label{sec:data_analysis}
Once equilibrium data has been collected from alchemical intermediates, it must be analyzed to produce an estimate of the free energy change (and its associated statistical uncertainty) for each leg of the thermodynamic cycle.
While a number of different estimators are available that will give consistent results under optimal circumstances, some approaches are recommended over others due to their robustness and ability to provide information on poor convergence.

\subsection{Estimators for free energy differences}
\label{subsec:estimators}
Free energy differences between two different states differing in the energy function are directly related to the
ratio of probabilities of those states.
As can be noted, the partition functions in Eq.~\ref{eq:conf_probability} are simply the total accumulated probabilities for all possible configurations of the system. Virtually all of the ways to estimate this free energy are based in converting this ratio of integrals to something that can be measured in one (or several) simulations.  

\paragraph{The Zwanzig relationship (EXP)}
The simplest method for calculating free energy differences from simulations is the so-called \textit{Zwanzig
relationship}~\cite{zwanzig1954hightemperature}, also called one-sided exponential re-weighting (EXP), or simply free energy perturbation, though this final term is sometimes used to encompass all ways of calculating free energy differences.

The (reduced) free energy difference $\Delta f_{01}$ between an initial state 0 and a final state 1 defined by two different potential energy functions 
$u_0(\vec{q})$ and $u_1(\vec{q})$ over coordinate space $\vec{q}$ can be calculated as:
\begin{eqnarray}
\Delta f_{01} & = & -\ln \expect{e^{-(u_1(\vec{q}) - u_0(\vec{q}))}}_0 =  -\ln \expect{e^{-\Delta u(\vec{q})} }_0
\end{eqnarray}\label{eqn.zwanzig}
and the average is over all samples from the simulation performed with $u_0$. In the case of NVT (canonical) sampling and assuming the masses do not change, then $u$ is simply $U/k_BT$, and $f$ is $F/k_BT$, but it can be generalized to other ensembles with the proper definition of $f$ and $u$.
Described in words, we take the samples generated during our run with the potential energy function $u_0(\vec{q})$ and calculate what the difference in energy would be if we switched instantaneously to the potential energy function $u_1(\vec{q})$, and average the exponential of the negative energy difference to get the negative of the exponential of the free energy difference. The original distributions, P($u_0$) as generated at $\vec{\lambda}=0$ and P($u_1$) would look like those seen in Fig.~\ref{fig:fig_sampling_scheme}\textbf{A}-\textbf{C} on the right hand side. Reevaluating requires almost no extra code functionality to perform; one need only to save a full precision trajectory, and run an unmodified molecular simulation code using the $u_1$ in order to calculate the new energies of stored snapshots. The analysis can be written in a line of code. We note that this method is even more general, in that the instantaneous work to change the potential energy function from $u_0$ to $u_1$ can be replaced by the non-reversible work $W$ to make the same change beginning from the same equilibrium conditions at either end state~\cite{jarzynski1997nonequilibrium,jarzynski1998equilibrium,crooks2000pathensemble}, allowing for non-equilibrium free energy calculations, an alternate approach. We do not detail non-equilibrium transformations here, and refer the reader to more advanced treatments~\cite{maragakis2008bayesian,oberhofer2005biased,procacci2015unbiased,shirts2003equilibrium,ytreberg2004singleensemble, gapsys2020large}, as our focus here is on equilibrium free energy techniques.

Although the Zwanzig equation is formally correct as long as the two states considered sample the same phase space volume, which is true for standard molecular models, it has some very important numerical issues that mean that it often performs badly for standard free energy calculations, even for small molecules~\cite{shirts2005comparison,lu2003appropriate}. One can show that if the standard deviation of the difference $\Delta u(\vec{q}) = u_1(\vec{q})-u_2(\vec{q})$ over all sampled $\vec{q}$ is large, which in this case, means only several times $k_BT$, then very few samples contribute to the average, and the answer will be both biased and extremely noisy~\cite{lelievre2010free}. Essentially, the method is dominated by contributions of rare snapshots~\cite{jarzynski2006rare, wu2005phasespace, wu2005phasespacea}. 


\paragraph{The Bennett Acceptance Ratio (BAR)}
If we have the differences in the potential energy sampled from the distribution defined by $u_0$ to the state defined by $u_1$, and we also have the differences in potential energies from the distribution sampled by $u_1$ to the state defined by $u_0$, we can obtain a significantly improved estimate of the
free energy difference compared to that obtained by EXP. 
This estimate was first derived by Bennett and is hence generally called the Bennett Acceptance Ratio (BAR). It is solved by finding the reduced free energy $f_{ij}$ that satisfied the following implicit equation:
\begin{eqnarray}
 \sum_{i=1}^{n_i} \frac{1}{1 + \exp[\ln(\frac{n_i}{n_j}) + u_{ij}(\vec{q}) - f_{ij})
 ]} \nonumber \\
 =\sum_{i=1}^{n_j} \frac{1}{1 + \exp[\ln(\frac{n_i}{n_j}) - u_{ij}(\vec{q}) + f_{ij})]},
\end{eqnarray}
where $n_i$ and $n_j$ are the number of samples from each state. More recent derivations show that this formula is the maximum likelihood estimate of the free energy difference given sets of samples from the two states~\cite{shirts2003equilibrium}. 

Many studies have demonstrated both the theoretical and practical superiority of BAR over EXP in molecular
simulations~\cite{shirts2005comparison,lu2003appropriate}, and BAR converges to EXP in the limit that all samples are from a single state~\cite{bennett1976efficient,bennett1976efficient,shirts2003equilibrium}. BAR also requires significantly less overlap between the configurational space of each state to converge than EXP, though some overlap must still exist.

The Bennett acceptance ratio is only defined between two states. Usually, the endpoints of interest in a free energy calculation are sufficiently different that we will need a chain of states that gradually change the potential energy function from $u_0$ to $u_1$, as discussed in Sec.~\ref{sec:important_path}. You can carry out a BAR estimate between each pair of states $\Delta f_{1 \rightarrow N} = \Delta {f_{1\rightarrow 2}} + \Delta {f_{2\rightarrow 3}} +  \ldots + \Delta f_{N-1\rightarrow N}$.

There is one important thing to note about the uncertainty estimates when summing multiple free energies together to calculate an overall free energy estimate. Although BAR itself gives a free energy estimate that is asymptotically correct and is much less biased than the uncertainty estimate for EXP, the uncertainties in $\Delta {f_{i-1\rightarrow i}}$ and $\Delta {f_{i\rightarrow i+1}}$ are not uncorrelated, because they both involve the energies $u_i(\vec{q})$. The variances of each of the free energies will \textit{not} propagate as variances usually do (in quadrature) into the variance of the overall free energy. Instead, some other method for propagating the uncertainty, such as bootstrapping~\cite{grossfield2018best} must be used.

\paragraph{Thermodynamic integration (TI)}
By taking the derivative of the free energy with respect to the
variable $\vec{\lambda}$, we find that:
\begin{equation}
\frac{df}{d\vec{\lambda}} = \frac{d}{d\vec{\lambda}} \left[-\ln \int \frac{\exp{-u(\vec{\lambda},\vec{q})}}{Z(\vec{\lambda})} d\vec{q}\right] = \expect{\frac{du(\vec{\lambda},\vec{q})}{d\vec{\lambda}}\
}_{\vec{\lambda}} .
\end{equation}
And then we can numerically integrate $df/d\vec{\lambda}$ over an alchemical transformation, using a range of different well-established techniques, to obtain:
\begin{equation}
\Delta f    = \int_{0}^{1} \expect{\frac{du(\vec{\lambda},\vec{q})}{d\vec{\lambda}}}_{\vec{\lambda}}  d\vec{\lambda}.    
\end{equation}
This approach to calculating the free energy is called thermodynamic integration (TI). Averaging over $\expect{\frac{du}{d\vec{\lambda}}}$ requires fewer uncorrelated samples to reach a given level of relative error
than averaging $e^{-u(\vec{q})}$, as the distribution of values is usually narrower, with a more Gaussian shape to the distribution. Rather than being limited by overlap, as in the case of BAR and MBAR (see below), we are instead limited by the bias in the numerical quadrature, which must be minimized sufficiently to be beneath the level of statistical noise.

Various numerical integration schemes are possible, but the trapezoid
rule provides a simple and robust scheme. All types of numerical integration can be written as:
\[ \Delta f \approx \sum_{k=1}^{K} w_k
\expect{\frac{du(\vec{\lambda},\vec{q})}{d\vec{\lambda}}}_{k}, \] where the weights $w_k$ correspond to a particular choice of numerical integration.
Researchers have tried a large number of different integration schemes~\cite{resat1993studies,jorge2010effect,shyu2009reducing}. However, many integration choices require specific choices of $\vec{\lambda}$ to minimize bias, which makes them unsuitable when the intermediates
have widely-varying levels of uncertainty. For example, integrating a cubic spline interpolation provided negligible benefits over a simple trapezoid rule~\cite{paliwal2011benchmark}. As fitting to higher order polynomials can have numerical instabilities for some energy functions, and because alternate functional forms might only be appropriate with some types of transformations, expertise and experience is required to perform such numerical integration modifications. For starting researchers, we therefore recommend the simple trapezoid rule scheme, as it allows for maximal flexibility in which values of $\vec{\lambda}$ are simulated. In practice, adding 2-3 more intermediate states is typically sufficient to match the performance of these more complicated numerical quadrature schemes. It is also possible to calculate the $\lambda$-derivatives at non-simulated states from simulated states in a scheme named extended TI~\cite{ruiter2016extended} which reduces the integration error.

One drawback of TI is that it requires derivatives with respect to $\vec{\lambda}$ to be calculated directly in the code. Unfortunately, many problems of interest require using pathways (such as the soft-core pathways, for removing repulsive interactions) that are not linear, as we discuss, making this more complex. Still, if the code of interest does compute $\frac{du}{d\vec{\lambda}}$, then TI is perhaps the simplest method to use, as it involves a very little post-processing effort.

\paragraph{The multistate Bennett acceptance ratio (MBAR)}
One can generalize Bennett's logic from two states to multiple states to obtain a free energy estimator that uses energy differences between configurations at all intermediate states to compute free energy differences between all states. MBAR gives a system of implicit equations for the free energies $f_i$:
\begin{equation}
f_i = - \ln \sum_{n=1}^{N} \frac{\exp(-u_i(\vec{q}_n))}{\sum_{k=1}^K N_k \exp(f_k-u_k(\vec{q}_n))},
\end{equation}
where there are $N_k$ samples from each of $K$ states, with $\sum_k N_k=N$ the total number of samples. Thus, we need to evaluate the energy function $u_i$ for all samples obtained at all states in the transformation. The equations can be solved by a number of different standard routines. We note that there are only $K-1$ independent equations, so only $K-1$ of the free energies are independent variables, and one of the $f_i$ must be specified (usually, without loss of generality, setting it to zero).

MBAR is probably the lowest variance asymptotically unbiased estimator of the free energy given the energies of the samples~\cite{tan2004likelihood}, which means that BAR is also the lowest variance estimator for the free energy difference between only 2 states, as it is mathematically exactly the same as MBAR in this case. MBAR also provides an uncertainty estimate, derived from standard error propagation methods for implicit functions, which has been shown to be highly accurate as long as there are sufficient samples at each state~\cite{paliwal2011benchmark}.

MBAR can also be thought of as the Zwanzig estimator of the free energy to state $i$ where the sampled distribution is the \textit{mixture distribution} of all the other samples thrown together in one ``pot'', defined by $p_m(\vec{q}) = N^{-1} \sum_k N_k \exp(f_k-u_k\vec{q})$, which is the weighted average of all the individual normalized probability distributions from the simulations that are performed~\cite{shirts2017reweighting}.

\paragraph{Recommendations}
\begin{itemize}
\item We recommend MBAR if all energy differences are available. It is the lowest variance unbiased free energy estimate given samples from multiple states.
\item BAR is essentially just as good as MBAR for highly optimized $\vec{\lambda}$ intermediates. Specifically, if the $\vec{\lambda}$s are chosen such that intermediate states have moderate overlap with their neighbors (i.e. between $i$ and $i+1$ and between $i$ and $i-1$, they will \textit{not} have significant overlap with their next nearest neighbors $i+2$ and $i-2$. Thus MBAR does not actually get significant information from these energy differences, so one might as well not even calculate them, and just perform BAR between nearest neighbors.~\cite{paliwal2011benchmark} 
\item TI usually gives similar values as MBAR implemented with sufficient numbers of intermediates, but quadrature errors that are hard to estimate beforehand  can occur if one is not careful.~\cite{paliwal2011benchmark}
\item WHAM is an approximation to MBAR, and there are no compelling reasons it should be used. If careful, it is not necessarily much worse than the other methods, but it always introduces some degree if binning error.
\item Other variants, especially ones that adaptively determine the free energies can be useful in certain circumstances but beyond the scope of a Best Practices article.
\end{itemize}

\subsection{Detecting the boundary between equilibrated and production regions}
\label{sec:automatic-equilibration-detection}
Much of the infrastructure for analyzing alchemical free energy calculations relies on the concept of asymptotically unbiased estimators, which produce unbiased estimates of the free energy when fed very long simulations~\cite{shirts2005comparison}.
In reality, free energy calculations are often initiated from highly atypical initial conditions (such as a protein-ligand geometry obtained from docking and subjected to a heuristic solvent placement scheme), and simulations are of a finite length dictated by available computational resources and computing demands.
As a result, these estimators can produce significantly biased estimates if fed the entirety of simulation data generated without further processing~\cite{chodera2016simple}.
\begin{figure}
    \centering
    \includegraphics[width=0.95\linewidth]{figures/fig11_equib_detection/Figure.pdf}
    \caption{{\bf Automatic partitioning into equilibration and production regions.}
    (\textbf{A}) The average (black line) standard deviation (shaded region) of the reduced potential $u^*$ over many independent replicate simulations started from the same initial conditions show a significant initial transient change before relaxing to the true average potential energy (\textbf{B}). A cumulative average (red) of the entire simulation data demonstrates simulation bias not seen when initial simulation data is omitted (blue). Using an automated approach to detect equilibration of the boundary $t_0$ using statistical inefficiency $g$ (\textbf{C})  for an effective simulation interval (\textbf{D}). (\textbf{E}) The optimal equilibration boundary $t_0$ is selected to maximize the number of uncorrelated samples.
    \emph{Figure adapted from~\cite{chodera2016simple}.}
    }
    \label{fig:automatic-equilibration-detection}
\end{figure}

To minimize this effect, an initial portion of the simulation is often discarded to \emph{equilibration}~\cite{braun2019best}, with the idea of removing the most heavily biased initial portion of simulation data but retaining the unbiased \emph{production} region that represents a stationary Markov chain process sampling from the desired equilibrium target distribution.
Because the simulation time required for the atypical initial sampler state to relax toward equilibrium is a property of the specific system being simulated and the specific initial conditions selected, it is simplest to collect data for the whole process and use an automated algorithm to select how much data should be discarded to equilibration in a post-processing step.

A simple approach to automatically partitioning simulation data into equilibration and production regions is described in~\cite{chodera2016simple} (illustrated in Fig.~\ref{fig:automatic-equilibration-detection}).
Suppose we have a simulation of length $T$ consisting of correlated data.
Here, the goal of the post-processing step is to select the equilibration boundary $t_0 \in [0, T]$ so as to \emph{maximize} the number of effectively uncorrelated samples remaining in the production region $N_{[t_0,T]}$, which is defined as
\begin{eqnarray}
N_{[t_0,T]} &=& \frac{T - t_0}{g_{[t_0,T]}}
\end{eqnarray}
where $g_{[t_0,T]}$ is the \emph{statistical inefficiency} of a timeseries $a_t$, described in more detail below.
Conveniently, this procedure also produces the information necessary to decorrelate the simulation data for estimating the free energy differences, a requisite next step in analysis.
This approach is implemented within the MBAR~\cite{kylebeauchamp2019choderalab} and alchemlyb~\cite{daviddotson2019alchemistry} packages, and is highly recommended for standard practice.

For additional discussion of working with correlated data and autocorrelation analysis, please refer to the work on Best Practices for Quantification of Uncertainty and Sampling Quality in Molecular Simulations~\cite{grossfield2018best}.

\paragraph{Computing the timeseries for equilibration detection}
Typically, the timeseries of note $a_t$ analyzed in automated equilibration detection is the negative logarithm of the probability density ($\pi(x_t; \vec{\lambda}$)) sampled by the MCMC algorithm (up to an irrelevant additive constant).
For simple independent simulations that sample $x_t \sim \pi(x ; \vec{\lambda})$, this is given by the reduced potential
\begin{eqnarray}
a_t &\equiv& - \ln \pi(x_t; \vec{\lambda}) + c = u(x_t; \vec{\lambda}) .
\end{eqnarray}

Note that the use of the effective reduced potential is not guaranteed to pick up on all slow relaxation processes that may be coupled to the alchemical free energy, but the simplicity of its computation means it is generally appropriate for most cases.

\paragraph{Cautions in automating equilibration detection}
For simulations that are simply not long enough to contain a large number of samples from true equilibrium either because they are very short or contain slow processes, this procedure cannot completely remove the bias.
In such cases, this approach simply selects the final portion of the the simulation, which may be contained in a single substate of configurational space, and may itself lead to biased estimates. 
This situation can be detected if the equilibration boundary $t_0$ is a significant fraction of the total simulation length $T$, with a good rule of thumb being that $T \gtrsim 20 t_0$.
If this is not possible, advanced analysis techniques that assume only local equilibrium (rather than global equilibrium) such as the TRAM estimators~\cite{mey2014xtram,wu2016multiensemble,nuske2017markov} may be more appropriate, but are beyond the scope of this paper. 

\subsection{Decorrelating samples for analysis}
\label{sec:decorrelating-samples}
\paragraph{Computing the statistical inefficiency}
Most estimators require an uncorrelated set of samples from the equilibrium distribution to produce (relatively) unbiased estimates of the free energy difference and its statistical uncertainty.
To do this, the production region of the simulation is generally \emph{subsampled} with an interval approximately equal to or greater than the \emph{statistical inefficiency} $g \ge 1$ to produce a set of uncorrelated samples that can be fed to the estimator machinery~\cite{chodera2016simple},
\begin{eqnarray}
g &\equiv& 1 + 2 \tau_\mathrm{eq} \label{eq:statistical-inefficiency-definition}
\end{eqnarray}
where $\tau_\mathrm{eq}$ is the integrated autocorrelation time, formally defined as
\begin{eqnarray}
\tau_\mathrm{eq} &\equiv& \sum_{t=1}^{T-1} \left(1 - \frac{t}{T}\right) C_t \label{eq:integrated-autocorrelation-time-definition} , 
\end{eqnarray}
with the discrete-time normalized fluctuation autocorrelation function $C_t$ defined as
\begin{eqnarray}
C_t &\equiv& \frac{\expect{a_n a_{n+t}} - \expect{a_n}^2}{\expect{a_n^2} - \expect{a_n}^2} . \label{equation:autocorrelation-definition}
\end{eqnarray}
The basic concept is that $\tau_\mathrm{eq}$ corresponds to the single-exponential decay time for the autocorrelation process that generates samples, so the statistical inefficiency $g$ measures the approximate temporal separation between two effectively uncorrelated samples (where two exponential relaxation times are presumed to be sufficient).

Robust estimation of $C_t$ for $t \sim T$ is difficult due to growth in statistical error, so common estimators of $g$ make use of several additional properties of $C_t$ to provide useful estimates (see \emph{Practical Computation of Statistical Inefficiencies} in~\cite{chodera2016simple} for a detailed discussion).

We recommend using the robust statistical inefficiency computation routines available within the MBAR~\cite{kylebeauchamp2019choderalab} and alchemlyb~\cite{daviddotson2019alchemistry} packages.

\paragraph{Subsampling data to generate uncorrelated samples}
Once the statistical inefficiency $g$ has been estimated, it is straightforward to subsample the correlated timeseries simulation data to produce effectively uncorrelated data that can be fed to the free energy estimators.
Suppose the correlated timeseries is $\{a_t\}_{t=1}^T$; we can form a new timeseries of $N_{\mathrm{eff}} \approx T / g$ effectively uncorrelated samples by selecting a subset of indices $\{ \: t = \mathrm{round}((n-1) \, g) \: | \: n \in \mathrm{range}(1,\ldots ,N) \: \}$ where $\mathrm{round(x)}$ denotes rounding to the nearest integer.

If independent simulations are used, the alchemical state $\vec{\lambda}$ may have a significant impact on the correlation time, and these simulations should be subsampled independently using a separate estimate of the statistical inefficiency $g$ for each alchemical state.
If coupled simulations are used (such as a Hamiltonian replica exchange simulation), the replicas should undergo equivalent random walks in alchemical space, and the replicas can be subsampled with the same $g$ to generate an equal number of uncorrelated samples at each alchemical state.
Conveniently, the approach described above for automated equilibration detection produces an appropriate estimate of $g$ over the production region for automating this process.

\paragraph{Cautions and considerations}
Reliable estimation of the statistical inefficiency is difficult, and estimates will not generally be as precise (in a relative error sense) as averages.
To ensure there is sufficient data available for reliable decorrelation and estimation of free energy differences, it is recommended that the effective number of uncorrelated samples $N_{\mathrm{eff}} \ge \approx 50$ if the BAR or MBAR estimators (discussed below in sec~\ref{subsec:estimators}) are used; the number may need to be much higher with alternate estimators.


\subsection{Uncertainty estimation}
\tocsubsectioncomment{To be split between single/ multiple papers. @Agastya P Bhati/ Peter Coveney to expand. Cycle closure etc. to be moved to second paper.}
\tocsubsectioncomment{@Volunteer: Add discussion of bootstrapping vs t-based confidence intervals for repeats of single calculations (both bad options)?}
\label{subsec:uncertainty}
It is important to consider the variation in your computed free energies from your equilibrium simulations, in order to obtain an estimate of uncertainty of the obtained value for the free energies of interest. A recent Best Practices paper by Grossfield et al.,~\cite{grossfield2018best} provides substantial detail on how to estimate uncertainties from molecular simulations and is a good starting point for this topic. 
The uncertainty of a free energy estimate is limited however, as it is only an estimate of the configurations sampled and cannot contain any information from the phase space not sampled during a simulation. As a consequence, the variance in free energy afforded by any estimator will always be an underestimate of the true uncertainty.
In general, the quantification of different error metrics depends on both data generation and analysis methods used from the ones discussed above. 

The computation of free energies using TI (Sec.n~\ref{subsec:estimators}) is straightforward and the trapezoidal rule is often recommended since it allows unequal spacing of $\vec{\lambda}$ states, which is required to minimize the variance in the free energy estimate, but in principle any good numerical integration method can be used. 
The determination of regions of high curvature when estimating the integral is helpful to determine regions of phase space where more sampling and/or more $\vec{\lambda}$ states are necessary to obtain the best approximation of the integral. Plotting $\vec{\lambda}$ with respect to the gradients at each of the $\vec{\lambda}$ values can be a helpful diagnostic. 
Additionally, computation of the overall variance of TI requires the calculation of the overall variance of integration, rather than each individual $\Delta$G$_{i,i+1}$ and assuming variances add independently. 
Therefore, $\mathrm{var}$($\Delta$f) = $\sum_{i=1}^{K}w_{k}^2 \mathrm{var}(\frac{du}{d\vec{\lambda}})_{k}$.

For alchemical changes that result in smooth, low curvature sets of $\expect{\frac{dU}{d\vec{\lambda}}}$, a relatively small number of $\vec{\lambda}$ states is necessary for sufficient accuracy and low variance in the free energy estimate. 
Depending on the difficulty of the perturbation, the bias introduced by discretization of the integral can become large due to increased curvature, and more $\vec{\lambda}$ intermediate states become necessary to reduce error.
It is recommended that researchers verify that a sufficient number of states are included such that the free energy is essentially invariant to the number of lambda intermediate states chosen. Good heuristics or measures to assess the 'difficulty' of a given perturbation is still an ongoing research topic. 

Compared with TI, the MBAR method (Sec.~\ref{subsec:estimators}) discussed above provides uncertainty estimation directly from solving a set of linear equations to compute the variances between all states. 
The number of states and amount of sampling should be optimized to minimize the uncertainty in the MBAR free energy estimate, while balancing other key considerations such as computational expense. 

If possible, it is advisable to analyze the same set of simulations with different estimators, providing an opportunity for synergy. If different estimators agree the free energy estimate is more reliable than if there are differences between methods that are larger than 1 kcal/mol and would indicate poor convergence. 

Uncertainty can also be assessed for a particular perturbation by repeating calculations with slight changes in initial configurations, forcefield parameters, and different random seeds in the MD engine. 
The assessment of variability in free energy calculations due to repeating simulations has been previously reported~\cite{aldeghi2019accurate,paliwal2011benchmark,mey2016blinded,mey2018impact}, and large variance in free energies estimated from simulations with different random seeds should be flagged as issues with convergence. 

For relative binding free energy calculations, additional sensitivity analysis can be performed by changing the initial configurations of non-core regions of the perturbation topology and determining if this change in configurations results in a large differences in the computed relative free energy, indicating poor sampling of ligand configuration.
The proposed changes in configuration are increasingly relevant if no experimental evidence is available to reduce uncertainty in where the changing atoms should be positioned.

In addition to statistical uncertainty and sampling, a variety of other factors can impact results from binding free energy calculations. In addition to the choice of initial configuration, results can depend on the choice of force field for the protein/receptor, water, and small molecule(s), so rerunning calculations with different choices of force field can also be used to assess how sensitive results and conclusions are to these particular choices. Other factors, like system preparation (choice of protonation state, tautomer, counterion presence, salt concentration, etc.) can also substantially impact results~\cite{mobley2017predicting, mobley2017predictinga}, so unless modelers are confident they have these factors correct, sensitivity to these choices may also need to be examined.

\subsection{Are my simulations any good?}
\label{sec:are-they-good}
There are different easily measurable indicators that can test how well converged simulations are, and if all alchemical states have been sufficiently sampled for a rigorous analysis. Furthermore, once you have established that individual perturbations are well behaved, there are some tricks to ensure the overall perturbation network gives reliable results.

\paragraph{Convergence of simulations}
Fig.~\ref{fig:freeenergytrajectories} illustrates how looking at the convergence of your data may be important. The CB8 host with guest G3 has a longer correlation time than the G6 guest in the octa acid (OA) host. In some cases, slow correlation time may not be expected and therefore not a feature known in advance. To this end, you should always look at all simulation data available and check convergence behaviour for each free energy estimate.
Comparing the free energy trajectories as a function of the simulation time in the forward and reverse time direction is a useful convergence test~\cite{klimovich2015guidelines}.
As shown in Fig.~\ref{fig:freeenergytrajectories}, disagreements larger than 1~$k_{B}T$ in the final part of the forward and reverse trajectories can be useful to detect unconverged results (see also Fig.~\ref{fig:convergence_forward_reverse}).
In this case, one can extend the simulations or try an approach that requires simulations in two separate binding modes where they interconvert at very slow timescales.  
\begin{figure}
    \includegraphics[width=0.90\linewidth]{figures/fig9_convergence/Figure.pdf}
    \caption{Average binding free energy of 5 replicate Hamiltonian replica exchange calculations as a function of total simulation time (i.e. the sum of the simulation time of all replicas) for the two host-guest systems CB8-G3 and OA-G6. Shaded areas represent 95\% confidence intervals around the mean computed from the 5 replicates data. The horizontal dash-dot lines show the final binding free energy prediction of the two calculations after a total of 5230 ns for OA-G6 and 6650 ns for CB8-G3. Dashed lines are the free energy trajectories computed in the forward (blue) and reverse (red) time direction for a single replicate calculation. Longer correlation times in CB8-G3 cause the calculation to converge more slowly. The original data used to generate the plot can be found at \url{https://github.com/samplchallenges/SAMPL6/blob/master/host_guest/Analysis/SAMPLing/Data/reference_free_energies.csv}.
}
    \label{fig:freeenergytrajectories}
\end{figure}

\paragraph{Overlap matrix}
One way of assessing reliability of the calculations is checking the phase space overlap between neighboring $\vec{\lambda}$-windows~\cite{wu2005phasespace, wu2005phasespacea}. For this purpose, a so-called overlap matrix $\mathcal{O}$ can be used. $\mathcal{O}$ is a $K\times K$ matrix, with $K$ being the number of simulated states, i.e. values of $\vec{\lambda}$. Sufficient overlap is important for reweighting estimators such as BAR or MBAR, but cannot help assess reliability of estimates when using TI. 
These matrices are graphical representations of the phase space overlap, i.e. the average probability that a sample generated at state $\vec{\lambda}_{j}$ can be observed at state $\vec{\lambda_{i}}$. As this probability is computed considering the samples from all states, and not just the adjacent states, the values in each row and column add up to 1. In this analysis, the goal is to ensure every state has overlap with its neighbors in both directions, indicated by off-diagonal elements that are sufficiently larger than zero. For accurate calculations, the matrix should be at least tridiagonal.

Details on the calculation and properties of these matrices can be found elsewhere~\cite{klimovich2015guidelines}.
In an overlap matrix $\mathcal{O}$, the off-diagonal values (${O}_{i,j,i\ne j}$) are negatively correlated with the variance of the free energy difference. Accordingly, the uncertainty of the free energy difference between the states $i$ and $j$ will be smaller when ${O}_{i,j,i\ne j}$ is larger (and thus the values in the main diagonal (${O}_{i,j,i=j}$) are smaller). In order to obtain a reliable estimate of the free energy all neighbouring states must be connected, i.e. there must be sufficient overlap between the samples of these states, such that ${O}_{i,j,i\ne j}\ge$ threshold).
However, due to the mathematical derivation it is difficult to explicitly describe the relation of the overlap matrix and the variance by formulae. Consequently, the threshold has to be derived empirically. It has been proposed that the values of the first off-diagonals (i.e. the diagonals above and below the main diagonal) should at least be 0.03 to obtain a reliable free energy estimate~\cite{klimovich2015guidelines}. Smaller values should be considered as a warning sign (see Fig.~\ref{fig:overlap}\textbf{C}), as the variance tends to be underestimated in case of poor overlap.

\begin{figure}
\includegraphics[width=0.90\columnwidth]{figures/fig12_overlap/Figure.pdf}
\caption{\label{fig:overlap} \textbf{Overlap matrices:} Visualising overlap matrices can help with assessing the quality of simulation data. (\textbf{A}) shows good overlap with all first off-diagonal entries well above 0.03, the suggested threshold, (\textbf{B}) is an example of mediocre overlap with good overlap at lower $\vec{\lambda}$ values and poor overlap at high $\vec{\lambda}$ values. (\textbf{C}) shows poor overlap resulting in disconnected simulations with unreliable MBAR estimates.}
\end{figure}

Fig.~\ref{fig:overlap}\textbf{A}, \textbf{B}, and \textbf{C} shows examples of good, mediocre, and poor overlap respectively. For Fig.~\ref{fig:overlap} \textbf{A}, the probability to find a sample from state $i$ in its neighbouring state $j$ is about 0.2 for all states adjacent to the main diagonal, and hence the overall connectivity is good. In the case of Fig.~\ref{fig:overlap} \textbf{B}, the overlap is strongly diminishing in the lower right corner, raising concerns regarding the reliability of the free energy estimate obtained. For Fig.~\ref{fig:overlap} \textbf{C}, the state at $\vec{\lambda}$ index = 6 is connected to neither of its neighbouring states. While this does not necessarily imply that the result for this perturbation is wrong, the energy estimate must at least be considered as highly unreliable.
In order to overcome the issue of poor overlap in this example, additional sampling should be performed by introducing additional states, i.e. $\vec{\lambda}$ values.

Interestingly, as the variance is inversely correlated with the number of states~\cite{klimovich2015guidelines}, it can in principle be reduced below any arbitrary threshold with enough simulation time and a large enough number of $\vec{\lambda}$ windows. However, decreasing the variance to a value close to 0 is not feasible, as this approach would significantly increase the calculation time. While variance can be decreased by increasing simulation length, if the overlap between states is known to be poor, increasing the number of $\vec{\lambda}$ values, or adjusting the spacing of those values to better cover regions of poor overlap will likely provide a larger immediate impact. Different approaches are described in Sec.~\ref{sec:simulation_protocol_choice} and more details can be found in the literature~\cite{dakka2018concurrent, hahn2019alchemical}.

\paragraph{Reversible binding simulations}
An even more stringent test of the correctness of binding free energy calculations is to compare the results to the equilibrium binding constants derived from long timescale reversible binding simulations~\cite{pan2017quantitative}. For small ligands with millimolar affinities, repeated binding to and unbinding from the protein can occur for a large number of times in a sufficiently long unbiased MD simulation (10-100 $\mu$s), and the equilibrium binding constants can be computed from the ratio of bound to unbound fractions of the simulation time. The agreement between the binding free energy calculations and the reversible binding simulations---given the same system preparation and the same force field parameters---will strongly support the correctness of both calculations, as the same results are arrived at by two independent methods, and any discrepancy will suggest some systematic error in one, or both, of the two methods. As part of validation testing of alchemical free energy codes a benchmark set to compare alchemical and direct computation of equilibrium binding constant should become standard in future.

\subsection{Common issues to watch out for during analysis}

It is important to carefully examine output data for common problems. Some of the most important things to check for are:
\begin{itemize}
\item \textbf{Sampling of the binding site by the ligand:} Make sure the ligand samples the binding site reasonably tightly for its expected potency and fit, and that it does not depart out of binding site in the coupled end state if it is a moderate to strong binder. 
\item \textbf{Consistency of free energy estimates across different estimators} Significant discrepancies, meaning results that further outside the mutual error estimates than would be plausible statistically, between free energies calculated with different free energy estimators such as TI, BAR, and MBAR. All of these estimators converge to the same results with sufficient sampling. Differences between them indicate poor overlap or errors in processing.
\item \textbf{Have replicas mixed well?} Poor replica mixing (for replica-exchange) or $\lambda$-space sampling for single-replica methods. If the system is not mixing between states, then the states are insufficiently close for mixing, or else there are bottlenecks in the configurational sampling that limit the accuracy.
\item \textbf{Behaviour of correlation times:} Correlation time that does not vary relatively smoothly as a function of $\vec{\lambda}$. Discontinuities in correlation time with $\vec{\lambda}$ indicate that the system is sampling significantly different configurations with only small changes to the Hamiltonian changes. This usually indicates sampling problems.
\item \textbf{Dependence of the free energy on initial configuration of the system.} Ensemble average properties should not depend on the starting point.
\item \textbf{Torsional sampling} Torsions with multiple low-energy minima where some of these minima are visited rarely or not at all. Which torsions have low energy minima can best be found by comparing to the simulation in the solvent. There should be clear physical reasons that simulation in the complex has different torsional distributions that the ligand in the solvent. 
\item \textbf{Free energy dependence on $\vec{\lambda}$} The free energy difference between states should vary relatively smoothly with $\vec{\lambda}$. If it varies drastically, then either there need to be finer sampling in $\vec{\lambda}$ in this region, or there are sampling problems there.
\item \textbf{Convergence of free energy} The free energy should clearly converge as a function of simulation time (Fig. ~\ref{fig:convergence_forward_reverse}).
\item If using non-equilibrium methods, \textbf{is the result independent of the speed at which the non-equilibrium change is performed}? Non-equilibrium methods are in theory independent of the switching time in the limit of good sampling unless the switching time is simply too short. 
%\item Other Diagnostics for non-equilibrium methods, robustness for switching time etc.?
\item \textbf{Visualization of data} In general, inspect output data such as energies and visualize the simulation trajectories and assess if they match your expectations. Many issues can be spotted by a straight forward visualization. 
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Conclusions                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\tocred{Unsettled Practices and Current Limitations}}
\tocsectioncomment{@Everyone to contribute to section on unsettled practices/ current limitiations, as suggested by John Chodera.}
\label{sec:unsettled}

\subsection{Unsettled practices}

Alchemical Free Energy (AFE) calculations have primarily been applied to simulate the stoichiometric, non-reversible binding of organic molecules to well-structured proteins. However, several areas of drug discovery involve other classes of binding events. While the underlying theory of alchemical free energy calculations is generally applicable, additional work may be required to develop efficient protocols suited to systems beyond the traditional small moleculeprotein complex.
For example, there is growing interest in identifying small molecules that directly bind to RNA or DNA, with recent preliminary studies showing promising results using specialized simulation protocols.\cite{Abramyan2025,Rasouli2024} In contrast, there has been limited investigation into the applicability of AFE methods to small-molecule ligands targeting intrinsically disordered proteins (IDPs,\cite{Papadourakis2024} or proteins containing intrinsically disordered regions (IDRs) that undergo disorder-to-order transitions upon ligand binding.\cite{MendozaMartinez2022}
The treatment of covalent binders has also received some attention.\cite{Luo2021,Zhang2019 } However, robust protocols for handling datasets of irreversible covalent binders containing diverse warheads have not yet achieved widespread adoption.\cite{Yu2019}



\subsection{Current limitations}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Conclusions                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\tocorange{Conclusions}}
\tocsubsectioncomment{@Volunteer to update reflecting focus on single calculations.}
\label{sec:conclusion}
Alchemical free energy calculations have seen a vast increase in popularity both in academic research as well as pharmaceutical industry applications in structure based drug discovery~\cite{schindler2020largescale, sherborne2016collaborating, wagner2017computational}. Commercial products such as FEP+ and Flare, which provide a convenient user interface make the setup and use of these methods much easier~\cite{wang2015accurate, kuhn2020assessment}, but this convenience comes with less flexibility in terms of choice of simulation protocols. It is also important to understand the current limitations of the methodology to recognise when automated workflow tools can be used effectively for a given protein target and when they are likely to fail still. Prospective prediction challenges such as the Drug Design Data resource grand challenges provide a community driven platform to evaluate different free energy protocols against each other on blinded targets~\cite{gaieb2018d3r, gaieb2019d3r}. Such efforts have highlighted that selection of seemingly identical or similar potential energy function or simulation package does not guarantee production of similar free energies owing to differences in simulation protocols. 
We hope that the best practice guide provides a set of tools that allow a better understanding of how to setup, run, and reliably interpret alchemical free energy calculations. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Software                    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\tocorange{Selection of available software packages}}
\tocsectioncomment{@Volunteers to update.}

\label{sec:software}
There are many different software solutions available for the setup, running, and analysis of alchemical free energy calculations. These will vary in customizability and ways in which they are ran, e.g. graphical user interface versus command line tool or python script. The following provides a non-exhaustive list of commercial and noncommercial tools available for conducting alchemical free energy calculations. 
\begin{itemize}

\item [] \textbf{Simulation software: Commercial}
   \begin{itemize}
    \item \href{https://www.schrodinger.com/fep}{FEP+} is a tool offered by Schr\"{o}dinger Inc. under a commercial license. It has an intuitive GUI which makes it easier for non-experts to run alchemical free energy calculations and analyze the results. It runs the DESMOND MD package under the hood and hence parallelizes well on GPUs~\cite{wang2015accurate}. 
    \item \href{https://www.cresset-group.com/software/flare/}{Flare} is a commercial structure-based drug design software offered by Cresset. Similar to FEP+ it has an easily accessible graphical user interface and strives to facilitate free energy calculations for non-experts while offering advanced users full control via a Python API. It only runs on GPUs, using CUDA or OpenCL~\cite{kuhn2020assessment}. It is build on top of the open source software packages Sire and BioSimSpace (cf. below).
    \item The molecular operating environment (\href{https://www.chemcomp.com/Products.htm}{MOE}) offered by the Chemical Computing Group (CCG) has a tool for performing free energy calculations. It is built on AMBER-TI (cf. below).
    \end{itemize}
    \item[]All the above tools also provide a convenient setup and analysis suite and are really a one in all product. \newline
\item [] \textbf{Simulation software: Free/low cost academic and Commercial}
	\begin{itemize}
	\item \href{https://www.charmm.org/}{CHARMM} has a variety of tools developed over the years. The PERT module can be used to define initial and final states and define the intermediate lambda points. FREN and BAR modules can be used to analyze the data after the MD run. Lambda-dynamics-based free energy calculation can be carried out using the BLOCK module.  
	\item \href{https://ambermd.org/}{AMBER}, including its new pmemd.cuda version supports free energy calculations~\cite{salomon-ferrer2013overview}. 
	\item \href{http://www.gromos.net/}{GROMOS} offers an extensive and flexible molecular dynamics and simulations analysis suites with free energy calculation functionalities including customizable alchemical paths and various sampling protocols~\cite{schmid2012architecture, kunz2012new, eichenberger2011gromos}.
	\end{itemize}
\item [] \textbf{Simulation software: Open Source}
	\begin{itemize}
	\item \href{https://www.plumed.org/}{PLUMED} is a tool which enables the usage of a variety of MD engines. It is designed as a plugin for MD packages such that it analyzes the trajectory on the fly. It also offers a VMD based plugin for the computation of collective variables~\cite{bonomi2019promoting}.   	
	\item \href{https://biosimspace.org/}{BioSimSpace} is a multiscale molecular simulation framework, written to allow computational modellers to quickly prototype and develop new algorithms for molecular simulation and molecular design~\cite{hedges2019biosimspace}. 
	\item \href{https://siremol.org/}{Sire} is a multiscale, molecular simulation framework that provides several applications, including SOMD, an MD/MC code for performing FEP calculations via an interface to OpenMM. 
	\item \href{http://getyank.org/latest/index.html}{YANK} is a tool developed by John Chodera and group on the top of OpenMM MD package. It allows the users to write their inputs in easy-to-use YAML format.
	\item \href{http://www.gromacs.org/}{GROMACS} is a molecular simulation package with a significant number of free energy methods implementations. The LiveCOMS GROMACS tutorial includes an example free energy calculation~\cite{lemkul2018From}.
	\item \href{http://pmx.mpibpc.mpg.de/instructions.html}{PMX}, an add-on to GROMACS, offers a mutation free energy calculation module~\cite{abraham2015gromacs}.
	\item \href{https://github.com/qusers/Q6}{Q} is MD code for performing FEP calculations using a variety of force fields~\cite{aaquist2017q6}. 
	\end{itemize}
\item[] \textbf{Setup tools:}
	\begin{itemize}
	\item \href{http://pmx.mpibpc.mpg.de/instructions.html}{PMX}: Setup of perturbation maps, perturbed topologies and input coordinates for GROMACS simulations at \url{https://github.com/deGrootLab/pmx}.
	\item \href{https://github.com/MobleyLab/Lomap}{Lomap/Lomap2} : Relative alchemical transformation graph planning for setting up perturbation networks~\cite{liu2013lead}.
	\item \href{http://www.charmm-gui.org/}{CHARMM-GUI} is a web-based tool for setting up a variety of MD simulations. It can be used to generate CHARMM scripts for solvation and ligand-binding free energy calculations~\cite{jo2008charmmgui}.
	\item \href{https://github.com/qusers/qligfep}{QligFEP} offers robust and fast setup of FEP calculations for the software package Q~\cite{jespers2019qligfep}.
	\item \href{https://github.com/protocaller/ProtoCaller}{ProtoCaller}, a setup tool for the automation of Gromacs free energy calculations~\cite{suruzhon2020protocaller}.
	\item \href{https://fesetup.readthedocs.io/en/latest/introduction.html}{FESetup} has been developed primarily to setup calculations in AMBER, GROMACS and SIRE~\cite{loeffler2015fesetup}.
	\end{itemize}
\item []\textbf{Analysis tools:}
	\begin{itemize}

	\item Alchemlyb: Multipackage free energy analysis
	\url{https://github.com/alchemistry/alchemlyb}~\cite{daviddotson2020alchemistry}.
	\item pymbar: MBAR implementation, but have to roll your own analysis wrapper      
	\url{https://github.com/choderalab/pymbar} \cite{shirts2008statisticallya}.
	\item Arsenic: Standardising alchemical free energy analysis \url{https://github.com/openforcefield/Arsenic}
	\item Free Energy Workflows: Sire-specific free energy map analysis using weighted path averages \url{https://github.com/michellab/freenrgworkflows}.
	\end{itemize}
\item[] Generally, commercial software will offer more complete pipelines in which standalone analysis applications are not necessarily needed; free and open source packages often require manual analysis but allow more flexibility and modification.
\end{itemize}


\section{\tocorange{Checklist}}
\tocsectioncomment{@Volunteer to update checklists/ move relevant sections to second paper.}
\label{sec:checklist}
\begin{Checklists*}
\begin{checklist}{ Know what you want to simulate}
    \textbf{Initial questions you should ask before you set up an alchemical free energy calculation using molecular dynamics simulations}
\begin{itemize}
    \item Do I understand the biology, chemistry and physics of my system?
    \item Have I properly prepared my protein and ligand systems?
    \item Does my system contain any structures that require custom parameters?
    \item What simulation protocol will provide the most evidence to verify my hypothesis?
    \item Are the projected computational expense and runtime realistic for my scientific goals?
    \item Will my protocol be reproducible? 
    \item Will my statistics be reliable? If not, would more replicates solve the problem? 
    \item Can I open-source my data?
\end{itemize}
\end{checklist}

\begin{checklist}{Preparing your simulations}
\textbf{Steps to getting started setting up your alchemical free energy calculation}
\begin{itemize}
    \item Make sure you know why you have picked your (combination of) force field(s)
    \item Energy minimize your system
    \item Equilibrate your system properly with your choice of thermodynamic ensemble
    \item Check the stability of your system and whether it behaves the way you believe it should
\end{itemize}
\end{checklist}

\begin{checklist}{Running absolute simulations}
        \textbf{Steps to running your absolute alchemical free energy calculations}
\begin{itemize}
 \item Check your ligands have the same, biologically correct binding pose
        \item Make sure your \textlambda-scheduling is  appropriate
        \item Check if your ligands are discharging and decoupling correctly
        \item Set up your restraints correctly
        \item Make sure you subsample the data in your free energy estimation protocol
        \item Apply the appropriate correction terms
\end{itemize}
\end{checklist}

\begin{checklist}{Running relative simulations}
        \textbf{Steps to running your relative alchemical free energy calculations}
\begin{itemize}
   \item Check your ligands  have the same, biologically correct binding pose
        \item Make sure your $\lambda$-scheduling is set correctly
        \item Make sure your molecular transformations are realistic (1-5 heavy atoms for reliable computations)
        \item Generate a perturbation network by your method of choice; check whether you have enough cycle closures to check consistency in the results
        \item Check whether dummy atoms were assigned correctly
        \item Consider subsampling the data in your free energy estimation protocol
        \item Apply the 
        appropriate correction terms
\end{itemize}
\end{checklist}
\end{Checklists*}

%Analyis checklist
\begin{Checklists*}
\begin{checklist}{How do I know which simulations are unreliable?}
    \textbf{Situations suggesting your relative alchemical free energy calculations have not run properly (assuming absence of experimental affinities)}
        \begin{itemize}
                \item Standard error (\textsigma) should not be \textgreater1 kcalmol$^{-1}$ 
    \item Simulated systems have not converged - trajectories should be manually checked for consistency; other methods such as generating RMSD plots are also recommended
    \newline\newline\textit{Relative:}
    \item If you observe hysteresis in perturbations and incorrect cycle closures
    \item Energy differences \textgreater$\sim$15 kcal$\cdot$mol$^{-1}$  are likely unreliable
    \newline\newline\textit{Absolute:}
    \item Energies \textless$\sim$-15 kcal$\cdot$mol$^{-1}$  are likely unreliable
    \item The ligand has not sampled most of the intended region after the decoupling step
    \item The ligand is drifting out of the intended region after the decoupling step
        \end{itemize}
\end{checklist}

\begin{checklist}{Why are they not reliable?}
    \textbf{Suggestions for finding out why your alchemical free energy calculations may not be reliable}
\begin{itemize}
    \item Check again whether dummy atoms were assigned correctly
    \item Inspect the trajectories across the $\lambda$-schedule (particularly the endpoints) for problems described in the text
    \item Inspect the overlap matrices for lack of overlap
\end{itemize}
\end{checklist}

\begin{checklist}{Data Analysis}
    \textbf{Steps to analyzing your output data correctly}
\begin{itemize}
    \item Make sure you have run enough replicates to ensure statistical reliability (\textgreater3)
    \item Compute both correlation and ranking coefficients and ranking statistics (e.g. r, \textrho, MUE and \texttau)
    \item Include error bars in all your visual analyses
\end{itemize}
\end{checklist}
\end{Checklists*}
\clearpage


\section*{Author Contributions}
%%%%%%%%%%%%%%%%
% This section mustt describe the actual contributions of
% author. Since this is an electronic-only journal, there is
% no length limit when you describe the authors' contributions,
% so we recommend describing what they actually did rather than
% simply categorizing them in a small number of
% predefined roles as might be done in other journals.
%
% See the policies ``Policies on Authorship'' section of https://livecoms.github.io
% for more information on deciding on authorship and author order.
%%%%%%%%%%%%%%%%
\textbf{ASJSM}: Coordinated the document, contributed to most sections, and co-designed Figs.~\ref{fig:fig_binding_thermodynamic_cycle},~\ref{fig:fig_topology},~\ref{fig:fig_mcss},~\ref{fig:fig_types_of_networks},~\ref{fig:fig_absolute_thermodynamic_cycle},~\ref{fig:scatterplot_analysis}, and created Figs.~\ref{fig:fig_what_is_lambda},~\ref{fig:fig_what_is_alchemy},~\ref{fig:overlap},~\ref{fig:pmf} and replotted~\ref{fig:automatic-equilibration-detection} and~\ref{fig:fig_types_of_networks}.\\
\textbf{BA}: Helped write the uncertainty estimation, stopping conditions, and output analysis sections and created figure ~\ref{fig:convergence_forward_reverse}.\\
\textbf{HBM} Contributed to Sec.~\ref{sec:plot_data} and Fig.~ \ref{fig:scatterplot_analysis} and helped edit the paper.\\
\textbf{JDC}: Wrote Sec.~\ref{sec:decorrelating-samples} and~\ref{sec:automatic-equilibration-detection} discussed structure and design of the whole document, suggested Figs.~\ref{fig:fig_what_is_alchemy} and~\ref{fig:fig_sampling_scheme}. \\
\textbf{DFH} Contributed to Sec.~\ref{sec:software} and helped edit the paper. \\
\textbf{MK}: Contributed to Sec.~\ref{sec:data_analysis}, provided the data for figure~\ref{fig:overlap}, compiled the dataset for Sec.~\ref{sec:benchmark} and helped edit the paper.\\
\textbf{JM}: Contributed to Sec.~\ref{subsec:reproducible},~\ref{sec:prerequisites},~\ref{sec:important_path},~\ref{subsec:estimators},~\ref{subsec:uncertainty}, and~\ref{sec:conclusion}\\
\textbf{DLM}: Contributed to the outline, drafted some of the sections, gave ideas on figures, and helped edit the paper.\\
\textbf{LNN}: Helped write the simulation length, stopping conditions, and information saving section. Edited and reviewed alchemical path section.\\
\textbf{SP} Wrote Sec.~\ref{sec:software}. \\
\textbf{AR}: Created figure~\ref{fig:freeenergytrajectories}, contributed to sections~\ref{sec:theory} and~\ref{sec:simulation_protocol_choice}, and helped edit the paper.\\
\textbf{JS}: Created Figs.~ \ref{fig:fig_what_is_alchemy},~\ref{fig:fig_binding_thermodynamic_cycle},~\ref{fig:fig_topology},~\ref{fig:fig_mcss},~\ref{fig:fig_absolute_thermodynamic_cycle},~\ref{fig:scatterplot_analysis}, and an initial draft of~\ref{fig:fig_types_of_networks}. Wrote Sec.~\ref{sec:plot_data}, the checklist Sec.~\ref{sec:checklist}, and contributed to general formatting discussions and editing.\\
\textbf{MRS}: Helped create figure~\ref{fig:fig_what_is_lambda}, wrote Sec.~\ref{sec:important_path} describing choices for alchemical pathways and parts of~\ref{sec:data_analysis} on the analysis for free energy calculations. Reviewed and edited text throughout.\\
\textbf{GT}: Contributed to Sec.~\ref{sec:intro} and~\ref{sec:drugdiscovery}, and helped edit the paper.\\
\textbf{HX}: Contributed Sec.~\ref{subsec:accuracy}, to Sec.~\ref{sec:relative-fe-protocol}, and to Sec.~\ref{sec:are-they-good}.
% We suggest you preserve this comment:
For a more detailed description of author contributions,
see the GitHub issue tracking and changelog at \githubrepository.

\section*{Other Contributions}
%%%%%%%%%%%%%%%
% You should include all people who have filed issues that were
% accepted into the paper, or that upon discussion altered what was in the paper.
% Multiple significant contributions might mean that the contributor
% should be moved to authorship at the discretion of the a
%
% See the policies ``Policies on Authorship'' section of https://livecoms.github.io for
% more information on deciding on authorship and author order.
%%%%%%%%%%%%%%%
Julia E. Rice participated in the original discussion of the document at the Best Practices in Molecular Simulation Workshop Hosted by at NIST, Gaithersburg, MD, August 24th-25th, 2017.
Marieke Schor proofread the manuscript. 

% We suggest you preserve this comment:
For a more detailed description of contributions from the community and others, 
see the GitHub issue tracking and changelog at \githubrepository.


\section*{Potentially Conflicting Interests}
%%%%%%%
%Declare any potentially competing interests, financial or otherwise
%%%%%%%
JM is a current member of the Scientific Advisory Board of Cresset. 
MK is employed by Cresset who commercially distribute a software for performing alchemical free energy calculations. MRS is a Open Science Fellow and consultant for Silicon Therapeutics.
JDC is a current member of the Scientific Advisory Board of OpenEye Scientific Software and a consultant to Foresite Laboratories.
\section*{Funding Information}
%%%%%%%
% Authors should acknowledge funding sources here. Reference specific grants.
%%%%%%%
ASJSM and JM acknowledge funding through an EPSRC flagship software grant: EP/P022138/1
MK and JM acknowledge funding through Innovate UK by KTP partnership 011120.
AR acknowledges partial support from the Tri-Institutional Program in Computational Biology and Medicine and the Sloan Kettering Institute.
HEBM acknowledges support from a Molecular Sciences Software Institute Investment Fellowship and Relay Therapeutics.
DLM acknowledges support from the National Institutes of Health (R01GM108889, R01GM124270, and R01GM132386), and the National Science Foundation (CHE 1352608).
JDC acknowledges support from the National Institutes of Health (NIH P30 CA008748, NIH R01 GM121505, R01 GM132386).
A complete funding history for the Chodera lab can be found at \url{http://choderalab.org/funding}.
The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.

\section*{Author Information}
\makeorcid
\bibliography{alchemical,manual,sb}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% APPENDICES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\appendix


\end{document}
